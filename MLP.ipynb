{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install optuna -q\n","!pip install --upgrade datasets -q\n","!pip install --upgrade triton -q"],"metadata":{"id":"cNHp-qi0iO-b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4f609f4-4b9b-46da-9dd2-d9b9bef21772","executionInfo":{"status":"ok","timestamp":1733600231636,"user_tz":-240,"elapsed":16713,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/364.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/233.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive') # mounting drive where files are stored"],"metadata":{"id":"6MsVjKl7huMh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d46eb162-9e4e-4724-eab7-cc60c21a051c","executionInfo":{"status":"ok","timestamp":1733600252322,"user_tz":-240,"elapsed":20691,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","path = \"/content/drive/MyDrive/AI_Cybersecurity/Project/\"\n","sys.path.append(path)"],"metadata":{"id":"IkmIgn4QEt86","executionInfo":{"status":"ok","timestamp":1733600252323,"user_tz":-240,"elapsed":6,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"CLBHtY71hlUj","executionInfo":{"status":"ok","timestamp":1733600260877,"user_tz":-240,"elapsed":8559,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F # loading libraries\n","from sklearn.datasets import load_iris\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import optuna\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset, DatasetDict, load_from_disk\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import roc_curve, auc\n","from contextlib import nullcontext\n","from utils import BPE_Tokenizer, MLP, train_model, test_model, run_inference_and_collect_results, calculate_auc_roc, plot_confusion_matrix, test_model_adversarial, run_inference_and_collect_results_adversarial, multiples_of_two"]},{"cell_type":"code","source":["torch.set_float32_matmul_precision('high')"],"metadata":{"id":"PRi6tZmEzEa6","executionInfo":{"status":"ok","timestamp":1733600260877,"user_tz":-240,"elapsed":3,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["tokenizer = BPE_Tokenizer(directory=path+'Tokenizer')\n","vocab = tokenizer.vocab\n","vocab_size = len(vocab) + 1\n","print(\"Vocab size is\", vocab_size)"],"metadata":{"id":"3WlYkCSQvBDQ","executionInfo":{"status":"ok","timestamp":1733600263831,"user_tz":-240,"elapsed":2956,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3226c53a-a5dc-4a8a-d645-a04a5b0d84c3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size is 10007\n"]}]},{"cell_type":"code","source":["tokenized_dataset = load_from_disk(path+\"Datasets/FinalDataset/\")"],"metadata":{"id":"GBTLpoNqEir8","executionInfo":{"status":"ok","timestamp":1733600281230,"user_tz":-240,"elapsed":17402,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_dataset = tokenized_dataset['train']\n","val_dataset = tokenized_dataset['validation']\n","test_dataset = tokenized_dataset['test']"],"metadata":{"id":"rQOhXEj-zSiM","executionInfo":{"status":"ok","timestamp":1733600281230,"user_tz":-240,"elapsed":8,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["batch_size = 128\n","\n","# Prepare dataloaders for batching the data during training and evaluation\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"ZsFSGRx9zU_R","executionInfo":{"status":"ok","timestamp":1733600281231,"user_tz":-240,"elapsed":7,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","num_metadata_features = len(train_dataset['metadata'][0])\n","hidden_layers=[128, 256]\n","vector_length = 1024\n","dropout = 0.2\n","warmup_steps = 10\n","context_size = 256\n","num_epochs = 1\n","max_lr = 2e-4\n","scheduler_config = {\"warmup_steps\": 5,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": max_lr,\n","                    \"min_lr\": max_lr * 0.1}"],"metadata":{"id":"ch84qLrFihkf","executionInfo":{"status":"ok","timestamp":1733600281231,"user_tz":-240,"elapsed":7,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Initialize the model for binary classification of class 0\n","model = MLP(vocab_size=vocab_size, context_size=context_size, vector_length=vector_length, hidden_layers=hidden_layers, dropout=dropout, num_metadata_features=num_metadata_features).to(device)\n","\n","# Test the model with the initial untrained state and compute training loss\n","for batch in train_loader:\n","    inputs = batch[\"input_ids\"].to(device)\n","    attention_mask = batch[\"attention_mask\"].to(device)\n","    metadata = batch[\"metadata\"].to(device)\n","    labels = batch[\"label\"].to(device)\n","    logits, _ = model(inputs, attention_mask, metadata, labels)  # Forward pass through the model\n","    print(logits.shape)\n","    break\n","\n","torch.cuda.empty_cache()\n","\n","loss = test_model(model, train_loader, fp16=True, device=\"cuda\")  # Compute the loss on the training dataset\n","print(f\"Initial Training Loss {loss:.4f}\")"],"metadata":{"id":"HyeHO1bs3qvb","executionInfo":{"status":"ok","timestamp":1733598308285,"user_tz":-240,"elapsed":21308,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9153a037-3361-4e1c-a585-25c2d718d567"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([128, 2])\n","Initial Training Loss 0.6877\n"]}]},{"cell_type":"code","source":["def objective(trial):\n","    # Define hyperparameters to optimize\n","    vector_length = trial.suggest_categorical(\"vector_length\", multiples_of_two(128, 1024))\n","    num_layers = trial.suggest_int(\"num_layers\", 1, 5)  # Number of hidden layers\n","    layer_size = trial.suggest_categorical(\"layer_size\", multiples_of_two(64, 512))  # Size of each layer\n","    hidden_layers = [layer_size] * num_layers  # Create a list of `num_layers`, each of size `layer_size`\n","    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n","    num_epochs = trial.suggest_int(\"num_epochs\", 1, 5)\n","    lr = trial.suggest_float(\"lr\", 1e-6, 1e-2, log=True)\n","    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n","    warmup_steps = trial.suggest_int(\"warmup_steps\", 10, 100, step=10)\n","    context_size = 256\n","\n","    # Create the model\n","    model = MLP(\n","        vocab_size=10240,\n","        vector_length=vector_length,\n","        context_size=context_size,\n","        num_metadata_features=num_metadata_features,\n","        hidden_layers=hidden_layers,\n","        dropout=dropout,\n","        padding_idx=tokenizer.padding_idx,\n","        num_classes=2,\n","    ).to(device)\n","    model = torch.compile(model)\n","\n","    # Optimizer\n","    optimizer = model.configure_optimizers(weight_decay=weight_decay, learning_rate=lr, device_type=device)\n","\n","    scheduler_config = {\"warmup_steps\": warmup_steps,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": lr,\n","                    \"min_lr\": lr * 0.1}\n","\n","    # Train the model\n","    model = train_model(\n","        model=model,\n","        train_dataloader=train_loader,\n","        val_dataloader=val_loader,\n","        num_epochs=num_epochs,\n","        optimizer=optimizer,\n","        device=device,\n","        fp16=True,\n","        log_interval=10,\n","        early_stopping=True,\n","    )\n","\n","    # Evaluate on the validation set\n","    val_loss = test_model(model, val_loader, device, fp16=True)\n","\n","    # Return the validation loss as the objective to minimize\n","    return val_loss"],"metadata":{"id":"cxaqmsgrWvra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create an Optuna study\n","study = optuna.create_study(direction=\"minimize\")\n","\n","# Run the optimization\n","study.optimize(objective, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-sWVWASYNVB","outputId":"cfb009fa-522d-4a37-b76e-f8c0e1f5bc8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:05:56,048] A new study created in memory with name: no-name-81db6dd8-94d3-40bd-bc04-356808213682\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 5, with 27,275,520 parameters\n","Num non-decayed parameter tensors: 4, with 194 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3809, Average Validation Loss: 0.0422, Accuracy: 99.19%, Precision: 99.96%, Recall: 98.65%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0897, Average Validation Loss: 0.0404, Accuracy: 99.23%, Precision: 99.94%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0725, Average Validation Loss: 0.0381, Accuracy: 99.22%, Precision: 99.98%, Recall: 98.67%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0428, Average Validation Loss: 0.0378, Accuracy: 99.25%, Precision: 99.96%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0354, Average Validation Loss: 0.0405, Accuracy: 99.23%, Precision: 99.99%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0590, Average Validation Loss: 0.0318, Accuracy: 99.18%, Precision: 100.00%, Recall: 98.58%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0409, Average Validation Loss: 0.0337, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.63%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0549, Average Validation Loss: 0.0276, Accuracy: 99.35%, Precision: 99.99%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0318, Average Validation Loss: 0.0290, Accuracy: 99.39%, Precision: 99.98%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0455, Average Validation Loss: 0.0271, Accuracy: 99.38%, Precision: 99.96%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0222, Average Validation Loss: 0.0308, Accuracy: 99.41%, Precision: 99.97%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0576, Average Validation Loss: 0.0310, Accuracy: 99.27%, Precision: 99.47%, Recall: 99.26%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0282, Average Validation Loss: 0.0424, Accuracy: 99.14%, Precision: 100.00%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:07:18,864] Trial 0 finished with value: 0.04248847967482525 and parameters: {'vector_length': 1024, 'num_layers': 3, 'layer_size': 64, 'dropout': 0.30000000000000004, 'num_epochs': 1, 'lr': 0.0007064166250862515, 'weight_decay': 9.92074768822372e-05, 'warmup_steps': 80}. Best is trial 0 with value: 0.04248847967482525.\n","W1207 13:07:20.195000 997 torch/_dynamo/convert_frame.py:844] [0/11] torch._dynamo hit config.cache_size_limit (8)\n","W1207 13:07:20.195000 997 torch/_dynamo/convert_frame.py:844] [0/11]    function: 'forward' (/content/drive/MyDrive/Project/utils.py:159)\n","W1207 13:07:20.195000 997 torch/_dynamo/convert_frame.py:844] [0/11]    last reason: 0/1: GLOBAL_STATE changed: grad_mode \n","W1207 13:07:20.195000 997 torch/_dynamo/convert_frame.py:844] [0/11] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n","W1207 13:07:20.195000 997 torch/_dynamo/convert_frame.py:844] [0/11] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 144,993,280 parameters\n","Num non-decayed parameter tensors: 3, with 1,026 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3151, Average Validation Loss: 0.0541, Accuracy: 99.19%, Precision: 99.84%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0652, Average Validation Loss: 0.0555, Accuracy: 99.21%, Precision: 99.97%, Recall: 98.66%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0474, Average Validation Loss: 0.0699, Accuracy: 99.22%, Precision: 99.99%, Recall: 98.66%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0933, Average Validation Loss: 0.0508, Accuracy: 99.28%, Precision: 99.96%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0259, Average Validation Loss: 0.0844, Accuracy: 99.01%, Precision: 100.00%, Recall: 98.29%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0355, Average Validation Loss: 0.0459, Accuracy: 99.34%, Precision: 99.92%, Recall: 98.94%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0630, Average Validation Loss: 0.0358, Accuracy: 99.31%, Precision: 99.90%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0864, Average Validation Loss: 0.0299, Accuracy: 99.26%, Precision: 99.61%, Recall: 99.11%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0399, Average Validation Loss: 0.0309, Accuracy: 99.26%, Precision: 99.56%, Recall: 99.14%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0474, Average Validation Loss: 0.0292, Accuracy: 99.33%, Precision: 99.94%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0424, Average Validation Loss: 0.0278, Accuracy: 99.38%, Precision: 99.77%, Recall: 99.15%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0624, Average Validation Loss: 0.0384, Accuracy: 99.03%, Precision: 99.05%, Recall: 99.25%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0512, Average Validation Loss: 0.0317, Accuracy: 99.36%, Precision: 99.70%, Recall: 99.18%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0387, Average Validation Loss: 0.0505, Accuracy: 98.99%, Precision: 100.00%, Recall: 98.27%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0326, Average Validation Loss: 0.0286, Accuracy: 99.38%, Precision: 99.99%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0577, Average Validation Loss: 0.0312, Accuracy: 99.39%, Precision: 99.98%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:08:49,186] Trial 1 finished with value: 0.031172359065542853 and parameters: {'vector_length': 1024, 'num_layers': 2, 'layer_size': 512, 'dropout': 0.30000000000000004, 'num_epochs': 4, 'lr': 0.0004224978088566638, 'weight_decay': 5.832566444236443e-05, 'warmup_steps': 80}. Best is trial 1 with value: 0.031172359065542853.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 6, with 27,279,616 parameters\n","Num non-decayed parameter tensors: 5, with 258 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6848, Average Validation Loss: 0.6734, Accuracy: 63.50%, Precision: 100.00%, Recall: 61.04%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6508, Average Validation Loss: 0.6219, Accuracy: 80.55%, Precision: 100.00%, Recall: 74.62%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.6285, Average Validation Loss: 0.5770, Accuracy: 89.66%, Precision: 100.00%, Recall: 84.69%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.5944, Average Validation Loss: 0.5409, Accuracy: 93.37%, Precision: 100.00%, Recall: 89.61%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.5827, Average Validation Loss: 0.5152, Accuracy: 94.70%, Precision: 100.00%, Recall: 91.52%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.5538, Average Validation Loss: 0.4874, Accuracy: 95.84%, Precision: 100.00%, Recall: 93.22%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.5428, Average Validation Loss: 0.4595, Accuracy: 96.71%, Precision: 100.00%, Recall: 94.56%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.5189, Average Validation Loss: 0.4347, Accuracy: 97.45%, Precision: 100.00%, Recall: 95.73%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.4899, Average Validation Loss: 0.4063, Accuracy: 97.45%, Precision: 100.00%, Recall: 95.73%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.4848, Average Validation Loss: 0.3868, Accuracy: 98.23%, Precision: 100.00%, Recall: 97.00%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.4704, Average Validation Loss: 0.3710, Accuracy: 98.14%, Precision: 100.00%, Recall: 96.85%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.4716, Average Validation Loss: 0.3513, Accuracy: 98.20%, Precision: 100.00%, Recall: 96.94%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.4446, Average Validation Loss: 0.3348, Accuracy: 98.45%, Precision: 100.00%, Recall: 97.36%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.4502, Average Validation Loss: 0.3223, Accuracy: 98.49%, Precision: 100.00%, Recall: 97.43%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.4207, Average Validation Loss: 0.3055, Accuracy: 98.55%, Precision: 100.00%, Recall: 97.53%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.4107, Average Validation Loss: 0.2864, Accuracy: 98.57%, Precision: 100.00%, Recall: 97.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.4174, Average Validation Loss: 0.2690, Accuracy: 98.59%, Precision: 100.00%, Recall: 97.59%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.4266, Average Validation Loss: 0.2580, Accuracy: 98.65%, Precision: 100.00%, Recall: 97.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3933, Average Validation Loss: 0.2489, Accuracy: 98.69%, Precision: 100.00%, Recall: 97.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.4021, Average Validation Loss: 0.2420, Accuracy: 98.77%, Precision: 100.00%, Recall: 97.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3690, Average Validation Loss: 0.2305, Accuracy: 98.66%, Precision: 100.00%, Recall: 97.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3781, Average Validation Loss: 0.2197, Accuracy: 98.64%, Precision: 100.00%, Recall: 97.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3754, Average Validation Loss: 0.2108, Accuracy: 98.83%, Precision: 100.00%, Recall: 97.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3359, Average Validation Loss: 0.2008, Accuracy: 98.93%, Precision: 100.00%, Recall: 98.17%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3350, Average Validation Loss: 0.1905, Accuracy: 98.79%, Precision: 100.00%, Recall: 97.92%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3392, Average Validation Loss: 0.1798, Accuracy: 98.77%, Precision: 100.00%, Recall: 97.90%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3147, Average Validation Loss: 0.1636, Accuracy: 98.89%, Precision: 100.00%, Recall: 98.10%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3010, Average Validation Loss: 0.1544, Accuracy: 98.91%, Precision: 100.00%, Recall: 98.13%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3302, Average Validation Loss: 0.1494, Accuracy: 98.94%, Precision: 100.00%, Recall: 98.19%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3249, Average Validation Loss: 0.1465, Accuracy: 98.97%, Precision: 100.00%, Recall: 98.24%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3093, Average Validation Loss: 0.1409, Accuracy: 98.99%, Precision: 100.00%, Recall: 98.26%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2997, Average Validation Loss: 0.1318, Accuracy: 98.98%, Precision: 100.00%, Recall: 98.25%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2795, Average Validation Loss: 0.1248, Accuracy: 98.98%, Precision: 100.00%, Recall: 98.24%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2802, Average Validation Loss: 0.1151, Accuracy: 99.06%, Precision: 100.00%, Recall: 98.38%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2402, Average Validation Loss: 0.1075, Accuracy: 99.07%, Precision: 100.00%, Recall: 98.40%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2591, Average Validation Loss: 0.1016, Accuracy: 99.06%, Precision: 100.00%, Recall: 98.39%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2440, Average Validation Loss: 0.0927, Accuracy: 99.10%, Precision: 100.00%, Recall: 98.45%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2438, Average Validation Loss: 0.0849, Accuracy: 99.11%, Precision: 100.00%, Recall: 98.47%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2341, Average Validation Loss: 0.0813, Accuracy: 99.12%, Precision: 100.00%, Recall: 98.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2159, Average Validation Loss: 0.0765, Accuracy: 99.12%, Precision: 100.00%, Recall: 98.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2162, Average Validation Loss: 0.0720, Accuracy: 99.15%, Precision: 100.00%, Recall: 98.54%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2182, Average Validation Loss: 0.0680, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1999, Average Validation Loss: 0.0648, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1949, Average Validation Loss: 0.0615, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2000, Average Validation Loss: 0.0576, Accuracy: 99.18%, Precision: 100.00%, Recall: 98.59%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1722, Average Validation Loss: 0.0558, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1761, Average Validation Loss: 0.0531, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1853, Average Validation Loss: 0.0497, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1764, Average Validation Loss: 0.0487, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1868, Average Validation Loss: 0.0443, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1734, Average Validation Loss: 0.0430, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1780, Average Validation Loss: 0.0438, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1825, Average Validation Loss: 0.0432, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.1440, Average Validation Loss: 0.0423, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.1705, Average Validation Loss: 0.0401, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1117, Average Validation Loss: 0.0391, Accuracy: 99.26%, Precision: 100.00%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1394, Average Validation Loss: 0.0389, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1262, Average Validation Loss: 0.0391, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.1284, Average Validation Loss: 0.0412, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.1194, Average Validation Loss: 0.0404, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.67%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.1808, Average Validation Loss: 0.0380, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1279, Average Validation Loss: 0.0366, Accuracy: 99.29%, Precision: 100.00%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1317, Average Validation Loss: 0.0345, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1184, Average Validation Loss: 0.0351, Accuracy: 99.29%, Precision: 100.00%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1203, Average Validation Loss: 0.0349, Accuracy: 99.29%, Precision: 100.00%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.1138, Average Validation Loss: 0.0348, Accuracy: 99.30%, Precision: 100.00%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.1145, Average Validation Loss: 0.0352, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.1241, Average Validation Loss: 0.0327, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0990, Average Validation Loss: 0.0329, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1056, Average Validation Loss: 0.0327, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.1058, Average Validation Loss: 0.0325, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.1022, Average Validation Loss: 0.0334, Accuracy: 99.33%, Precision: 100.00%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.1074, Average Validation Loss: 0.0339, Accuracy: 99.33%, Precision: 100.00%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:15:12,308] Trial 2 finished with value: 0.033903507590042174 and parameters: {'vector_length': 1024, 'num_layers': 4, 'layer_size': 64, 'dropout': 0.5, 'num_epochs': 5, 'lr': 1.955213376771193e-05, 'weight_decay': 3.880830286912796e-06, 'warmup_steps': 80}. Best is trial 1 with value: 0.031172359065542853.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 18,114,688 parameters\n","Num non-decayed parameter tensors: 2, with 514 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6426, Average Validation Loss: 0.5888, Accuracy: 61.79%, Precision: 100.00%, Recall: 59.95%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5519, Average Validation Loss: 0.4983, Accuracy: 82.75%, Precision: 100.00%, Recall: 76.83%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.4582, Average Validation Loss: 0.4178, Accuracy: 95.45%, Precision: 99.99%, Recall: 92.64%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3805, Average Validation Loss: 0.3442, Accuracy: 96.24%, Precision: 99.99%, Recall: 93.84%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3132, Average Validation Loss: 0.2806, Accuracy: 97.33%, Precision: 99.99%, Recall: 95.54%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2531, Average Validation Loss: 0.2257, Accuracy: 98.16%, Precision: 99.98%, Recall: 96.91%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2000, Average Validation Loss: 0.1799, Accuracy: 98.49%, Precision: 99.98%, Recall: 97.45%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1695, Average Validation Loss: 0.1427, Accuracy: 98.85%, Precision: 99.97%, Recall: 98.06%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1345, Average Validation Loss: 0.1152, Accuracy: 99.04%, Precision: 99.97%, Recall: 98.38%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1116, Average Validation Loss: 0.0944, Accuracy: 99.18%, Precision: 99.96%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0835, Average Validation Loss: 0.0790, Accuracy: 99.19%, Precision: 99.96%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0703, Average Validation Loss: 0.0680, Accuracy: 99.23%, Precision: 99.96%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0630, Average Validation Loss: 0.0600, Accuracy: 99.25%, Precision: 99.96%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0616, Average Validation Loss: 0.0544, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0653, Average Validation Loss: 0.0500, Accuracy: 99.28%, Precision: 99.98%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0582, Average Validation Loss: 0.0464, Accuracy: 99.29%, Precision: 99.98%, Recall: 98.79%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0486, Average Validation Loss: 0.0436, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0440, Average Validation Loss: 0.0413, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0427, Average Validation Loss: 0.0394, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0359, Average Validation Loss: 0.0379, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0464, Average Validation Loss: 0.0367, Accuracy: 99.34%, Precision: 99.98%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0423, Average Validation Loss: 0.0354, Accuracy: 99.35%, Precision: 99.97%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0289, Average Validation Loss: 0.0341, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0253, Average Validation Loss: 0.0335, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0393, Average Validation Loss: 0.0328, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0272, Average Validation Loss: 0.0322, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0406, Average Validation Loss: 0.0312, Accuracy: 99.36%, Precision: 99.98%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0306, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0264, Average Validation Loss: 0.0302, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0399, Average Validation Loss: 0.0297, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0283, Average Validation Loss: 0.0299, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0347, Average Validation Loss: 0.0288, Accuracy: 99.37%, Precision: 99.99%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0329, Average Validation Loss: 0.0287, Accuracy: 99.39%, Precision: 99.97%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0304, Average Validation Loss: 0.0281, Accuracy: 99.38%, Precision: 99.97%, Recall: 98.95%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0302, Average Validation Loss: 0.0277, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0166, Average Validation Loss: 0.0278, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0195, Average Validation Loss: 0.0283, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0268, Average Validation Loss: 0.0269, Accuracy: 99.37%, Precision: 99.99%, Recall: 98.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0209, Average Validation Loss: 0.0265, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0318, Average Validation Loss: 0.0262, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0311, Average Validation Loss: 0.0260, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0344, Average Validation Loss: 0.0260, Accuracy: 99.42%, Precision: 99.96%, Recall: 99.03%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0305, Average Validation Loss: 0.0254, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.95%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0131, Average Validation Loss: 0.0264, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0320, Average Validation Loss: 0.0254, Accuracy: 99.37%, Precision: 99.99%, Recall: 98.92%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0186, Average Validation Loss: 0.0248, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0225, Average Validation Loss: 0.0246, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0275, Average Validation Loss: 0.0244, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:19:08,585] Trial 3 finished with value: 0.024416507828376583 and parameters: {'vector_length': 128, 'num_layers': 1, 'layer_size': 512, 'dropout': 0.1, 'num_epochs': 4, 'lr': 6.669732474227777e-06, 'weight_decay': 5.895154573238439e-06, 'warmup_steps': 90}. Best is trial 3 with value: 0.024416507828376583.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 6, with 73,165,312 parameters\n","Num non-decayed parameter tensors: 5, with 2,050 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6896, Average Validation Loss: 0.6856, Accuracy: 58.09%, Precision: 100.00%, Recall: 57.71%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6831, Average Validation Loss: 0.6755, Accuracy: 59.39%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6688, Average Validation Loss: 0.6587, Accuracy: 61.34%, Precision: 100.00%, Recall: 59.67%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6477, Average Validation Loss: 0.6304, Accuracy: 62.71%, Precision: 100.00%, Recall: 60.53%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6124, Average Validation Loss: 0.5891, Accuracy: 64.40%, Precision: 100.00%, Recall: 61.64%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5685, Average Validation Loss: 0.5372, Accuracy: 68.61%, Precision: 100.00%, Recall: 64.56%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5106, Average Validation Loss: 0.4788, Accuracy: 80.16%, Precision: 100.00%, Recall: 74.25%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.4701, Average Validation Loss: 0.4181, Accuracy: 91.76%, Precision: 100.00%, Recall: 87.40%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.3984, Average Validation Loss: 0.3581, Accuracy: 93.83%, Precision: 100.00%, Recall: 90.27%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3538, Average Validation Loss: 0.3015, Accuracy: 95.81%, Precision: 99.99%, Recall: 93.17%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2965, Average Validation Loss: 0.2502, Accuracy: 97.09%, Precision: 99.99%, Recall: 95.17%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2526, Average Validation Loss: 0.2045, Accuracy: 98.23%, Precision: 99.98%, Recall: 97.01%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2208, Average Validation Loss: 0.1657, Accuracy: 98.84%, Precision: 99.96%, Recall: 98.05%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1778, Average Validation Loss: 0.1334, Accuracy: 99.04%, Precision: 99.94%, Recall: 98.41%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1563, Average Validation Loss: 0.1071, Accuracy: 99.09%, Precision: 99.95%, Recall: 98.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1177, Average Validation Loss: 0.0871, Accuracy: 99.10%, Precision: 99.96%, Recall: 98.49%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1124, Average Validation Loss: 0.0713, Accuracy: 99.18%, Precision: 99.95%, Recall: 98.64%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0776, Average Validation Loss: 0.0602, Accuracy: 99.22%, Precision: 99.93%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0761, Average Validation Loss: 0.0528, Accuracy: 99.22%, Precision: 99.96%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0609, Average Validation Loss: 0.0476, Accuracy: 99.23%, Precision: 99.96%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0789, Average Validation Loss: 0.0432, Accuracy: 99.24%, Precision: 99.91%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0611, Average Validation Loss: 0.0404, Accuracy: 99.26%, Precision: 99.87%, Recall: 98.85%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0485, Average Validation Loss: 0.0383, Accuracy: 99.25%, Precision: 99.90%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0465, Average Validation Loss: 0.0371, Accuracy: 99.26%, Precision: 99.94%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0601, Average Validation Loss: 0.0358, Accuracy: 99.27%, Precision: 99.95%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0573, Average Validation Loss: 0.0339, Accuracy: 99.28%, Precision: 99.89%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0432, Average Validation Loss: 0.0332, Accuracy: 99.29%, Precision: 99.92%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0430, Average Validation Loss: 0.0333, Accuracy: 99.28%, Precision: 99.95%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0487, Average Validation Loss: 0.0325, Accuracy: 99.29%, Precision: 99.95%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0394, Average Validation Loss: 0.0317, Accuracy: 99.30%, Precision: 99.95%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0392, Average Validation Loss: 0.0315, Accuracy: 99.30%, Precision: 99.95%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0428, Average Validation Loss: 0.0315, Accuracy: 99.30%, Precision: 99.95%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0349, Average Validation Loss: 0.0300, Accuracy: 99.32%, Precision: 99.95%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0434, Average Validation Loss: 0.0302, Accuracy: 99.32%, Precision: 99.95%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0286, Average Validation Loss: 0.0291, Accuracy: 99.32%, Precision: 99.93%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0402, Average Validation Loss: 0.0295, Accuracy: 99.32%, Precision: 99.95%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0386, Average Validation Loss: 0.0300, Accuracy: 99.32%, Precision: 99.96%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0359, Average Validation Loss: 0.0295, Accuracy: 99.33%, Precision: 99.95%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:22:25,949] Trial 4 finished with value: 0.029569815636637645 and parameters: {'vector_length': 512, 'num_layers': 4, 'layer_size': 512, 'dropout': 0.30000000000000004, 'num_epochs': 3, 'lr': 3.862291825859076e-06, 'weight_decay': 1.7162322879412439e-06, 'warmup_steps': 50}. Best is trial 3 with value: 0.024416507828376583.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 5,528,192 parameters\n","Num non-decayed parameter tensors: 3, with 258 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6842, Average Validation Loss: 0.6816, Accuracy: 58.14%, Precision: 99.99%, Recall: 57.74%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6782, Average Validation Loss: 0.6738, Accuracy: 58.34%, Precision: 99.99%, Recall: 57.86%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6674, Average Validation Loss: 0.6659, Accuracy: 58.59%, Precision: 99.99%, Recall: 58.01%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6634, Average Validation Loss: 0.6578, Accuracy: 58.99%, Precision: 99.99%, Recall: 58.24%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6567, Average Validation Loss: 0.6495, Accuracy: 59.65%, Precision: 99.99%, Recall: 58.64%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6486, Average Validation Loss: 0.6408, Accuracy: 60.60%, Precision: 99.99%, Recall: 59.21%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6332, Average Validation Loss: 0.6316, Accuracy: 61.36%, Precision: 100.00%, Recall: 59.68%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6280, Average Validation Loss: 0.6221, Accuracy: 61.99%, Precision: 100.00%, Recall: 60.07%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6087, Average Validation Loss: 0.6117, Accuracy: 62.53%, Precision: 100.00%, Recall: 60.41%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6056, Average Validation Loss: 0.6010, Accuracy: 63.25%, Precision: 100.00%, Recall: 60.88%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5924, Average Validation Loss: 0.5897, Accuracy: 64.13%, Precision: 100.00%, Recall: 61.45%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5789, Average Validation Loss: 0.5776, Accuracy: 64.93%, Precision: 100.00%, Recall: 61.99%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5813, Average Validation Loss: 0.5652, Accuracy: 66.01%, Precision: 100.00%, Recall: 62.72%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5559, Average Validation Loss: 0.5521, Accuracy: 67.58%, Precision: 100.00%, Recall: 63.82%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5588, Average Validation Loss: 0.5384, Accuracy: 69.73%, Precision: 100.00%, Recall: 65.39%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5384, Average Validation Loss: 0.5242, Accuracy: 72.34%, Precision: 100.00%, Recall: 67.40%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5149, Average Validation Loss: 0.5096, Accuracy: 74.54%, Precision: 100.00%, Recall: 69.19%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.4954, Average Validation Loss: 0.4950, Accuracy: 76.17%, Precision: 100.00%, Recall: 70.58%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.4886, Average Validation Loss: 0.4799, Accuracy: 78.80%, Precision: 100.00%, Recall: 72.95%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.4764, Average Validation Loss: 0.4646, Accuracy: 81.86%, Precision: 100.00%, Recall: 75.92%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4545, Average Validation Loss: 0.4492, Accuracy: 85.20%, Precision: 100.00%, Recall: 79.44%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.4545, Average Validation Loss: 0.4334, Accuracy: 88.46%, Precision: 100.00%, Recall: 83.22%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.4293, Average Validation Loss: 0.4177, Accuracy: 91.38%, Precision: 100.00%, Recall: 86.90%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4169, Average Validation Loss: 0.4026, Accuracy: 92.95%, Precision: 99.99%, Recall: 89.03%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.3982, Average Validation Loss: 0.3865, Accuracy: 94.12%, Precision: 99.99%, Recall: 90.69%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3800, Average Validation Loss: 0.3712, Accuracy: 94.71%, Precision: 99.99%, Recall: 91.54%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3763, Average Validation Loss: 0.3566, Accuracy: 95.34%, Precision: 99.98%, Recall: 92.49%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3536, Average Validation Loss: 0.3420, Accuracy: 95.86%, Precision: 99.98%, Recall: 93.27%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3479, Average Validation Loss: 0.3280, Accuracy: 96.51%, Precision: 99.98%, Recall: 94.27%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3288, Average Validation Loss: 0.3135, Accuracy: 96.97%, Precision: 99.97%, Recall: 95.00%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3056, Average Validation Loss: 0.3003, Accuracy: 97.01%, Precision: 99.97%, Recall: 95.06%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3028, Average Validation Loss: 0.2878, Accuracy: 97.03%, Precision: 99.98%, Recall: 95.08%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2932, Average Validation Loss: 0.2751, Accuracy: 97.18%, Precision: 99.98%, Recall: 95.31%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2851, Average Validation Loss: 0.2633, Accuracy: 97.50%, Precision: 99.98%, Recall: 95.83%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2670, Average Validation Loss: 0.2513, Accuracy: 97.82%, Precision: 99.96%, Recall: 96.36%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2469, Average Validation Loss: 0.2397, Accuracy: 98.02%, Precision: 99.95%, Recall: 96.70%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2442, Average Validation Loss: 0.2293, Accuracy: 98.13%, Precision: 99.95%, Recall: 96.89%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2222, Average Validation Loss: 0.2191, Accuracy: 98.19%, Precision: 99.97%, Recall: 96.96%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2131, Average Validation Loss: 0.2096, Accuracy: 98.21%, Precision: 99.98%, Recall: 96.99%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2091, Average Validation Loss: 0.1997, Accuracy: 98.29%, Precision: 99.97%, Recall: 97.13%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2076, Average Validation Loss: 0.1907, Accuracy: 98.39%, Precision: 99.97%, Recall: 97.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1918, Average Validation Loss: 0.1815, Accuracy: 98.56%, Precision: 99.96%, Recall: 97.59%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1953, Average Validation Loss: 0.1734, Accuracy: 98.69%, Precision: 99.95%, Recall: 97.82%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1741, Average Validation Loss: 0.1656, Accuracy: 98.74%, Precision: 99.96%, Recall: 97.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1682, Average Validation Loss: 0.1586, Accuracy: 98.80%, Precision: 99.96%, Recall: 97.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1575, Average Validation Loss: 0.1513, Accuracy: 98.89%, Precision: 99.96%, Recall: 98.14%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1513, Average Validation Loss: 0.1446, Accuracy: 98.93%, Precision: 99.96%, Recall: 98.21%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1449, Average Validation Loss: 0.1385, Accuracy: 98.94%, Precision: 99.96%, Recall: 98.22%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1434, Average Validation Loss: 0.1323, Accuracy: 98.96%, Precision: 99.97%, Recall: 98.24%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1327, Average Validation Loss: 0.1267, Accuracy: 98.97%, Precision: 99.97%, Recall: 98.26%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1322, Average Validation Loss: 0.1211, Accuracy: 99.00%, Precision: 99.97%, Recall: 98.32%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1225, Average Validation Loss: 0.1160, Accuracy: 99.02%, Precision: 99.97%, Recall: 98.35%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1278, Average Validation Loss: 0.1113, Accuracy: 99.05%, Precision: 99.96%, Recall: 98.40%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1193, Average Validation Loss: 0.1070, Accuracy: 99.10%, Precision: 99.96%, Recall: 98.49%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1271, Average Validation Loss: 0.1029, Accuracy: 99.12%, Precision: 99.96%, Recall: 98.53%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1037, Average Validation Loss: 0.0993, Accuracy: 99.13%, Precision: 99.96%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0966, Average Validation Loss: 0.0954, Accuracy: 99.13%, Precision: 99.97%, Recall: 98.54%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1039, Average Validation Loss: 0.0923, Accuracy: 99.14%, Precision: 99.97%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0976, Average Validation Loss: 0.0895, Accuracy: 99.16%, Precision: 99.97%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0897, Average Validation Loss: 0.0864, Accuracy: 99.16%, Precision: 99.98%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0919, Average Validation Loss: 0.0837, Accuracy: 99.15%, Precision: 99.98%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0931, Average Validation Loss: 0.0812, Accuracy: 99.16%, Precision: 99.98%, Recall: 98.58%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0900, Average Validation Loss: 0.0789, Accuracy: 99.19%, Precision: 99.98%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0778, Average Validation Loss: 0.0766, Accuracy: 99.19%, Precision: 99.98%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0828, Average Validation Loss: 0.0745, Accuracy: 99.19%, Precision: 99.98%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0837, Average Validation Loss: 0.0725, Accuracy: 99.21%, Precision: 99.98%, Recall: 98.65%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0900, Average Validation Loss: 0.0707, Accuracy: 99.22%, Precision: 99.98%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0727, Average Validation Loss: 0.0692, Accuracy: 99.22%, Precision: 99.97%, Recall: 98.69%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0710, Average Validation Loss: 0.0673, Accuracy: 99.22%, Precision: 99.98%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0777, Average Validation Loss: 0.0658, Accuracy: 99.23%, Precision: 99.98%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0689, Average Validation Loss: 0.0643, Accuracy: 99.24%, Precision: 99.97%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0672, Average Validation Loss: 0.0629, Accuracy: 99.25%, Precision: 99.98%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0785, Average Validation Loss: 0.0615, Accuracy: 99.25%, Precision: 99.98%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0677, Average Validation Loss: 0.0602, Accuracy: 99.25%, Precision: 99.98%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0595, Average Validation Loss: 0.0589, Accuracy: 99.25%, Precision: 99.98%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0555, Average Validation Loss: 0.0578, Accuracy: 99.24%, Precision: 99.98%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0607, Average Validation Loss: 0.0568, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0601, Average Validation Loss: 0.0558, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0534, Average Validation Loss: 0.0547, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0679, Average Validation Loss: 0.0537, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0677, Average Validation Loss: 0.0527, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0656, Average Validation Loss: 0.0519, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.74%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0498, Average Validation Loss: 0.0513, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0566, Average Validation Loss: 0.0502, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0683, Average Validation Loss: 0.0495, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.76%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0574, Average Validation Loss: 0.0488, Accuracy: 99.28%, Precision: 99.98%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0593, Average Validation Loss: 0.0481, Accuracy: 99.29%, Precision: 99.98%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0635, Average Validation Loss: 0.0474, Accuracy: 99.29%, Precision: 99.98%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0565, Average Validation Loss: 0.0468, Accuracy: 99.29%, Precision: 99.98%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0441, Average Validation Loss: 0.0462, Accuracy: 99.29%, Precision: 99.98%, Recall: 98.79%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0462, Average Validation Loss: 0.0456, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0510, Average Validation Loss: 0.0455, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0634, Average Validation Loss: 0.0447, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0615, Average Validation Loss: 0.0440, Accuracy: 99.30%, Precision: 99.98%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0559, Average Validation Loss: 0.0434, Accuracy: 99.30%, Precision: 99.98%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0434, Average Validation Loss: 0.0429, Accuracy: 99.30%, Precision: 99.98%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0455, Average Validation Loss: 0.0425, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0463, Average Validation Loss: 0.0425, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0417, Average Validation Loss: 0.0421, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0512, Average Validation Loss: 0.0413, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0392, Average Validation Loss: 0.0408, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0403, Average Validation Loss: 0.0403, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0484, Average Validation Loss: 0.0399, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0417, Average Validation Loss: 0.0395, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0452, Average Validation Loss: 0.0391, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0351, Average Validation Loss: 0.0388, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0441, Average Validation Loss: 0.0386, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0326, Average Validation Loss: 0.0387, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0447, Average Validation Loss: 0.0380, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0421, Average Validation Loss: 0.0376, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0333, Average Validation Loss: 0.0379, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0399, Average Validation Loss: 0.0370, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0364, Average Validation Loss: 0.0367, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0348, Average Validation Loss: 0.0365, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0384, Average Validation Loss: 0.0361, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0390, Average Validation Loss: 0.0368, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0405, Average Validation Loss: 0.0355, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0376, Average Validation Loss: 0.0352, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0410, Average Validation Loss: 0.0351, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0428, Average Validation Loss: 0.0346, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.0349, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0406, Average Validation Loss: 0.0342, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0449, Average Validation Loss: 0.0339, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0407, Average Validation Loss: 0.0337, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0332, Average Validation Loss: 0.0335, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0335, Average Validation Loss: 0.0341, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0348, Average Validation Loss: 0.0333, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:32:43,917] Trial 5 finished with value: 0.03322683662377499 and parameters: {'vector_length': 128, 'num_layers': 2, 'layer_size': 128, 'dropout': 0.1, 'num_epochs': 1, 'lr': 2.661363222780671e-06, 'weight_decay': 7.419077258137341e-05, 'warmup_steps': 60}. Best is trial 3 with value: 0.024416507828376583.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 144,993,280 parameters\n","Num non-decayed parameter tensors: 3, with 1,026 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2518, Average Validation Loss: 0.0543, Accuracy: 99.05%, Precision: 99.99%, Recall: 98.38%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0576, Average Validation Loss: 0.0599, Accuracy: 99.12%, Precision: 99.99%, Recall: 98.50%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0584, Average Validation Loss: 0.0450, Accuracy: 99.20%, Precision: 99.99%, Recall: 98.64%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0549, Average Validation Loss: 0.0312, Accuracy: 99.32%, Precision: 99.86%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0318, Average Validation Loss: 0.0486, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0666, Average Validation Loss: 0.0333, Accuracy: 99.27%, Precision: 99.96%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0430, Average Validation Loss: 0.0312, Accuracy: 99.26%, Precision: 99.96%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0524, Average Validation Loss: 0.0254, Accuracy: 99.37%, Precision: 99.93%, Recall: 98.97%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0423, Average Validation Loss: 0.0304, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0383, Average Validation Loss: 0.0268, Accuracy: 99.39%, Precision: 99.96%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0294, Average Validation Loss: 0.0233, Accuracy: 99.42%, Precision: 99.90%, Recall: 99.10%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0548, Average Validation Loss: 0.0235, Accuracy: 99.44%, Precision: 99.90%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0295, Average Validation Loss: 0.0285, Accuracy: 99.38%, Precision: 99.97%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0391, Average Validation Loss: 0.0290, Accuracy: 99.38%, Precision: 99.96%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0232, Average Validation Loss: 0.0285, Accuracy: 99.39%, Precision: 99.97%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0462, Average Validation Loss: 0.0219, Accuracy: 99.46%, Precision: 99.96%, Recall: 99.10%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0324, Average Validation Loss: 0.0264, Accuracy: 99.41%, Precision: 99.98%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0328, Average Validation Loss: 0.0258, Accuracy: 99.41%, Precision: 99.98%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0347, Average Validation Loss: 0.0213, Accuracy: 99.49%, Precision: 99.94%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0402, Average Validation Loss: 0.0330, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0309, Average Validation Loss: 0.0224, Accuracy: 99.44%, Precision: 99.93%, Recall: 99.11%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:34:40,239] Trial 6 finished with value: 0.022466586580550348 and parameters: {'vector_length': 1024, 'num_layers': 2, 'layer_size': 512, 'dropout': 0.4, 'num_epochs': 4, 'lr': 0.00010074901065788951, 'weight_decay': 3.005640827982952e-06, 'warmup_steps': 80}. Best is trial 6 with value: 0.022466586580550348.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 3,415,424 parameters\n","Num non-decayed parameter tensors: 3, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6959, Average Validation Loss: 0.6915, Accuracy: 43.45%, Precision: 2.07%, Recall: 68.72%, F1: 0.04\n","Epoch 0, Average Training Loss: 0.6888, Average Validation Loss: 0.6866, Accuracy: 47.77%, Precision: 10.26%, Recall: 86.60%, F1: 0.18\n","Epoch 0, Average Training Loss: 0.6865, Average Validation Loss: 0.6816, Accuracy: 60.66%, Precision: 34.16%, Recall: 92.06%, F1: 0.50\n","Epoch 0, Average Training Loss: 0.6800, Average Validation Loss: 0.6768, Accuracy: 78.29%, Precision: 67.33%, Recall: 92.70%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.6734, Average Validation Loss: 0.6721, Accuracy: 89.24%, Precision: 89.19%, Recall: 91.77%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.6696, Average Validation Loss: 0.6672, Accuracy: 92.09%, Precision: 97.77%, Recall: 89.40%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.6651, Average Validation Loss: 0.6625, Accuracy: 91.00%, Precision: 99.41%, Recall: 86.78%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.6605, Average Validation Loss: 0.6575, Accuracy: 88.85%, Precision: 99.79%, Recall: 83.80%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.6574, Average Validation Loss: 0.6526, Accuracy: 88.16%, Precision: 99.90%, Recall: 82.90%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.6516, Average Validation Loss: 0.6477, Accuracy: 88.15%, Precision: 99.95%, Recall: 82.87%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.6478, Average Validation Loss: 0.6424, Accuracy: 88.44%, Precision: 99.96%, Recall: 83.20%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.6396, Average Validation Loss: 0.6369, Accuracy: 87.95%, Precision: 99.97%, Recall: 82.61%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.6329, Average Validation Loss: 0.6312, Accuracy: 86.99%, Precision: 99.99%, Recall: 81.47%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.6275, Average Validation Loss: 0.6251, Accuracy: 85.64%, Precision: 99.99%, Recall: 79.94%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.6220, Average Validation Loss: 0.6188, Accuracy: 84.19%, Precision: 99.99%, Recall: 78.35%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.6179, Average Validation Loss: 0.6126, Accuracy: 83.41%, Precision: 100.00%, Recall: 77.52%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.6091, Average Validation Loss: 0.6059, Accuracy: 83.42%, Precision: 100.00%, Recall: 77.53%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.6013, Average Validation Loss: 0.5990, Accuracy: 83.23%, Precision: 100.00%, Recall: 77.32%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.5962, Average Validation Loss: 0.5919, Accuracy: 82.59%, Precision: 100.00%, Recall: 76.66%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.5916, Average Validation Loss: 0.5847, Accuracy: 82.60%, Precision: 100.00%, Recall: 76.67%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.5823, Average Validation Loss: 0.5771, Accuracy: 83.37%, Precision: 100.00%, Recall: 77.47%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.5788, Average Validation Loss: 0.5693, Accuracy: 83.98%, Precision: 100.00%, Recall: 78.12%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.5640, Average Validation Loss: 0.5612, Accuracy: 84.41%, Precision: 100.00%, Recall: 78.58%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.5615, Average Validation Loss: 0.5531, Accuracy: 85.24%, Precision: 100.00%, Recall: 79.49%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.5551, Average Validation Loss: 0.5448, Accuracy: 86.28%, Precision: 100.00%, Recall: 80.65%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.5460, Average Validation Loss: 0.5360, Accuracy: 87.37%, Precision: 100.00%, Recall: 81.92%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.5295, Average Validation Loss: 0.5273, Accuracy: 88.07%, Precision: 100.00%, Recall: 82.74%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.5258, Average Validation Loss: 0.5183, Accuracy: 88.91%, Precision: 100.00%, Recall: 83.75%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.5201, Average Validation Loss: 0.5093, Accuracy: 89.73%, Precision: 100.00%, Recall: 84.78%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.5132, Average Validation Loss: 0.5001, Accuracy: 90.47%, Precision: 100.00%, Recall: 85.72%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.4987, Average Validation Loss: 0.4909, Accuracy: 91.16%, Precision: 100.00%, Recall: 86.61%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4990, Average Validation Loss: 0.4816, Accuracy: 92.03%, Precision: 100.00%, Recall: 87.77%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4806, Average Validation Loss: 0.4724, Accuracy: 92.64%, Precision: 100.00%, Recall: 88.59%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4818, Average Validation Loss: 0.4633, Accuracy: 93.05%, Precision: 100.00%, Recall: 89.17%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4687, Average Validation Loss: 0.4538, Accuracy: 93.53%, Precision: 100.00%, Recall: 89.84%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4614, Average Validation Loss: 0.4445, Accuracy: 94.08%, Precision: 100.00%, Recall: 90.61%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4558, Average Validation Loss: 0.4351, Accuracy: 94.48%, Precision: 100.00%, Recall: 91.20%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4480, Average Validation Loss: 0.4259, Accuracy: 95.04%, Precision: 100.00%, Recall: 92.02%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.4269, Average Validation Loss: 0.4161, Accuracy: 95.37%, Precision: 100.00%, Recall: 92.51%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.4322, Average Validation Loss: 0.4069, Accuracy: 95.58%, Precision: 100.00%, Recall: 92.82%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.4166, Average Validation Loss: 0.3980, Accuracy: 95.81%, Precision: 100.00%, Recall: 93.18%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.4068, Average Validation Loss: 0.3887, Accuracy: 95.96%, Precision: 100.00%, Recall: 93.40%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.4009, Average Validation Loss: 0.3797, Accuracy: 96.12%, Precision: 100.00%, Recall: 93.65%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3911, Average Validation Loss: 0.3711, Accuracy: 96.23%, Precision: 100.00%, Recall: 93.82%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3873, Average Validation Loss: 0.3624, Accuracy: 96.42%, Precision: 100.00%, Recall: 94.11%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3785, Average Validation Loss: 0.3538, Accuracy: 96.64%, Precision: 100.00%, Recall: 94.45%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3733, Average Validation Loss: 0.3452, Accuracy: 96.86%, Precision: 100.00%, Recall: 94.80%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3637, Average Validation Loss: 0.3370, Accuracy: 96.98%, Precision: 100.00%, Recall: 94.99%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3513, Average Validation Loss: 0.3289, Accuracy: 97.09%, Precision: 100.00%, Recall: 95.15%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3534, Average Validation Loss: 0.3207, Accuracy: 97.31%, Precision: 100.00%, Recall: 95.51%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3423, Average Validation Loss: 0.3130, Accuracy: 97.54%, Precision: 99.99%, Recall: 95.88%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3296, Average Validation Loss: 0.3054, Accuracy: 97.61%, Precision: 99.99%, Recall: 96.00%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3346, Average Validation Loss: 0.2981, Accuracy: 97.72%, Precision: 99.99%, Recall: 96.18%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3216, Average Validation Loss: 0.2906, Accuracy: 97.81%, Precision: 99.99%, Recall: 96.31%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3148, Average Validation Loss: 0.2836, Accuracy: 97.90%, Precision: 99.99%, Recall: 96.47%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3031, Average Validation Loss: 0.2763, Accuracy: 97.96%, Precision: 99.99%, Recall: 96.56%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3028, Average Validation Loss: 0.2700, Accuracy: 97.96%, Precision: 99.99%, Recall: 96.56%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3045, Average Validation Loss: 0.2635, Accuracy: 98.01%, Precision: 99.99%, Recall: 96.65%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2952, Average Validation Loss: 0.2569, Accuracy: 98.21%, Precision: 99.99%, Recall: 96.98%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2777, Average Validation Loss: 0.2506, Accuracy: 98.38%, Precision: 99.99%, Recall: 97.25%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2831, Average Validation Loss: 0.2442, Accuracy: 98.50%, Precision: 99.99%, Recall: 97.46%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2714, Average Validation Loss: 0.2378, Accuracy: 98.51%, Precision: 99.99%, Recall: 97.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2535, Average Validation Loss: 0.2322, Accuracy: 98.52%, Precision: 99.99%, Recall: 97.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2483, Average Validation Loss: 0.2266, Accuracy: 98.50%, Precision: 99.99%, Recall: 97.46%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2525, Average Validation Loss: 0.2212, Accuracy: 98.46%, Precision: 99.99%, Recall: 97.39%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2479, Average Validation Loss: 0.2157, Accuracy: 98.50%, Precision: 99.99%, Recall: 97.46%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2513, Average Validation Loss: 0.2106, Accuracy: 98.52%, Precision: 99.99%, Recall: 97.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2430, Average Validation Loss: 0.2057, Accuracy: 98.61%, Precision: 99.99%, Recall: 97.64%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2408, Average Validation Loss: 0.2005, Accuracy: 98.65%, Precision: 99.99%, Recall: 97.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2349, Average Validation Loss: 0.1958, Accuracy: 98.67%, Precision: 99.99%, Recall: 97.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2195, Average Validation Loss: 0.1911, Accuracy: 98.70%, Precision: 99.99%, Recall: 97.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2274, Average Validation Loss: 0.1867, Accuracy: 98.73%, Precision: 99.99%, Recall: 97.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2181, Average Validation Loss: 0.1820, Accuracy: 98.77%, Precision: 99.99%, Recall: 97.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2193, Average Validation Loss: 0.1781, Accuracy: 98.82%, Precision: 99.99%, Recall: 97.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2151, Average Validation Loss: 0.1734, Accuracy: 98.88%, Precision: 99.98%, Recall: 98.11%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1997, Average Validation Loss: 0.1698, Accuracy: 98.90%, Precision: 99.99%, Recall: 98.13%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2084, Average Validation Loss: 0.1659, Accuracy: 98.91%, Precision: 99.99%, Recall: 98.14%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1976, Average Validation Loss: 0.1620, Accuracy: 98.93%, Precision: 99.99%, Recall: 98.17%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2088, Average Validation Loss: 0.1581, Accuracy: 98.94%, Precision: 99.98%, Recall: 98.20%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1901, Average Validation Loss: 0.1547, Accuracy: 98.95%, Precision: 99.98%, Recall: 98.22%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1963, Average Validation Loss: 0.1513, Accuracy: 98.96%, Precision: 99.98%, Recall: 98.24%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1898, Average Validation Loss: 0.1481, Accuracy: 98.94%, Precision: 99.99%, Recall: 98.19%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1824, Average Validation Loss: 0.1456, Accuracy: 98.96%, Precision: 99.99%, Recall: 98.22%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1811, Average Validation Loss: 0.1417, Accuracy: 98.98%, Precision: 99.99%, Recall: 98.27%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1796, Average Validation Loss: 0.1386, Accuracy: 99.00%, Precision: 99.99%, Recall: 98.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1857, Average Validation Loss: 0.1355, Accuracy: 99.00%, Precision: 99.99%, Recall: 98.30%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1751, Average Validation Loss: 0.1329, Accuracy: 99.01%, Precision: 99.99%, Recall: 98.31%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1659, Average Validation Loss: 0.1299, Accuracy: 99.01%, Precision: 99.99%, Recall: 98.32%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1656, Average Validation Loss: 0.1275, Accuracy: 99.02%, Precision: 99.99%, Recall: 98.32%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1504, Average Validation Loss: 0.1245, Accuracy: 99.02%, Precision: 99.99%, Recall: 98.33%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1478, Average Validation Loss: 0.1220, Accuracy: 99.03%, Precision: 100.00%, Recall: 98.33%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1617, Average Validation Loss: 0.1194, Accuracy: 99.03%, Precision: 100.00%, Recall: 98.33%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1515, Average Validation Loss: 0.1170, Accuracy: 99.03%, Precision: 100.00%, Recall: 98.33%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1570, Average Validation Loss: 0.1145, Accuracy: 99.04%, Precision: 100.00%, Recall: 98.34%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1432, Average Validation Loss: 0.1124, Accuracy: 99.05%, Precision: 100.00%, Recall: 98.37%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1529, Average Validation Loss: 0.1100, Accuracy: 99.06%, Precision: 100.00%, Recall: 98.39%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1463, Average Validation Loss: 0.1078, Accuracy: 99.07%, Precision: 100.00%, Recall: 98.39%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1567, Average Validation Loss: 0.1057, Accuracy: 99.07%, Precision: 100.00%, Recall: 98.40%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1383, Average Validation Loss: 0.1039, Accuracy: 99.07%, Precision: 100.00%, Recall: 98.40%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1434, Average Validation Loss: 0.1019, Accuracy: 99.08%, Precision: 100.00%, Recall: 98.41%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1434, Average Validation Loss: 0.0999, Accuracy: 99.10%, Precision: 100.00%, Recall: 98.45%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1399, Average Validation Loss: 0.0983, Accuracy: 99.12%, Precision: 100.00%, Recall: 98.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1381, Average Validation Loss: 0.0963, Accuracy: 99.12%, Precision: 100.00%, Recall: 98.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1398, Average Validation Loss: 0.0944, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1281, Average Validation Loss: 0.0929, Accuracy: 99.15%, Precision: 99.99%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1202, Average Validation Loss: 0.0909, Accuracy: 99.16%, Precision: 99.99%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1249, Average Validation Loss: 0.0894, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1278, Average Validation Loss: 0.0880, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1250, Average Validation Loss: 0.0869, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1273, Average Validation Loss: 0.0853, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1291, Average Validation Loss: 0.0837, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1216, Average Validation Loss: 0.0824, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1138, Average Validation Loss: 0.0816, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1155, Average Validation Loss: 0.0802, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1123, Average Validation Loss: 0.0792, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1052, Average Validation Loss: 0.0774, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1082, Average Validation Loss: 0.0763, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1028, Average Validation Loss: 0.0751, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1074, Average Validation Loss: 0.0740, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1109, Average Validation Loss: 0.0730, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1025, Average Validation Loss: 0.0722, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0965, Average Validation Loss: 0.0714, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1032, Average Validation Loss: 0.0705, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1073, Average Validation Loss: 0.0692, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1031, Average Validation Loss: 0.0688, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0992, Average Validation Loss: 0.0674, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0855, Average Validation Loss: 0.0665, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0972, Average Validation Loss: 0.0656, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1054, Average Validation Loss: 0.0648, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0960, Average Validation Loss: 0.0640, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0806, Average Validation Loss: 0.0634, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0995, Average Validation Loss: 0.0631, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0901, Average Validation Loss: 0.0620, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1003, Average Validation Loss: 0.0614, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.62%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0951, Average Validation Loss: 0.0606, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0879, Average Validation Loss: 0.0600, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.62%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0867, Average Validation Loss: 0.0594, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0996, Average Validation Loss: 0.0589, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.62%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0870, Average Validation Loss: 0.0583, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0930, Average Validation Loss: 0.0577, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.63%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0787, Average Validation Loss: 0.0575, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.63%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0989, Average Validation Loss: 0.0568, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0867, Average Validation Loss: 0.0559, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.63%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0904, Average Validation Loss: 0.0553, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0901, Average Validation Loss: 0.0548, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1027, Average Validation Loss: 0.0542, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0891, Average Validation Loss: 0.0540, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0234, Average Validation Loss: 0.0538, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0829, Average Validation Loss: 0.0532, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0793, Average Validation Loss: 0.0528, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0794, Average Validation Loss: 0.0525, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0848, Average Validation Loss: 0.0521, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0791, Average Validation Loss: 0.0516, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0775, Average Validation Loss: 0.0512, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0794, Average Validation Loss: 0.0508, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0712, Average Validation Loss: 0.0504, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0734, Average Validation Loss: 0.0502, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0707, Average Validation Loss: 0.0499, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 1, Average Training Loss: 0.0658, Average Validation Loss: 0.0496, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0882, Average Validation Loss: 0.0492, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0685, Average Validation Loss: 0.0488, Accuracy: 99.21%, Precision: 100.00%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0739, Average Validation Loss: 0.0484, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0716, Average Validation Loss: 0.0480, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0721, Average Validation Loss: 0.0476, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0759, Average Validation Loss: 0.0472, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.66%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0722, Average Validation Loss: 0.0468, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.66%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0749, Average Validation Loss: 0.0464, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.66%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0688, Average Validation Loss: 0.0461, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.66%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0629, Average Validation Loss: 0.0458, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.66%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0571, Average Validation Loss: 0.0457, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.66%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0899, Average Validation Loss: 0.0454, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.66%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 1, Average Training Loss: 0.0688, Average Validation Loss: 0.0451, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.67%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 1, Average Training Loss: 0.0631, Average Validation Loss: 0.0449, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.67%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0685, Average Validation Loss: 0.0446, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.67%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0665, Average Validation Loss: 0.0448, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.67%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0800, Average Validation Loss: 0.0442, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.67%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 1, Average Training Loss: 0.0686, Average Validation Loss: 0.0438, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.67%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0834, Average Validation Loss: 0.0435, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0620, Average Validation Loss: 0.0432, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.69%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0615, Average Validation Loss: 0.0431, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.69%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 1, Average Training Loss: 0.0563, Average Validation Loss: 0.0434, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 1, Average Training Loss: 0.0610, Average Validation Loss: 0.0427, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0621, Average Validation Loss: 0.0424, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0767, Average Validation Loss: 0.0422, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.69%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0708, Average Validation Loss: 0.0419, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 1, Average Training Loss: 0.0659, Average Validation Loss: 0.0417, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","Epoch 1, Average Training Loss: 0.0570, Average Validation Loss: 0.0415, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.0663, Average Validation Loss: 0.0414, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.0634, Average Validation Loss: 0.0411, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 1, Average Training Loss: 0.0584, Average Validation Loss: 0.0410, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 1, Average Training Loss: 0.0668, Average Validation Loss: 0.0408, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 1: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:50:05,182] Trial 7 finished with value: 0.04082007793759977 and parameters: {'vector_length': 128, 'num_layers': 2, 'layer_size': 64, 'dropout': 0.30000000000000004, 'num_epochs': 3, 'lr': 2.0147494961887756e-06, 'weight_decay': 0.0004069819187159517, 'warmup_steps': 50}. Best is trial 6 with value: 0.022466586580550348.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 38,876,672 parameters\n","Num non-decayed parameter tensors: 3, with 514 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6858, Average Validation Loss: 0.6767, Accuracy: 61.95%, Precision: 99.99%, Recall: 60.05%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6707, Average Validation Loss: 0.6602, Accuracy: 60.85%, Precision: 100.00%, Recall: 59.36%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6526, Average Validation Loss: 0.6441, Accuracy: 60.82%, Precision: 100.00%, Recall: 59.34%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6394, Average Validation Loss: 0.6276, Accuracy: 61.42%, Precision: 100.00%, Recall: 59.72%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6188, Average Validation Loss: 0.6104, Accuracy: 62.47%, Precision: 100.00%, Recall: 60.38%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6101, Average Validation Loss: 0.5921, Accuracy: 64.01%, Precision: 100.00%, Recall: 61.37%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5864, Average Validation Loss: 0.5732, Accuracy: 66.08%, Precision: 100.00%, Recall: 62.77%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5662, Average Validation Loss: 0.5526, Accuracy: 68.18%, Precision: 100.00%, Recall: 64.25%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5429, Average Validation Loss: 0.5311, Accuracy: 70.02%, Precision: 100.00%, Recall: 65.60%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5253, Average Validation Loss: 0.5084, Accuracy: 72.37%, Precision: 100.00%, Recall: 67.43%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.4926, Average Validation Loss: 0.4846, Accuracy: 76.04%, Precision: 100.00%, Recall: 70.48%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.4722, Average Validation Loss: 0.4609, Accuracy: 81.91%, Precision: 100.00%, Recall: 75.97%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4551, Average Validation Loss: 0.4360, Accuracy: 87.56%, Precision: 100.00%, Recall: 82.14%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.4260, Average Validation Loss: 0.4111, Accuracy: 91.16%, Precision: 100.00%, Recall: 86.61%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.3920, Average Validation Loss: 0.3868, Accuracy: 92.67%, Precision: 100.00%, Recall: 88.64%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.3959, Average Validation Loss: 0.3629, Accuracy: 93.70%, Precision: 100.00%, Recall: 90.07%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3651, Average Validation Loss: 0.3397, Accuracy: 95.03%, Precision: 100.00%, Recall: 92.00%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3451, Average Validation Loss: 0.3170, Accuracy: 96.06%, Precision: 99.99%, Recall: 93.57%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3139, Average Validation Loss: 0.2955, Accuracy: 96.42%, Precision: 99.99%, Recall: 94.11%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2988, Average Validation Loss: 0.2750, Accuracy: 97.04%, Precision: 99.99%, Recall: 95.10%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2791, Average Validation Loss: 0.2554, Accuracy: 97.54%, Precision: 99.99%, Recall: 95.89%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2548, Average Validation Loss: 0.2368, Accuracy: 97.91%, Precision: 99.99%, Recall: 96.49%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2428, Average Validation Loss: 0.2199, Accuracy: 98.18%, Precision: 99.98%, Recall: 96.94%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2194, Average Validation Loss: 0.2041, Accuracy: 98.22%, Precision: 99.98%, Recall: 97.00%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2133, Average Validation Loss: 0.1898, Accuracy: 98.35%, Precision: 99.99%, Recall: 97.20%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1982, Average Validation Loss: 0.1766, Accuracy: 98.59%, Precision: 99.98%, Recall: 97.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1817, Average Validation Loss: 0.1643, Accuracy: 98.77%, Precision: 99.98%, Recall: 97.92%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1789, Average Validation Loss: 0.1531, Accuracy: 98.92%, Precision: 99.97%, Recall: 98.17%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1717, Average Validation Loss: 0.1432, Accuracy: 99.00%, Precision: 99.96%, Recall: 98.32%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1586, Average Validation Loss: 0.1340, Accuracy: 99.02%, Precision: 99.96%, Recall: 98.36%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1434, Average Validation Loss: 0.1256, Accuracy: 99.03%, Precision: 99.96%, Recall: 98.37%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1318, Average Validation Loss: 0.1176, Accuracy: 99.05%, Precision: 99.96%, Recall: 98.41%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1281, Average Validation Loss: 0.1104, Accuracy: 99.08%, Precision: 99.96%, Recall: 98.46%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1331, Average Validation Loss: 0.1043, Accuracy: 99.11%, Precision: 99.96%, Recall: 98.51%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1209, Average Validation Loss: 0.0982, Accuracy: 99.14%, Precision: 99.96%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1011, Average Validation Loss: 0.0931, Accuracy: 99.14%, Precision: 99.96%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1059, Average Validation Loss: 0.0878, Accuracy: 99.13%, Precision: 99.97%, Recall: 98.53%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1025, Average Validation Loss: 0.0834, Accuracy: 99.18%, Precision: 99.96%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0949, Average Validation Loss: 0.0797, Accuracy: 99.19%, Precision: 99.96%, Recall: 98.64%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0936, Average Validation Loss: 0.0755, Accuracy: 99.20%, Precision: 99.96%, Recall: 98.66%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0821, Average Validation Loss: 0.0720, Accuracy: 99.21%, Precision: 99.96%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0898, Average Validation Loss: 0.0690, Accuracy: 99.21%, Precision: 99.96%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0708, Average Validation Loss: 0.0661, Accuracy: 99.21%, Precision: 99.96%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0676, Average Validation Loss: 0.0636, Accuracy: 99.23%, Precision: 99.96%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0769, Average Validation Loss: 0.0614, Accuracy: 99.23%, Precision: 99.97%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0736, Average Validation Loss: 0.0588, Accuracy: 99.22%, Precision: 99.98%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0773, Average Validation Loss: 0.0571, Accuracy: 99.24%, Precision: 99.97%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0640, Average Validation Loss: 0.0547, Accuracy: 99.25%, Precision: 99.97%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0696, Average Validation Loss: 0.0532, Accuracy: 99.24%, Precision: 99.97%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0612, Average Validation Loss: 0.0519, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0792, Average Validation Loss: 0.0503, Accuracy: 99.26%, Precision: 99.97%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0461, Average Validation Loss: 0.0491, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0555, Average Validation Loss: 0.0479, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0644, Average Validation Loss: 0.0468, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0584, Average Validation Loss: 0.0457, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0594, Average Validation Loss: 0.0448, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0582, Average Validation Loss: 0.0439, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0492, Average Validation Loss: 0.0432, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0465, Average Validation Loss: 0.0431, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0467, Average Validation Loss: 0.0421, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0492, Average Validation Loss: 0.0413, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0732, Average Validation Loss: 0.0406, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0489, Average Validation Loss: 0.0406, Accuracy: 99.28%, Precision: 99.98%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0535, Average Validation Loss: 0.0400, Accuracy: 99.30%, Precision: 99.98%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0398, Average Validation Loss: 0.0388, Accuracy: 99.30%, Precision: 99.97%, Recall: 98.82%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0585, Average Validation Loss: 0.0383, Accuracy: 99.30%, Precision: 99.97%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0472, Average Validation Loss: 0.0379, Accuracy: 99.30%, Precision: 99.98%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0491, Average Validation Loss: 0.0376, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0393, Average Validation Loss: 0.0377, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0485, Average Validation Loss: 0.0371, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0437, Average Validation Loss: 0.0368, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0466, Average Validation Loss: 0.0364, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0372, Average Validation Loss: 0.0366, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.76%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0425, Average Validation Loss: 0.0363, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0475, Average Validation Loss: 0.0354, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0392, Average Validation Loss: 0.0352, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0376, Average Validation Loss: 0.0351, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0507, Average Validation Loss: 0.0348, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0375, Average Validation Loss: 0.0345, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0356, Average Validation Loss: 0.0342, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0502, Average Validation Loss: 0.0337, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0482, Average Validation Loss: 0.0333, Accuracy: 99.31%, Precision: 99.98%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0440, Average Validation Loss: 0.0330, Accuracy: 99.31%, Precision: 99.98%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0441, Average Validation Loss: 0.0335, Accuracy: 99.31%, Precision: 99.98%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0348, Average Validation Loss: 0.0329, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0271, Average Validation Loss: 0.0329, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0469, Average Validation Loss: 0.0330, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0366, Average Validation Loss: 0.0326, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:57:32,604] Trial 8 finished with value: 0.0325535055350613 and parameters: {'vector_length': 512, 'num_layers': 2, 'layer_size': 256, 'dropout': 0.30000000000000004, 'num_epochs': 5, 'lr': 1.1028092257874397e-06, 'weight_decay': 6.448004353665794e-06, 'warmup_steps': 70}. Best is trial 6 with value: 0.022466586580550348.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 38,811,136 parameters\n","Num non-decayed parameter tensors: 2, with 258 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2916, Average Validation Loss: 0.0492, Accuracy: 98.97%, Precision: 99.81%, Recall: 98.41%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0499, Average Validation Loss: 0.0304, Accuracy: 99.28%, Precision: 99.87%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0654, Average Validation Loss: 0.0364, Accuracy: 99.29%, Precision: 99.64%, Recall: 99.12%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0428, Average Validation Loss: 0.0293, Accuracy: 99.37%, Precision: 99.96%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0296, Average Validation Loss: 0.0268, Accuracy: 99.39%, Precision: 99.93%, Recall: 99.02%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0319, Average Validation Loss: 0.0255, Accuracy: 99.39%, Precision: 99.87%, Recall: 99.07%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0248, Average Validation Loss: 0.0289, Accuracy: 99.34%, Precision: 99.93%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0392, Average Validation Loss: 0.0263, Accuracy: 99.39%, Precision: 99.90%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0311, Average Validation Loss: 0.0267, Accuracy: 99.41%, Precision: 99.93%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0252, Average Validation Loss: 0.0236, Accuracy: 99.42%, Precision: 99.93%, Recall: 99.07%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0191, Average Validation Loss: 0.0251, Accuracy: 99.40%, Precision: 99.96%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0184, Average Validation Loss: 0.0229, Accuracy: 99.41%, Precision: 99.88%, Recall: 99.10%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0229, Accuracy: 99.44%, Precision: 99.91%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0287, Average Validation Loss: 0.0242, Accuracy: 99.42%, Precision: 99.98%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0330, Average Validation Loss: 0.0215, Accuracy: 99.50%, Precision: 99.93%, Recall: 99.20%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0323, Average Validation Loss: 0.0218, Accuracy: 99.46%, Precision: 99.96%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0140, Average Validation Loss: 0.0239, Accuracy: 99.45%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0272, Average Validation Loss: 0.0200, Accuracy: 99.47%, Precision: 99.90%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0364, Average Validation Loss: 0.0215, Accuracy: 99.47%, Precision: 99.97%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0202, Accuracy: 99.47%, Precision: 99.84%, Recall: 99.24%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0226, Average Validation Loss: 0.0234, Accuracy: 99.45%, Precision: 99.96%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0277, Average Validation Loss: 0.0205, Accuracy: 99.48%, Precision: 99.88%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0342, Average Validation Loss: 0.0194, Accuracy: 99.50%, Precision: 99.91%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 13:59:31,643] Trial 9 finished with value: 0.0194498984545872 and parameters: {'vector_length': 512, 'num_layers': 1, 'layer_size': 256, 'dropout': 0.4, 'num_epochs': 3, 'lr': 5.117893851479622e-05, 'weight_decay': 1.6578123999204082e-05, 'warmup_steps': 100}. Best is trial 9 with value: 0.0194498984545872.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 7, with 19,674,368 parameters\n","Num non-decayed parameter tensors: 6, with 1,282 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 2.1315, Average Validation Loss: 0.2339, Accuracy: 91.50%, Precision: 100.00%, Recall: 87.06%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.3247, Average Validation Loss: 0.0986, Accuracy: 97.90%, Precision: 97.05%, Recall: 99.26%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2418, Average Validation Loss: 0.0761, Accuracy: 99.17%, Precision: 99.96%, Recall: 98.61%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2364, Average Validation Loss: 0.0716, Accuracy: 98.42%, Precision: 100.00%, Recall: 97.32%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2001, Average Validation Loss: 0.0531, Accuracy: 99.29%, Precision: 99.95%, Recall: 98.82%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1582, Average Validation Loss: 0.0660, Accuracy: 99.27%, Precision: 99.90%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1921, Average Validation Loss: 0.0852, Accuracy: 99.03%, Precision: 100.00%, Recall: 98.34%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.1535, Average Validation Loss: 0.0357, Accuracy: 99.24%, Precision: 99.97%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3233, Average Validation Loss: 0.0366, Accuracy: 99.28%, Precision: 99.98%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.2571, Average Validation Loss: 0.0403, Accuracy: 99.25%, Precision: 99.80%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.3742, Average Validation Loss: 0.0432, Accuracy: 99.31%, Precision: 99.90%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.4651, Average Validation Loss: 0.0371, Accuracy: 99.14%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.3681, Average Validation Loss: 0.0306, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1802, Average Validation Loss: 0.0582, Accuracy: 99.22%, Precision: 99.99%, Recall: 98.67%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4116, Average Validation Loss: 0.0815, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.4203, Average Validation Loss: 0.0751, Accuracy: 99.04%, Precision: 100.00%, Recall: 98.35%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.5197, Average Validation Loss: 0.0618, Accuracy: 99.18%, Precision: 99.98%, Recall: 98.61%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.2268, Average Validation Loss: 0.0463, Accuracy: 99.25%, Precision: 99.96%, Recall: 98.74%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:01:02,584] Trial 10 finished with value: 0.04608979498420062 and parameters: {'vector_length': 256, 'num_layers': 5, 'layer_size': 256, 'dropout': 0.5, 'num_epochs': 2, 'lr': 0.009539626015101757, 'weight_decay': 1.908338715152352e-05, 'warmup_steps': 20}. Best is trial 9 with value: 0.0194498984545872.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 38,811,136 parameters\n","Num non-decayed parameter tensors: 2, with 258 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2105, Average Validation Loss: 0.0456, Accuracy: 99.17%, Precision: 99.93%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0690, Average Validation Loss: 0.0339, Accuracy: 99.14%, Precision: 99.50%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0375, Average Validation Loss: 0.0328, Accuracy: 99.22%, Precision: 99.61%, Recall: 99.04%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0408, Average Validation Loss: 0.0475, Accuracy: 99.24%, Precision: 99.97%, Recall: 98.72%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0363, Average Validation Loss: 0.0326, Accuracy: 99.30%, Precision: 99.92%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0356, Average Validation Loss: 0.0290, Accuracy: 99.37%, Precision: 99.90%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0397, Average Validation Loss: 0.0418, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.72%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0295, Average Validation Loss: 0.0304, Accuracy: 99.36%, Precision: 99.96%, Recall: 98.92%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0506, Average Validation Loss: 0.0313, Accuracy: 99.30%, Precision: 99.61%, Recall: 99.17%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0228, Average Validation Loss: 0.0457, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0417, Average Validation Loss: 0.0289, Accuracy: 99.31%, Precision: 99.64%, Recall: 99.15%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:02:01,215] Trial 11 finished with value: 0.02907759473734611 and parameters: {'vector_length': 512, 'num_layers': 1, 'layer_size': 256, 'dropout': 0.4, 'num_epochs': 3, 'lr': 7.314711553205775e-05, 'weight_decay': 1.0458197834839022e-06, 'warmup_steps': 100}. Best is trial 9 with value: 0.0194498984545872.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3267, Average Validation Loss: 0.0744, Accuracy: 99.02%, Precision: 99.70%, Recall: 98.61%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0521, Average Validation Loss: 0.0320, Accuracy: 99.25%, Precision: 99.87%, Recall: 98.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0296, Average Validation Loss: 0.0283, Accuracy: 99.30%, Precision: 99.93%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0456, Average Validation Loss: 0.0261, Accuracy: 99.31%, Precision: 99.92%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0331, Average Validation Loss: 0.0283, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0364, Average Validation Loss: 0.0240, Accuracy: 99.37%, Precision: 99.98%, Recall: 98.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0219, Average Validation Loss: 0.0262, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0379, Average Validation Loss: 0.0245, Accuracy: 99.46%, Precision: 99.91%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0472, Average Validation Loss: 0.0236, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0333, Average Validation Loss: 0.0222, Accuracy: 99.44%, Precision: 99.98%, Recall: 99.06%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0253, Average Validation Loss: 0.0232, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0193, Average Validation Loss: 0.0249, Accuracy: 99.37%, Precision: 99.99%, Recall: 98.92%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0258, Average Validation Loss: 0.0223, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0209, Average Validation Loss: 0.0210, Accuracy: 99.46%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0162, Average Validation Loss: 0.0224, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0258, Average Validation Loss: 0.0196, Accuracy: 99.46%, Precision: 99.98%, Recall: 99.09%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0222, Average Validation Loss: 0.0191, Accuracy: 99.45%, Precision: 99.98%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0190, Average Validation Loss: 0.0182, Accuracy: 99.48%, Precision: 99.96%, Recall: 99.15%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0094, Average Validation Loss: 0.0208, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0303, Average Validation Loss: 0.0177, Accuracy: 99.55%, Precision: 99.90%, Recall: 99.31%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0279, Average Validation Loss: 0.0166, Accuracy: 99.53%, Precision: 99.94%, Recall: 99.24%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0240, Average Validation Loss: 0.0164, Accuracy: 99.57%, Precision: 99.94%, Recall: 99.31%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0192, Average Validation Loss: 0.0168, Accuracy: 99.50%, Precision: 99.96%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0158, Accuracy: 99.54%, Precision: 99.90%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0285, Average Validation Loss: 0.0154, Accuracy: 99.55%, Precision: 99.96%, Recall: 99.26%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0351, Average Validation Loss: 0.0142, Accuracy: 99.58%, Precision: 99.95%, Recall: 99.32%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0208, Average Validation Loss: 0.0146, Accuracy: 99.58%, Precision: 99.96%, Recall: 99.30%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0148, Average Validation Loss: 0.0139, Accuracy: 99.59%, Precision: 99.94%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0192, Average Validation Loss: 0.0133, Accuracy: 99.64%, Precision: 99.93%, Recall: 99.43%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0270, Average Validation Loss: 0.0133, Accuracy: 99.63%, Precision: 99.92%, Recall: 99.44%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0097, Average Validation Loss: 0.0147, Accuracy: 99.55%, Precision: 99.99%, Recall: 99.23%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:04:33,516] Trial 12 finished with value: 0.014669710158911609 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.4, 'num_epochs': 4, 'lr': 7.089012646046724e-05, 'weight_decay': 1.667488806698983e-05, 'warmup_steps': 100}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4636, Average Validation Loss: 0.2231, Accuracy: 98.64%, Precision: 99.82%, Recall: 97.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1316, Average Validation Loss: 0.0552, Accuracy: 99.15%, Precision: 99.84%, Recall: 98.69%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0722, Average Validation Loss: 0.0359, Accuracy: 99.28%, Precision: 99.79%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0437, Average Validation Loss: 0.0297, Accuracy: 99.30%, Precision: 99.94%, Recall: 98.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0323, Average Validation Loss: 0.0285, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0340, Average Validation Loss: 0.0256, Accuracy: 99.39%, Precision: 99.93%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0254, Average Validation Loss: 0.0310, Accuracy: 99.31%, Precision: 100.00%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0503, Average Validation Loss: 0.0255, Accuracy: 99.39%, Precision: 99.97%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0217, Average Validation Loss: 0.0240, Accuracy: 99.42%, Precision: 99.96%, Recall: 99.04%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0293, Average Validation Loss: 0.0262, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0209, Average Validation Loss: 0.0244, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0298, Average Validation Loss: 0.0224, Accuracy: 99.48%, Precision: 99.96%, Recall: 99.14%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0246, Average Validation Loss: 0.0217, Accuracy: 99.48%, Precision: 99.99%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0162, Average Validation Loss: 0.0241, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0091, Average Validation Loss: 0.0250, Accuracy: 99.43%, Precision: 99.99%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0385, Average Validation Loss: 0.0218, Accuracy: 99.49%, Precision: 99.92%, Recall: 99.19%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.0208, Accuracy: 99.48%, Precision: 99.99%, Recall: 99.11%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0255, Average Validation Loss: 0.0199, Accuracy: 99.48%, Precision: 99.97%, Recall: 99.13%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0196, Average Validation Loss: 0.0222, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0301, Average Validation Loss: 0.0204, Accuracy: 99.51%, Precision: 99.93%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0239, Average Validation Loss: 0.0209, Accuracy: 99.48%, Precision: 99.99%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0241, Average Validation Loss: 0.0192, Accuracy: 99.50%, Precision: 99.98%, Recall: 99.15%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0339, Average Validation Loss: 0.0211, Accuracy: 99.54%, Precision: 99.90%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0195, Average Validation Loss: 0.0240, Accuracy: 99.42%, Precision: 100.00%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0273, Average Validation Loss: 0.0181, Accuracy: 99.53%, Precision: 99.90%, Recall: 99.29%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0324, Average Validation Loss: 0.0180, Accuracy: 99.53%, Precision: 99.90%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.0184, Accuracy: 99.50%, Precision: 99.97%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0218, Average Validation Loss: 0.0184, Accuracy: 99.49%, Precision: 99.97%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0128, Average Validation Loss: 0.0169, Accuracy: 99.51%, Precision: 99.95%, Recall: 99.20%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0270, Average Validation Loss: 0.0164, Accuracy: 99.53%, Precision: 99.95%, Recall: 99.23%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0284, Average Validation Loss: 0.0160, Accuracy: 99.56%, Precision: 99.96%, Recall: 99.27%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0206, Average Validation Loss: 0.0168, Accuracy: 99.51%, Precision: 99.99%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0169, Accuracy: 99.60%, Precision: 99.93%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0187, Average Validation Loss: 0.0170, Accuracy: 99.52%, Precision: 99.99%, Recall: 99.17%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:07:20,201] Trial 13 finished with value: 0.017031838944357995 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.4, 'num_epochs': 2, 'lr': 4.197562926034612e-05, 'weight_decay': 2.021135314698852e-05, 'warmup_steps': 100}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3412, Average Validation Loss: 0.0378, Accuracy: 99.13%, Precision: 99.73%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0178, Average Validation Loss: 0.0415, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.72%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0435, Average Validation Loss: 0.0289, Accuracy: 99.36%, Precision: 99.85%, Recall: 99.03%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0491, Average Validation Loss: 0.0393, Accuracy: 99.32%, Precision: 99.96%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0668, Average Validation Loss: 0.0280, Accuracy: 99.30%, Precision: 99.57%, Recall: 99.20%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0412, Average Validation Loss: 0.0310, Accuracy: 99.39%, Precision: 99.89%, Recall: 99.06%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0401, Average Validation Loss: 0.0264, Accuracy: 99.38%, Precision: 99.73%, Recall: 99.20%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0455, Average Validation Loss: 0.0311, Accuracy: 99.35%, Precision: 99.94%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0438, Average Validation Loss: 0.0239, Accuracy: 99.41%, Precision: 99.84%, Recall: 99.15%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0317, Average Validation Loss: 0.0294, Accuracy: 99.36%, Precision: 99.95%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0138, Average Validation Loss: 0.0265, Accuracy: 99.41%, Precision: 99.94%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0443, Average Validation Loss: 0.0213, Accuracy: 99.48%, Precision: 99.89%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0370, Average Validation Loss: 0.0204, Accuracy: 99.49%, Precision: 99.95%, Recall: 99.17%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0277, Average Validation Loss: 0.0194, Accuracy: 99.50%, Precision: 99.89%, Recall: 99.24%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0182, Average Validation Loss: 0.0211, Accuracy: 99.44%, Precision: 99.97%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0278, Average Validation Loss: 0.0202, Accuracy: 99.50%, Precision: 99.81%, Recall: 99.31%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0335, Average Validation Loss: 0.0217, Accuracy: 99.54%, Precision: 99.80%, Recall: 99.40%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0209, Average Validation Loss: 0.0170, Accuracy: 99.53%, Precision: 99.95%, Recall: 99.24%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0337, Average Validation Loss: 0.0157, Accuracy: 99.59%, Precision: 99.92%, Recall: 99.37%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0163, Accuracy: 99.53%, Precision: 99.96%, Recall: 99.23%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0114, Average Validation Loss: 0.0166, Accuracy: 99.51%, Precision: 99.93%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0138, Average Validation Loss: 0.0187, Accuracy: 99.56%, Precision: 99.66%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0142, Average Validation Loss: 0.0171, Accuracy: 99.55%, Precision: 99.93%, Recall: 99.28%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0189, Average Validation Loss: 0.0162, Accuracy: 99.58%, Precision: 99.92%, Recall: 99.35%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:09:18,940] Trial 14 finished with value: 0.01532584475919705 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.2, 'num_epochs': 2, 'lr': 0.00040179548711394747, 'weight_decay': 0.0002419274179983588, 'warmup_steps': 20}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 5, with 11,049,728 parameters\n","Num non-decayed parameter tensors: 4, with 386 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3069, Average Validation Loss: 0.0450, Accuracy: 99.11%, Precision: 99.77%, Recall: 98.69%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0292, Average Validation Loss: 0.0837, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0801, Average Validation Loss: 0.0375, Accuracy: 99.20%, Precision: 99.56%, Recall: 99.05%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0352, Average Validation Loss: 0.0291, Accuracy: 99.30%, Precision: 99.93%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0398, Average Validation Loss: 0.0282, Accuracy: 99.36%, Precision: 99.91%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0387, Average Validation Loss: 0.0275, Accuracy: 99.37%, Precision: 99.87%, Recall: 99.04%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0270, Average Validation Loss: 0.0272, Accuracy: 99.36%, Precision: 99.85%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0246, Average Validation Loss: 0.0312, Accuracy: 99.36%, Precision: 99.95%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0488, Average Validation Loss: 0.0297, Accuracy: 99.32%, Precision: 99.57%, Recall: 99.25%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0379, Average Validation Loss: 0.0343, Accuracy: 99.21%, Precision: 99.99%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0354, Average Validation Loss: 0.0236, Accuracy: 99.41%, Precision: 99.92%, Recall: 99.05%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0216, Average Validation Loss: 0.0304, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0288, Average Validation Loss: 0.0261, Accuracy: 99.38%, Precision: 99.55%, Recall: 99.36%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0339, Average Validation Loss: 0.0239, Accuracy: 99.43%, Precision: 99.99%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0163, Average Validation Loss: 0.0210, Accuracy: 99.47%, Precision: 99.97%, Recall: 99.10%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0352, Average Validation Loss: 0.0190, Accuracy: 99.53%, Precision: 99.84%, Recall: 99.34%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0357, Average Validation Loss: 0.0224, Accuracy: 99.43%, Precision: 99.99%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0241, Average Validation Loss: 0.0196, Accuracy: 99.49%, Precision: 99.96%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0218, Average Validation Loss: 0.0184, Accuracy: 99.53%, Precision: 99.76%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0157, Average Validation Loss: 0.0198, Accuracy: 99.56%, Precision: 99.89%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0197, Accuracy: 99.54%, Precision: 99.94%, Recall: 99.26%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:11:03,651] Trial 15 finished with value: 0.01904302129547137 and parameters: {'vector_length': 256, 'num_layers': 3, 'layer_size': 128, 'dropout': 0.2, 'num_epochs': 2, 'lr': 0.000583559567804935, 'weight_decay': 0.0009334807707068941, 'warmup_steps': 10}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 1.2822, Average Validation Loss: 0.1080, Accuracy: 97.30%, Precision: 99.95%, Recall: 95.53%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0567, Average Validation Loss: 0.0542, Accuracy: 99.31%, Precision: 99.94%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0757, Average Validation Loss: 0.0857, Accuracy: 97.05%, Precision: 95.42%, Recall: 99.41%, F1: 0.97\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0549, Average Validation Loss: 0.0610, Accuracy: 99.13%, Precision: 100.00%, Recall: 98.50%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0320, Average Validation Loss: 0.0322, Accuracy: 99.33%, Precision: 99.98%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0374, Average Validation Loss: 0.0268, Accuracy: 99.41%, Precision: 99.90%, Recall: 99.07%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0302, Average Validation Loss: 0.0446, Accuracy: 99.36%, Precision: 99.87%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0262, Average Validation Loss: 0.0331, Accuracy: 99.44%, Precision: 99.88%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0263, Average Validation Loss: 0.0248, Accuracy: 99.47%, Precision: 99.90%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0367, Average Validation Loss: 0.0291, Accuracy: 99.40%, Precision: 100.00%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0088, Average Validation Loss: 0.0293, Accuracy: 99.44%, Precision: 99.97%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0229, Average Validation Loss: 0.0281, Accuracy: 99.47%, Precision: 99.96%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0515, Average Validation Loss: 0.0212, Accuracy: 99.47%, Precision: 99.94%, Recall: 99.14%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0281, Average Validation Loss: 0.0229, Accuracy: 99.40%, Precision: 99.98%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0153, Average Validation Loss: 0.0285, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0346, Average Validation Loss: 0.0214, Accuracy: 99.42%, Precision: 99.98%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0287, Average Validation Loss: 0.0220, Accuracy: 99.44%, Precision: 99.96%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0201, Average Validation Loss: 0.0238, Accuracy: 99.44%, Precision: 99.97%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:12:34,255] Trial 16 finished with value: 0.023839316443175176 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.2, 'num_epochs': 4, 'lr': 0.003022139155867, 'weight_decay': 0.00021472756867181697, 'warmup_steps': 30}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 5, with 11,049,728 parameters\n","Num non-decayed parameter tensors: 4, with 386 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4444, Average Validation Loss: 0.1197, Accuracy: 98.89%, Precision: 99.70%, Recall: 98.38%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0925, Average Validation Loss: 0.0353, Accuracy: 99.11%, Precision: 99.56%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0274, Average Validation Loss: 0.0415, Accuracy: 99.25%, Precision: 99.93%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0499, Average Validation Loss: 0.0318, Accuracy: 99.33%, Precision: 99.84%, Recall: 99.00%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0455, Average Validation Loss: 0.0265, Accuracy: 99.39%, Precision: 99.86%, Recall: 99.07%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0356, Average Validation Loss: 0.0259, Accuracy: 99.44%, Precision: 99.96%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0274, Average Validation Loss: 0.0302, Accuracy: 99.41%, Precision: 99.98%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0259, Average Validation Loss: 0.0247, Accuracy: 99.43%, Precision: 99.97%, Recall: 99.04%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0280, Average Validation Loss: 0.0267, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0284, Average Validation Loss: 0.0229, Accuracy: 99.46%, Precision: 99.93%, Recall: 99.14%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0480, Average Validation Loss: 0.0226, Accuracy: 99.47%, Precision: 99.96%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0341, Average Validation Loss: 0.0233, Accuracy: 99.44%, Precision: 99.97%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0553, Average Validation Loss: 0.0221, Accuracy: 99.46%, Precision: 99.95%, Recall: 99.11%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0254, Average Validation Loss: 0.0210, Accuracy: 99.50%, Precision: 99.89%, Recall: 99.25%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0280, Average Validation Loss: 0.0261, Accuracy: 99.46%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0316, Average Validation Loss: 0.0251, Accuracy: 99.46%, Precision: 99.96%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0412, Average Validation Loss: 0.0202, Accuracy: 99.48%, Precision: 99.92%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0269, Average Validation Loss: 0.0205, Accuracy: 99.49%, Precision: 99.95%, Recall: 99.17%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0386, Average Validation Loss: 0.0188, Accuracy: 99.52%, Precision: 99.96%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0136, Average Validation Loss: 0.0228, Accuracy: 99.47%, Precision: 99.99%, Recall: 99.09%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0162, Average Validation Loss: 0.0239, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0411, Average Validation Loss: 0.0171, Accuracy: 99.56%, Precision: 99.98%, Recall: 99.26%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0306, Average Validation Loss: 0.0182, Accuracy: 99.53%, Precision: 99.99%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0260, Average Validation Loss: 0.0167, Accuracy: 99.58%, Precision: 99.99%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0384, Average Validation Loss: 0.0155, Accuracy: 99.58%, Precision: 99.90%, Recall: 99.37%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0263, Average Validation Loss: 0.0166, Accuracy: 99.56%, Precision: 99.99%, Recall: 99.25%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0338, Average Validation Loss: 0.0173, Accuracy: 99.60%, Precision: 99.87%, Recall: 99.43%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0101, Average Validation Loss: 0.0237, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0081, Average Validation Loss: 0.0244, Accuracy: 99.49%, Precision: 100.00%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0332, Average Validation Loss: 0.0228, Accuracy: 99.43%, Precision: 99.35%, Recall: 99.64%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:15:03,331] Trial 17 finished with value: 0.022779144684003817 and parameters: {'vector_length': 256, 'num_layers': 3, 'layer_size': 128, 'dropout': 0.2, 'num_epochs': 2, 'lr': 0.0002296252897623957, 'weight_decay': 0.00017702652016480134, 'warmup_steps': 30}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 6, with 11,066,112 parameters\n","Num non-decayed parameter tensors: 5, with 514 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3073, Average Validation Loss: 0.0781, Accuracy: 99.19%, Precision: 99.91%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0890, Average Validation Loss: 0.0888, Accuracy: 99.11%, Precision: 100.00%, Recall: 98.47%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0776, Average Validation Loss: 0.0306, Accuracy: 99.27%, Precision: 100.00%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0387, Average Validation Loss: 0.0327, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0376, Average Validation Loss: 0.0310, Accuracy: 99.36%, Precision: 99.81%, Recall: 99.08%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0420, Average Validation Loss: 0.0261, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0197, Average Validation Loss: 0.0265, Accuracy: 99.41%, Precision: 99.96%, Recall: 99.03%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0269, Accuracy: 99.39%, Precision: 99.84%, Recall: 99.11%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0341, Average Validation Loss: 0.0258, Accuracy: 99.34%, Precision: 100.00%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0303, Average Validation Loss: 0.0257, Accuracy: 99.33%, Precision: 100.00%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0465, Average Validation Loss: 0.0280, Accuracy: 99.26%, Precision: 100.00%, Recall: 98.72%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:15:59,300] Trial 18 finished with value: 0.02748761998137107 and parameters: {'vector_length': 256, 'num_layers': 4, 'layer_size': 128, 'dropout': 0.2, 'num_epochs': 1, 'lr': 0.00131577661933806, 'weight_decay': 3.394059146969969e-05, 'warmup_steps': 30}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5786, Average Validation Loss: 0.4601, Accuracy: 75.63%, Precision: 100.00%, Recall: 70.12%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.3648, Average Validation Loss: 0.2663, Accuracy: 96.92%, Precision: 99.87%, Recall: 95.00%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2046, Average Validation Loss: 0.1378, Accuracy: 98.69%, Precision: 99.83%, Recall: 97.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1092, Average Validation Loss: 0.0771, Accuracy: 99.13%, Precision: 99.86%, Recall: 98.64%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0623, Average Validation Loss: 0.0515, Accuracy: 99.21%, Precision: 99.97%, Recall: 98.67%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0427, Average Validation Loss: 0.0403, Accuracy: 99.27%, Precision: 99.96%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0439, Average Validation Loss: 0.0359, Accuracy: 99.30%, Precision: 99.95%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0426, Average Validation Loss: 0.0332, Accuracy: 99.29%, Precision: 99.96%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0379, Average Validation Loss: 0.0319, Accuracy: 99.32%, Precision: 99.96%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0237, Average Validation Loss: 0.0301, Accuracy: 99.30%, Precision: 99.97%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0443, Average Validation Loss: 0.0293, Accuracy: 99.36%, Precision: 99.94%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0470, Average Validation Loss: 0.0299, Accuracy: 99.39%, Precision: 99.91%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0285, Average Validation Loss: 0.0290, Accuracy: 99.28%, Precision: 100.00%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0186, Average Validation Loss: 0.0263, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0313, Average Validation Loss: 0.0259, Accuracy: 99.42%, Precision: 99.94%, Recall: 99.05%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0301, Average Validation Loss: 0.0253, Accuracy: 99.42%, Precision: 99.94%, Recall: 99.05%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0250, Average Validation Loss: 0.0257, Accuracy: 99.40%, Precision: 100.00%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0286, Average Validation Loss: 0.0266, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0311, Average Validation Loss: 0.0239, Accuracy: 99.44%, Precision: 99.97%, Recall: 99.05%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0244, Average Validation Loss: 0.0235, Accuracy: 99.43%, Precision: 99.99%, Recall: 99.03%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0257, Average Validation Loss: 0.0232, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.04%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0278, Average Validation Loss: 0.0231, Accuracy: 99.47%, Precision: 99.99%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0292, Average Validation Loss: 0.0226, Accuracy: 99.45%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0193, Average Validation Loss: 0.0223, Accuracy: 99.46%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0281, Average Validation Loss: 0.0220, Accuracy: 99.46%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0187, Average Validation Loss: 0.0219, Accuracy: 99.46%, Precision: 100.00%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0184, Average Validation Loss: 0.0227, Accuracy: 99.43%, Precision: 100.00%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0245, Average Validation Loss: 0.0213, Accuracy: 99.47%, Precision: 99.99%, Recall: 99.10%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0223, Average Validation Loss: 0.0215, Accuracy: 99.50%, Precision: 99.98%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0153, Average Validation Loss: 0.0218, Accuracy: 99.45%, Precision: 100.00%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.0233, Accuracy: 99.43%, Precision: 100.00%, Recall: 99.01%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0288, Average Validation Loss: 0.0208, Accuracy: 99.49%, Precision: 99.99%, Recall: 99.13%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0294, Average Validation Loss: 0.0213, Accuracy: 99.51%, Precision: 99.98%, Recall: 99.17%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:18:42,047] Trial 19 finished with value: 0.02134743867995771 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.1, 'num_epochs': 5, 'lr': 1.6399851319818785e-05, 'weight_decay': 0.0008547931781092403, 'warmup_steps': 40}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 7, with 11,082,496 parameters\n","Num non-decayed parameter tensors: 6, with 642 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6774, Average Validation Loss: 0.6372, Accuracy: 78.28%, Precision: 100.00%, Recall: 72.48%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5865, Average Validation Loss: 0.4701, Accuracy: 88.40%, Precision: 100.00%, Recall: 83.13%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.4415, Average Validation Loss: 0.2930, Accuracy: 96.47%, Precision: 100.00%, Recall: 94.19%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3029, Average Validation Loss: 0.1599, Accuracy: 98.87%, Precision: 100.00%, Recall: 98.06%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1878, Average Validation Loss: 0.0722, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1085, Average Validation Loss: 0.0507, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0677, Average Validation Loss: 0.0448, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0683, Average Validation Loss: 0.0340, Accuracy: 99.33%, Precision: 99.95%, Recall: 98.90%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0489, Average Validation Loss: 0.0356, Accuracy: 99.34%, Precision: 99.97%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0391, Average Validation Loss: 0.0429, Accuracy: 99.30%, Precision: 100.00%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0687, Average Validation Loss: 0.0332, Accuracy: 99.41%, Precision: 99.96%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0520, Average Validation Loss: 0.0270, Accuracy: 99.39%, Precision: 99.85%, Recall: 99.09%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0522, Average Validation Loss: 0.0297, Accuracy: 99.40%, Precision: 99.96%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0382, Average Validation Loss: 0.0263, Accuracy: 99.42%, Precision: 99.96%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0527, Average Validation Loss: 0.0260, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0725, Average Validation Loss: 0.0226, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0413, Average Validation Loss: 0.0239, Accuracy: 99.41%, Precision: 100.00%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0415, Average Validation Loss: 0.0210, Accuracy: 99.48%, Precision: 99.99%, Recall: 99.12%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0460, Average Validation Loss: 0.0223, Accuracy: 99.48%, Precision: 99.98%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0440, Average Validation Loss: 0.0197, Accuracy: 99.50%, Precision: 99.95%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0593, Average Validation Loss: 0.0196, Accuracy: 99.55%, Precision: 99.93%, Recall: 99.28%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0438, Average Validation Loss: 0.0182, Accuracy: 99.52%, Precision: 99.96%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0465, Average Validation Loss: 0.0177, Accuracy: 99.55%, Precision: 99.96%, Recall: 99.26%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0347, Average Validation Loss: 0.0190, Accuracy: 99.56%, Precision: 99.99%, Recall: 99.25%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0236, Average Validation Loss: 0.0256, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0385, Average Validation Loss: 0.0158, Accuracy: 99.59%, Precision: 99.91%, Recall: 99.37%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0226, Average Validation Loss: 0.0232, Accuracy: 99.50%, Precision: 100.00%, Recall: 99.14%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0363, Average Validation Loss: 0.0148, Accuracy: 99.60%, Precision: 99.93%, Recall: 99.37%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0319, Average Validation Loss: 0.0172, Accuracy: 99.59%, Precision: 99.99%, Recall: 99.31%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0232, Average Validation Loss: 0.0186, Accuracy: 99.57%, Precision: 99.99%, Recall: 99.26%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0354, Average Validation Loss: 0.0144, Accuracy: 99.60%, Precision: 99.89%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0330, Average Validation Loss: 0.0156, Accuracy: 99.60%, Precision: 99.97%, Recall: 99.33%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0163, Accuracy: 99.58%, Precision: 99.97%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:21:25,285] Trial 20 finished with value: 0.01678971676911051 and parameters: {'vector_length': 256, 'num_layers': 5, 'layer_size': 128, 'dropout': 0.5, 'num_epochs': 3, 'lr': 0.00017694725114909208, 'weight_decay': 0.00034878962465769353, 'warmup_steps': 10}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 7, with 11,082,496 parameters\n","Num non-decayed parameter tensors: 6, with 642 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6843, Average Validation Loss: 0.6524, Accuracy: 78.93%, Precision: 100.00%, Recall: 73.07%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.6146, Average Validation Loss: 0.5200, Accuracy: 84.29%, Precision: 100.00%, Recall: 78.45%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.5065, Average Validation Loss: 0.3702, Accuracy: 92.18%, Precision: 100.00%, Recall: 87.96%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.3709, Average Validation Loss: 0.2597, Accuracy: 98.27%, Precision: 100.00%, Recall: 97.07%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2917, Average Validation Loss: 0.1521, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1852, Average Validation Loss: 0.0577, Accuracy: 99.27%, Precision: 99.96%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0986, Average Validation Loss: 0.0375, Accuracy: 99.29%, Precision: 99.96%, Recall: 98.82%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0608, Average Validation Loss: 0.0468, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0719, Average Validation Loss: 0.0406, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0987, Average Validation Loss: 0.0275, Accuracy: 99.31%, Precision: 99.86%, Recall: 98.95%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0432, Average Validation Loss: 0.0308, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0454, Average Validation Loss: 0.0323, Accuracy: 99.35%, Precision: 99.98%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0245, Average Validation Loss: 0.0283, Accuracy: 99.39%, Precision: 99.92%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0406, Average Validation Loss: 0.0309, Accuracy: 99.38%, Precision: 99.96%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0463, Average Validation Loss: 0.0257, Accuracy: 99.42%, Precision: 99.87%, Recall: 99.12%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0241, Average Validation Loss: 0.0291, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0342, Average Validation Loss: 0.0257, Accuracy: 99.45%, Precision: 99.96%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0706, Average Validation Loss: 0.0224, Accuracy: 99.47%, Precision: 99.91%, Recall: 99.16%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0409, Average Validation Loss: 0.0269, Accuracy: 99.40%, Precision: 100.00%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0468, Average Validation Loss: 0.0222, Accuracy: 99.46%, Precision: 99.98%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0245, Average Validation Loss: 0.0233, Accuracy: 99.45%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0413, Average Validation Loss: 0.0219, Accuracy: 99.49%, Precision: 99.98%, Recall: 99.14%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0280, Average Validation Loss: 0.0285, Accuracy: 99.44%, Precision: 100.00%, Recall: 99.04%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:23:19,657] Trial 21 finished with value: 0.028496713127714356 and parameters: {'vector_length': 256, 'num_layers': 5, 'layer_size': 128, 'dropout': 0.5, 'num_epochs': 3, 'lr': 0.0001565442197873896, 'weight_decay': 0.00032794151619273135, 'warmup_steps': 10}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 7, with 11,082,496 parameters\n","Num non-decayed parameter tensors: 6, with 642 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6724, Average Validation Loss: 0.6320, Accuracy: 57.19%, Precision: 100.00%, Recall: 57.19%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.5588, Average Validation Loss: 0.4460, Accuracy: 65.58%, Precision: 100.00%, Recall: 62.42%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.4326, Average Validation Loss: 0.3309, Accuracy: 94.92%, Precision: 100.00%, Recall: 91.84%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3583, Average Validation Loss: 0.2839, Accuracy: 98.70%, Precision: 100.00%, Recall: 97.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3067, Average Validation Loss: 0.2249, Accuracy: 99.22%, Precision: 99.99%, Recall: 98.66%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2263, Average Validation Loss: 0.1109, Accuracy: 99.25%, Precision: 99.94%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1541, Average Validation Loss: 0.0358, Accuracy: 99.19%, Precision: 99.50%, Recall: 99.08%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0988, Average Validation Loss: 0.0402, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0588, Average Validation Loss: 0.0321, Accuracy: 99.33%, Precision: 99.92%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0516, Average Validation Loss: 0.0337, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0522, Average Validation Loss: 0.0288, Accuracy: 99.35%, Precision: 99.96%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0430, Average Validation Loss: 0.0280, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0336, Average Validation Loss: 0.0264, Accuracy: 99.41%, Precision: 99.98%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0133, Average Validation Loss: 0.0417, Accuracy: 99.27%, Precision: 100.00%, Recall: 98.73%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0338, Average Validation Loss: 0.0327, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0572, Average Validation Loss: 0.0245, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0576, Average Validation Loss: 0.0240, Accuracy: 99.41%, Precision: 99.99%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0472, Average Validation Loss: 0.0230, Accuracy: 99.48%, Precision: 99.91%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0409, Average Validation Loss: 0.0256, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0363, Average Validation Loss: 0.0211, Accuracy: 99.49%, Precision: 99.94%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0437, Average Validation Loss: 0.0229, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0318, Average Validation Loss: 0.0220, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.04%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0603, Average Validation Loss: 0.0218, Accuracy: 99.53%, Precision: 99.96%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0246, Average Validation Loss: 0.0275, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0337, Average Validation Loss: 0.0220, Accuracy: 99.47%, Precision: 99.99%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:25:23,808] Trial 22 finished with value: 0.022012243157479208 and parameters: {'vector_length': 256, 'num_layers': 5, 'layer_size': 128, 'dropout': 0.5, 'num_epochs': 2, 'lr': 0.00022939767429758654, 'weight_decay': 0.00014693713441774308, 'warmup_steps': 20}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 6, with 11,066,112 parameters\n","Num non-decayed parameter tensors: 5, with 514 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3513, Average Validation Loss: 0.0682, Accuracy: 99.13%, Precision: 100.00%, Recall: 98.51%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0722, Average Validation Loss: 0.0504, Accuracy: 99.28%, Precision: 99.96%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0672, Average Validation Loss: 0.0391, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0609, Average Validation Loss: 0.0479, Accuracy: 99.24%, Precision: 99.55%, Recall: 99.13%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0669, Average Validation Loss: 0.0290, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0588, Average Validation Loss: 0.0282, Accuracy: 99.26%, Precision: 100.00%, Recall: 98.73%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0481, Average Validation Loss: 0.0276, Accuracy: 99.31%, Precision: 100.00%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0363, Average Validation Loss: 0.0282, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0395, Average Validation Loss: 0.0268, Accuracy: 99.33%, Precision: 100.00%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0617, Average Validation Loss: 0.0261, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0636, Average Validation Loss: 0.0370, Accuracy: 99.39%, Precision: 99.90%, Recall: 99.05%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0487, Average Validation Loss: 0.0280, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0579, Average Validation Loss: 0.0246, Accuracy: 99.39%, Precision: 99.95%, Recall: 99.00%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0349, Average Validation Loss: 0.0239, Accuracy: 99.42%, Precision: 99.87%, Recall: 99.12%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0374, Average Validation Loss: 0.0278, Accuracy: 99.35%, Precision: 99.92%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0482, Average Validation Loss: 0.0239, Accuracy: 99.40%, Precision: 99.93%, Recall: 99.03%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0389, Average Validation Loss: 0.0242, Accuracy: 99.39%, Precision: 99.98%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0219, Accuracy: 99.44%, Precision: 99.94%, Recall: 99.09%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0372, Average Validation Loss: 0.0222, Accuracy: 99.47%, Precision: 99.96%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0267, Average Validation Loss: 0.0204, Accuracy: 99.46%, Precision: 99.96%, Recall: 99.10%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0459, Average Validation Loss: 0.0219, Accuracy: 99.47%, Precision: 99.84%, Recall: 99.24%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0321, Average Validation Loss: 0.0344, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0195, Average Validation Loss: 0.0209, Accuracy: 99.47%, Precision: 99.74%, Recall: 99.33%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0619, Average Validation Loss: 0.0236, Accuracy: 99.28%, Precision: 100.00%, Recall: 98.76%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0275, Average Validation Loss: 0.0217, Accuracy: 99.36%, Precision: 100.00%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:27:27,347] Trial 23 finished with value: 0.021711680919838112 and parameters: {'vector_length': 256, 'num_layers': 4, 'layer_size': 128, 'dropout': 0.4, 'num_epochs': 4, 'lr': 0.00164238792096478, 'weight_decay': 0.00044223529040355566, 'warmup_steps': 10}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 11,033,344 parameters\n","Num non-decayed parameter tensors: 3, with 258 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6427, Average Validation Loss: 0.5769, Accuracy: 64.38%, Precision: 100.00%, Recall: 61.62%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5142, Average Validation Loss: 0.4487, Accuracy: 71.36%, Precision: 100.00%, Recall: 66.63%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.3961, Average Validation Loss: 0.3176, Accuracy: 93.65%, Precision: 100.00%, Recall: 90.01%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.2889, Average Validation Loss: 0.2105, Accuracy: 97.88%, Precision: 100.00%, Recall: 96.42%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2263, Average Validation Loss: 0.1415, Accuracy: 98.97%, Precision: 99.96%, Recall: 98.26%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1694, Average Validation Loss: 0.1009, Accuracy: 99.10%, Precision: 99.98%, Recall: 98.47%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1474, Average Validation Loss: 0.0770, Accuracy: 99.16%, Precision: 99.96%, Recall: 98.59%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1132, Average Validation Loss: 0.0618, Accuracy: 99.24%, Precision: 99.96%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1021, Average Validation Loss: 0.0524, Accuracy: 99.22%, Precision: 99.98%, Recall: 98.67%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0753, Average Validation Loss: 0.0457, Accuracy: 99.22%, Precision: 99.98%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0903, Average Validation Loss: 0.0408, Accuracy: 99.26%, Precision: 99.97%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0680, Average Validation Loss: 0.0378, Accuracy: 99.29%, Precision: 99.96%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0544, Average Validation Loss: 0.0359, Accuracy: 99.26%, Precision: 99.97%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0466, Average Validation Loss: 0.0358, Accuracy: 99.24%, Precision: 99.98%, Recall: 98.71%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0520, Average Validation Loss: 0.0336, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0544, Average Validation Loss: 0.0324, Accuracy: 99.30%, Precision: 99.96%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0448, Average Validation Loss: 0.0312, Accuracy: 99.30%, Precision: 99.96%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0474, Average Validation Loss: 0.0309, Accuracy: 99.29%, Precision: 99.96%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0619, Average Validation Loss: 0.0295, Accuracy: 99.33%, Precision: 99.95%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0379, Average Validation Loss: 0.0295, Accuracy: 99.31%, Precision: 99.96%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0334, Average Validation Loss: 0.0315, Accuracy: 99.28%, Precision: 99.97%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0536, Average Validation Loss: 0.0300, Accuracy: 99.29%, Precision: 99.97%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0397, Average Validation Loss: 0.0272, Accuracy: 99.36%, Precision: 99.96%, Recall: 98.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0345, Average Validation Loss: 0.0280, Accuracy: 99.33%, Precision: 99.96%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0269, Average Validation Loss: 0.0278, Accuracy: 99.33%, Precision: 99.96%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0526, Average Validation Loss: 0.0259, Accuracy: 99.38%, Precision: 99.96%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0334, Average Validation Loss: 0.0250, Accuracy: 99.41%, Precision: 99.95%, Recall: 99.03%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0487, Average Validation Loss: 0.0250, Accuracy: 99.40%, Precision: 99.96%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0445, Average Validation Loss: 0.0242, Accuracy: 99.42%, Precision: 99.94%, Recall: 99.06%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0360, Average Validation Loss: 0.0247, Accuracy: 99.40%, Precision: 99.96%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0436, Average Validation Loss: 0.0254, Accuracy: 99.39%, Precision: 99.96%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0360, Average Validation Loss: 0.0243, Accuracy: 99.41%, Precision: 99.96%, Recall: 99.03%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0284, Average Validation Loss: 0.0255, Accuracy: 99.39%, Precision: 99.96%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0384, Average Validation Loss: 0.0256, Accuracy: 99.39%, Precision: 99.96%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:30:14,300] Trial 24 finished with value: 0.025647011095959994 and parameters: {'vector_length': 256, 'num_layers': 2, 'layer_size': 128, 'dropout': 0.5, 'num_epochs': 3, 'lr': 1.9055631232803427e-05, 'weight_decay': 4.0946409254545506e-05, 'warmup_steps': 20}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 5, with 11,049,728 parameters\n","Num non-decayed parameter tensors: 4, with 386 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4303, Average Validation Loss: 0.0890, Accuracy: 98.68%, Precision: 99.93%, Recall: 97.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0969, Average Validation Loss: 0.0360, Accuracy: 99.24%, Precision: 99.88%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0703, Average Validation Loss: 0.0328, Accuracy: 99.31%, Precision: 99.90%, Recall: 98.90%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0300, Average Validation Loss: 0.0368, Accuracy: 99.32%, Precision: 99.98%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0430, Average Validation Loss: 0.0282, Accuracy: 99.39%, Precision: 99.98%, Recall: 98.97%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0331, Average Validation Loss: 0.0256, Accuracy: 99.43%, Precision: 99.99%, Recall: 99.02%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0320, Average Validation Loss: 0.0280, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0236, Average Validation Loss: 0.0245, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.04%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0226, Average Validation Loss: 0.0304, Accuracy: 99.40%, Precision: 100.00%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0374, Average Validation Loss: 0.0216, Accuracy: 99.47%, Precision: 99.96%, Recall: 99.13%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0394, Average Validation Loss: 0.0219, Accuracy: 99.44%, Precision: 99.84%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0329, Average Validation Loss: 0.0223, Accuracy: 99.46%, Precision: 99.98%, Recall: 99.09%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0275, Average Validation Loss: 0.0215, Accuracy: 99.45%, Precision: 99.99%, Recall: 99.06%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0280, Average Validation Loss: 0.0234, Accuracy: 99.45%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0384, Average Validation Loss: 0.0222, Accuracy: 99.46%, Precision: 99.98%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:31:29,587] Trial 25 finished with value: 0.02253110275377293 and parameters: {'vector_length': 256, 'num_layers': 3, 'layer_size': 128, 'dropout': 0.4, 'num_epochs': 4, 'lr': 0.0003253782008206704, 'weight_decay': 1.058944001935151e-05, 'warmup_steps': 40}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6932, Average Validation Loss: 0.1825, Accuracy: 95.43%, Precision: 100.00%, Recall: 92.60%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.1310, Average Validation Loss: 0.0464, Accuracy: 98.65%, Precision: 98.57%, Recall: 99.06%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0869, Average Validation Loss: 0.0388, Accuracy: 99.22%, Precision: 99.67%, Recall: 98.98%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0695, Average Validation Loss: 0.0363, Accuracy: 99.33%, Precision: 99.80%, Recall: 99.03%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0792, Average Validation Loss: 0.0266, Accuracy: 99.37%, Precision: 99.87%, Recall: 99.03%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0442, Average Validation Loss: 0.0271, Accuracy: 99.33%, Precision: 99.87%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0484, Average Validation Loss: 0.0343, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0490, Average Validation Loss: 0.0233, Accuracy: 99.41%, Precision: 99.97%, Recall: 99.02%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0334, Average Validation Loss: 0.0227, Accuracy: 99.41%, Precision: 99.88%, Recall: 99.10%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0223, Average Validation Loss: 0.0402, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0305, Average Validation Loss: 0.0210, Accuracy: 99.46%, Precision: 99.86%, Recall: 99.20%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0442, Average Validation Loss: 0.0278, Accuracy: 99.41%, Precision: 99.99%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0280, Average Validation Loss: 0.0300, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0274, Average Validation Loss: 0.0208, Accuracy: 99.44%, Precision: 99.88%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0234, Average Validation Loss: 0.0290, Accuracy: 99.37%, Precision: 99.98%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0264, Average Validation Loss: 0.0260, Accuracy: 99.41%, Precision: 99.97%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:32:49,713] Trial 26 finished with value: 0.026011243844373352 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.5, 'num_epochs': 2, 'lr': 0.0011952620506455994, 'weight_decay': 0.00011394679037211591, 'warmup_steps': 40}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 7, with 11,082,496 parameters\n","Num non-decayed parameter tensors: 6, with 642 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6700, Average Validation Loss: 0.5966, Accuracy: 85.40%, Precision: 100.00%, Recall: 79.66%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.5020, Average Validation Loss: 0.3456, Accuracy: 93.53%, Precision: 100.00%, Recall: 89.84%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.2791, Average Validation Loss: 0.1225, Accuracy: 99.13%, Precision: 99.87%, Recall: 98.64%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1066, Average Validation Loss: 0.0447, Accuracy: 99.25%, Precision: 99.91%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0456, Average Validation Loss: 0.0337, Accuracy: 99.27%, Precision: 99.74%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0363, Average Validation Loss: 0.0400, Accuracy: 99.32%, Precision: 99.93%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0332, Average Validation Loss: 0.0341, Accuracy: 99.35%, Precision: 99.89%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0292, Accuracy: 99.37%, Precision: 99.84%, Recall: 99.07%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0511, Average Validation Loss: 0.0280, Accuracy: 99.38%, Precision: 99.87%, Recall: 99.05%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0265, Average Validation Loss: 0.0326, Accuracy: 99.35%, Precision: 99.98%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0300, Accuracy: 99.37%, Precision: 99.98%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0246, Average Validation Loss: 0.0276, Accuracy: 99.40%, Precision: 99.98%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0323, Average Validation Loss: 0.0248, Accuracy: 99.45%, Precision: 99.97%, Recall: 99.08%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0213, Average Validation Loss: 0.0252, Accuracy: 99.45%, Precision: 99.96%, Recall: 99.09%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0426, Average Validation Loss: 0.0223, Accuracy: 99.47%, Precision: 99.84%, Recall: 99.24%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0360, Average Validation Loss: 0.0306, Accuracy: 99.41%, Precision: 99.98%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0306, Average Validation Loss: 0.0266, Accuracy: 99.42%, Precision: 99.97%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0362, Average Validation Loss: 0.0225, Accuracy: 99.49%, Precision: 99.96%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0418, Average Validation Loss: 0.0219, Accuracy: 99.49%, Precision: 99.97%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0314, Average Validation Loss: 0.0212, Accuracy: 99.50%, Precision: 99.97%, Recall: 99.16%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0280, Average Validation Loss: 0.0193, Accuracy: 99.54%, Precision: 99.95%, Recall: 99.25%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0307, Average Validation Loss: 0.0192, Accuracy: 99.54%, Precision: 99.99%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0262, Average Validation Loss: 0.0194, Accuracy: 99.54%, Precision: 99.99%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0228, Average Validation Loss: 0.0176, Accuracy: 99.58%, Precision: 99.96%, Recall: 99.31%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0349, Average Validation Loss: 0.0169, Accuracy: 99.59%, Precision: 99.90%, Recall: 99.39%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0283, Average Validation Loss: 0.0206, Accuracy: 99.50%, Precision: 99.99%, Recall: 99.14%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0256, Average Validation Loss: 0.0184, Accuracy: 99.54%, Precision: 99.99%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0305, Average Validation Loss: 0.0192, Accuracy: 99.59%, Precision: 99.80%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0247, Average Validation Loss: 0.0233, Accuracy: 99.49%, Precision: 99.99%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:35:12,877] Trial 27 finished with value: 0.02323806652959713 and parameters: {'vector_length': 256, 'num_layers': 5, 'layer_size': 128, 'dropout': 0.2, 'num_epochs': 3, 'lr': 0.0001283720976899434, 'weight_decay': 0.0005525790511421569, 'warmup_steps': 60}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 5, with 3,419,520 parameters\n","Num non-decayed parameter tensors: 4, with 194 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6849, Average Validation Loss: 0.6711, Accuracy: 78.20%, Precision: 100.00%, Recall: 72.40%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.6600, Average Validation Loss: 0.6347, Accuracy: 72.29%, Precision: 100.00%, Recall: 67.36%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.6144, Average Validation Loss: 0.5722, Accuracy: 84.34%, Precision: 100.00%, Recall: 78.51%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.5452, Average Validation Loss: 0.4816, Accuracy: 95.17%, Precision: 99.98%, Recall: 92.23%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.4676, Average Validation Loss: 0.3855, Accuracy: 97.10%, Precision: 99.97%, Recall: 95.20%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.4249, Average Validation Loss: 0.3082, Accuracy: 97.67%, Precision: 99.97%, Recall: 96.11%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.3590, Average Validation Loss: 0.2489, Accuracy: 98.55%, Precision: 99.97%, Recall: 97.56%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.3054, Average Validation Loss: 0.1997, Accuracy: 99.03%, Precision: 99.96%, Recall: 98.38%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2689, Average Validation Loss: 0.1628, Accuracy: 98.91%, Precision: 99.97%, Recall: 98.15%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2459, Average Validation Loss: 0.1357, Accuracy: 98.95%, Precision: 99.97%, Recall: 98.23%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2162, Average Validation Loss: 0.1119, Accuracy: 99.05%, Precision: 99.97%, Recall: 98.39%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1936, Average Validation Loss: 0.0930, Accuracy: 99.17%, Precision: 99.97%, Recall: 98.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1752, Average Validation Loss: 0.0813, Accuracy: 99.09%, Precision: 99.97%, Recall: 98.47%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1623, Average Validation Loss: 0.0702, Accuracy: 99.15%, Precision: 99.97%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1480, Average Validation Loss: 0.0606, Accuracy: 99.22%, Precision: 99.97%, Recall: 98.69%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1370, Average Validation Loss: 0.0535, Accuracy: 99.26%, Precision: 99.97%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1187, Average Validation Loss: 0.0495, Accuracy: 99.25%, Precision: 99.97%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0936, Average Validation Loss: 0.0465, Accuracy: 99.22%, Precision: 99.98%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1045, Average Validation Loss: 0.0439, Accuracy: 99.21%, Precision: 99.99%, Recall: 98.65%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0963, Average Validation Loss: 0.0407, Accuracy: 99.25%, Precision: 99.98%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0912, Average Validation Loss: 0.0381, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0749, Average Validation Loss: 0.0370, Accuracy: 99.26%, Precision: 99.97%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0893, Average Validation Loss: 0.0358, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0772, Average Validation Loss: 0.0352, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0915, Average Validation Loss: 0.0340, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0651, Average Validation Loss: 0.0348, Accuracy: 99.29%, Precision: 99.98%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0592, Average Validation Loss: 0.0338, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0679, Average Validation Loss: 0.0326, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0598, Average Validation Loss: 0.0330, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0656, Average Validation Loss: 0.0322, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0676, Average Validation Loss: 0.0310, Accuracy: 99.31%, Precision: 99.98%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0476, Average Validation Loss: 0.0299, Accuracy: 99.34%, Precision: 99.98%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0696, Average Validation Loss: 0.0301, Accuracy: 99.34%, Precision: 99.98%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0468, Average Validation Loss: 0.0302, Accuracy: 99.36%, Precision: 99.98%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0685, Average Validation Loss: 0.0285, Accuracy: 99.37%, Precision: 99.98%, Recall: 98.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0479, Average Validation Loss: 0.0288, Accuracy: 99.37%, Precision: 99.98%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0556, Average Validation Loss: 0.0315, Accuracy: 99.35%, Precision: 99.99%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0386, Average Validation Loss: 0.0324, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0644, Average Validation Loss: 0.0304, Accuracy: 99.35%, Precision: 99.98%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0515, Average Validation Loss: 0.0272, Accuracy: 99.41%, Precision: 99.98%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0454, Average Validation Loss: 0.0273, Accuracy: 99.40%, Precision: 99.97%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0675, Average Validation Loss: 0.0276, Accuracy: 99.40%, Precision: 99.98%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0585, Average Validation Loss: 0.0264, Accuracy: 99.41%, Precision: 99.96%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0563, Average Validation Loss: 0.0268, Accuracy: 99.42%, Precision: 99.98%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0499, Average Validation Loss: 0.0278, Accuracy: 99.41%, Precision: 99.98%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:38:52,297] Trial 28 finished with value: 0.027808212648724785 and parameters: {'vector_length': 128, 'num_layers': 3, 'layer_size': 64, 'dropout': 0.4, 'num_epochs': 4, 'lr': 3.578355771769988e-05, 'weight_decay': 0.00025323732433674026, 'warmup_steps': 20}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 5, with 27,275,520 parameters\n","Num non-decayed parameter tensors: 4, with 194 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2416, Average Validation Loss: 0.0448, Accuracy: 98.73%, Precision: 98.81%, Recall: 98.97%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0742, Average Validation Loss: 0.0485, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0353, Average Validation Loss: 0.0481, Accuracy: 99.21%, Precision: 99.99%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0312, Average Validation Loss: 0.0403, Accuracy: 99.28%, Precision: 99.93%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0846, Average Validation Loss: 0.0314, Accuracy: 99.31%, Precision: 99.98%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0527, Average Validation Loss: 0.0318, Accuracy: 99.26%, Precision: 99.67%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0375, Average Validation Loss: 0.0390, Accuracy: 99.30%, Precision: 99.90%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0511, Average Validation Loss: 0.0361, Accuracy: 99.30%, Precision: 99.86%, Recall: 98.92%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0695, Average Validation Loss: 0.0337, Accuracy: 99.27%, Precision: 99.98%, Recall: 98.76%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0372, Average Validation Loss: 0.0296, Accuracy: 99.34%, Precision: 99.95%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0443, Average Validation Loss: 0.0358, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0332, Accuracy: 99.30%, Precision: 99.84%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0316, Average Validation Loss: 0.0356, Accuracy: 99.32%, Precision: 99.93%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0330, Average Validation Loss: 0.0292, Accuracy: 99.35%, Precision: 99.76%, Recall: 99.10%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0296, Average Validation Loss: 0.0307, Accuracy: 99.31%, Precision: 99.61%, Recall: 99.19%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:40:12,521] Trial 29 finished with value: 0.03171008243854787 and parameters: {'vector_length': 1024, 'num_layers': 3, 'layer_size': 64, 'dropout': 0.30000000000000004, 'num_epochs': 1, 'lr': 0.0007362923264280894, 'weight_decay': 8.744196125424576e-05, 'warmup_steps': 70}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 11,033,344 parameters\n","Num non-decayed parameter tensors: 3, with 258 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5359, Average Validation Loss: 0.0762, Accuracy: 99.11%, Precision: 99.86%, Recall: 98.61%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1003, Average Validation Loss: 0.1006, Accuracy: 99.06%, Precision: 100.00%, Recall: 98.39%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0850, Average Validation Loss: 0.0549, Accuracy: 99.26%, Precision: 99.93%, Recall: 98.79%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0417, Average Validation Loss: 0.0369, Accuracy: 99.32%, Precision: 99.82%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0480, Average Validation Loss: 0.0519, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0467, Average Validation Loss: 0.0426, Accuracy: 99.25%, Precision: 99.96%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0190, Average Validation Loss: 0.0543, Accuracy: 99.27%, Precision: 99.96%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.1013, Average Validation Loss: 0.0433, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0634, Average Validation Loss: 0.0308, Accuracy: 99.27%, Precision: 100.00%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0474, Average Validation Loss: 0.0333, Accuracy: 99.27%, Precision: 100.00%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0413, Average Validation Loss: 0.0244, Accuracy: 99.38%, Precision: 99.97%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0769, Average Validation Loss: 0.0334, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0594, Average Validation Loss: 0.0269, Accuracy: 99.27%, Precision: 100.00%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0736, Average Validation Loss: 0.0351, Accuracy: 99.39%, Precision: 99.96%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0460, Average Validation Loss: 0.0323, Accuracy: 99.30%, Precision: 100.00%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0238, Average Validation Loss: 0.0478, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:41:32,266] Trial 30 finished with value: 0.0477858893123748 and parameters: {'vector_length': 256, 'num_layers': 2, 'layer_size': 128, 'dropout': 0.5, 'num_epochs': 2, 'lr': 0.002838721773881476, 'weight_decay': 5.2791164573314764e-05, 'warmup_steps': 10}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4921, Average Validation Loss: 0.2596, Accuracy: 96.45%, Precision: 99.93%, Recall: 94.22%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.1609, Average Validation Loss: 0.0774, Accuracy: 99.02%, Precision: 99.64%, Recall: 98.66%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0606, Average Validation Loss: 0.0415, Accuracy: 99.19%, Precision: 99.96%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0334, Average Validation Loss: 0.0310, Accuracy: 99.33%, Precision: 99.94%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0414, Average Validation Loss: 0.0296, Accuracy: 99.35%, Precision: 99.89%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0307, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0310, Average Validation Loss: 0.0267, Accuracy: 99.38%, Precision: 99.92%, Recall: 99.00%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0205, Average Validation Loss: 0.0292, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0391, Average Validation Loss: 0.0251, Accuracy: 99.41%, Precision: 99.93%, Recall: 99.04%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0288, Average Validation Loss: 0.0254, Accuracy: 99.38%, Precision: 99.98%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0341, Average Validation Loss: 0.0245, Accuracy: 99.45%, Precision: 99.91%, Recall: 99.13%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0255, Accuracy: 99.38%, Precision: 99.98%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0369, Average Validation Loss: 0.0238, Accuracy: 99.45%, Precision: 99.93%, Recall: 99.12%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0234, Average Validation Loss: 0.0242, Accuracy: 99.41%, Precision: 99.97%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0150, Average Validation Loss: 0.0238, Accuracy: 99.44%, Precision: 99.97%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0108, Average Validation Loss: 0.0261, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0443, Average Validation Loss: 0.0223, Accuracy: 99.47%, Precision: 99.93%, Recall: 99.15%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0229, Average Validation Loss: 0.0219, Accuracy: 99.47%, Precision: 99.93%, Recall: 99.16%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0211, Average Validation Loss: 0.0222, Accuracy: 99.46%, Precision: 99.97%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0309, Average Validation Loss: 0.0209, Accuracy: 99.48%, Precision: 99.94%, Recall: 99.16%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0330, Average Validation Loss: 0.0205, Accuracy: 99.50%, Precision: 99.97%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0324, Average Validation Loss: 0.0202, Accuracy: 99.50%, Precision: 99.98%, Recall: 99.16%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0178, Average Validation Loss: 0.0208, Accuracy: 99.49%, Precision: 100.00%, Recall: 99.11%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0238, Average Validation Loss: 0.0200, Accuracy: 99.52%, Precision: 100.00%, Recall: 99.16%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0199, Average Validation Loss: 0.0198, Accuracy: 99.52%, Precision: 99.99%, Recall: 99.17%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0175, Average Validation Loss: 0.0214, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0190, Accuracy: 99.52%, Precision: 99.96%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0198, Average Validation Loss: 0.0186, Accuracy: 99.53%, Precision: 99.96%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0264, Average Validation Loss: 0.0182, Accuracy: 99.53%, Precision: 99.97%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0089, Average Validation Loss: 0.0271, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0240, Average Validation Loss: 0.0180, Accuracy: 99.52%, Precision: 99.99%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0135, Average Validation Loss: 0.0180, Accuracy: 99.51%, Precision: 99.99%, Recall: 99.16%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0159, Average Validation Loss: 0.0197, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:44:14,006] Trial 31 finished with value: 0.019706283251100496 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.4, 'num_epochs': 2, 'lr': 3.517269500784435e-05, 'weight_decay': 2.3139010241272728e-05, 'warmup_steps': 90}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6195, Average Validation Loss: 0.5452, Accuracy: 63.34%, Precision: 100.00%, Recall: 60.94%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.4785, Average Validation Loss: 0.4081, Accuracy: 90.20%, Precision: 100.00%, Recall: 85.37%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.3640, Average Validation Loss: 0.2876, Accuracy: 96.54%, Precision: 99.96%, Recall: 94.34%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2507, Average Validation Loss: 0.1927, Accuracy: 97.93%, Precision: 99.94%, Recall: 96.57%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1714, Average Validation Loss: 0.1287, Accuracy: 98.60%, Precision: 99.93%, Recall: 97.67%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1245, Average Validation Loss: 0.0904, Accuracy: 99.05%, Precision: 99.93%, Recall: 98.44%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0852, Average Validation Loss: 0.0686, Accuracy: 99.08%, Precision: 99.96%, Recall: 98.46%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0703, Average Validation Loss: 0.0550, Accuracy: 99.18%, Precision: 99.96%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0560, Average Validation Loss: 0.0472, Accuracy: 99.23%, Precision: 99.96%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0428, Average Validation Loss: 0.0441, Accuracy: 99.20%, Precision: 99.99%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0455, Average Validation Loss: 0.0385, Accuracy: 99.26%, Precision: 99.98%, Recall: 98.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0383, Average Validation Loss: 0.0361, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0430, Average Validation Loss: 0.0353, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.71%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0320, Average Validation Loss: 0.0333, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0418, Average Validation Loss: 0.0318, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0278, Average Validation Loss: 0.0317, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0339, Average Validation Loss: 0.0303, Accuracy: 99.35%, Precision: 99.98%, Recall: 98.90%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0374, Average Validation Loss: 0.0298, Accuracy: 99.33%, Precision: 99.98%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0386, Average Validation Loss: 0.0295, Accuracy: 99.33%, Precision: 99.98%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0375, Average Validation Loss: 0.0289, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0407, Average Validation Loss: 0.0287, Accuracy: 99.38%, Precision: 99.98%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0338, Average Validation Loss: 0.0283, Accuracy: 99.36%, Precision: 99.98%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0192, Average Validation Loss: 0.0280, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0276, Accuracy: 99.36%, Precision: 99.98%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0210, Average Validation Loss: 0.0269, Accuracy: 99.38%, Precision: 99.97%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0298, Average Validation Loss: 0.0266, Accuracy: 99.38%, Precision: 99.97%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0187, Average Validation Loss: 0.0271, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0184, Average Validation Loss: 0.0275, Accuracy: 99.35%, Precision: 99.99%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0367, Average Validation Loss: 0.0263, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0232, Average Validation Loss: 0.0256, Accuracy: 99.41%, Precision: 99.97%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0380, Average Validation Loss: 0.0252, Accuracy: 99.42%, Precision: 99.96%, Recall: 99.04%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0433, Average Validation Loss: 0.0251, Accuracy: 99.43%, Precision: 99.95%, Recall: 99.06%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0335, Average Validation Loss: 0.0251, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0204, Average Validation Loss: 0.0250, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0182, Average Validation Loss: 0.0253, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0270, Average Validation Loss: 0.0244, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:47:09,716] Trial 32 finished with value: 0.024364689703577677 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.4, 'num_epochs': 1, 'lr': 1.0862051423820923e-05, 'weight_decay': 1.0494093510105466e-05, 'warmup_steps': 90}. Best is trial 12 with value: 0.014669710158911609.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3662, Average Validation Loss: 0.1036, Accuracy: 98.40%, Precision: 99.89%, Recall: 97.38%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0655, Average Validation Loss: 0.0333, Accuracy: 99.23%, Precision: 99.86%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0307, Average Validation Loss: 0.0295, Accuracy: 99.27%, Precision: 99.90%, Recall: 98.85%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0389, Average Validation Loss: 0.0280, Accuracy: 99.33%, Precision: 99.94%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0347, Average Validation Loss: 0.0263, Accuracy: 99.36%, Precision: 99.93%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0155, Average Validation Loss: 0.0347, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0481, Average Validation Loss: 0.0317, Accuracy: 99.39%, Precision: 99.74%, Recall: 99.20%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0321, Average Validation Loss: 0.0259, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0391, Average Validation Loss: 0.0224, Accuracy: 99.46%, Precision: 99.96%, Recall: 99.10%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0310, Average Validation Loss: 0.0270, Accuracy: 99.36%, Precision: 100.00%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0369, Average Validation Loss: 0.0227, Accuracy: 99.44%, Precision: 100.00%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0110, Average Validation Loss: 0.0212, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0096, Average Validation Loss: 0.0248, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0193, Average Validation Loss: 0.0204, Accuracy: 99.46%, Precision: 100.00%, Recall: 99.06%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0219, Accuracy: 99.44%, Precision: 100.00%, Recall: 99.03%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0323, Average Validation Loss: 0.0198, Accuracy: 99.53%, Precision: 99.93%, Recall: 99.25%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0178, Average Validation Loss: 0.0203, Accuracy: 99.47%, Precision: 99.99%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0328, Average Validation Loss: 0.0197, Accuracy: 99.50%, Precision: 99.99%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0179, Average Validation Loss: 0.0197, Accuracy: 99.50%, Precision: 99.99%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0314, Average Validation Loss: 0.0189, Accuracy: 99.58%, Precision: 99.93%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0182, Accuracy: 99.52%, Precision: 99.99%, Recall: 99.17%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0156, Average Validation Loss: 0.0269, Accuracy: 99.37%, Precision: 100.00%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0203, Average Validation Loss: 0.0168, Accuracy: 99.58%, Precision: 99.95%, Recall: 99.33%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0119, Average Validation Loss: 0.0182, Accuracy: 99.54%, Precision: 99.99%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0213, Average Validation Loss: 0.0164, Accuracy: 99.57%, Precision: 99.96%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0212, Average Validation Loss: 0.0176, Accuracy: 99.55%, Precision: 100.00%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0207, Average Validation Loss: 0.0185, Accuracy: 99.51%, Precision: 100.00%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0242, Average Validation Loss: 0.0157, Accuracy: 99.59%, Precision: 99.98%, Recall: 99.31%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0167, Average Validation Loss: 0.0174, Accuracy: 99.53%, Precision: 100.00%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0131, Average Validation Loss: 0.0149, Accuracy: 99.61%, Precision: 99.95%, Recall: 99.38%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0144, Average Validation Loss: 0.0170, Accuracy: 99.55%, Precision: 99.99%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0209, Average Validation Loss: 0.0145, Accuracy: 99.60%, Precision: 99.89%, Recall: 99.41%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0101, Average Validation Loss: 0.0161, Accuracy: 99.55%, Precision: 99.99%, Recall: 99.24%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0111, Average Validation Loss: 0.0139, Accuracy: 99.62%, Precision: 99.88%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0332, Average Validation Loss: 0.0142, Accuracy: 99.58%, Precision: 99.95%, Recall: 99.33%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0259, Average Validation Loss: 0.0132, Accuracy: 99.63%, Precision: 99.90%, Recall: 99.45%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0132, Accuracy: 99.60%, Precision: 99.87%, Recall: 99.43%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0137, Average Validation Loss: 0.0201, Accuracy: 99.49%, Precision: 100.00%, Recall: 99.11%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0088, Average Validation Loss: 0.0192, Accuracy: 99.50%, Precision: 100.00%, Recall: 99.13%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0192, Average Validation Loss: 0.0134, Accuracy: 99.65%, Precision: 99.91%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0242, Average Validation Loss: 0.0141, Accuracy: 99.63%, Precision: 100.00%, Recall: 99.35%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:50:30,531] Trial 33 finished with value: 0.01404915655038093 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.30000000000000004, 'num_epochs': 2, 'lr': 5.880481148892314e-05, 'weight_decay': 1.0456198819636015e-05, 'warmup_steps': 100}. Best is trial 33 with value: 0.01404915655038093.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 144,993,280 parameters\n","Num non-decayed parameter tensors: 3, with 1,026 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.1884, Average Validation Loss: 0.0404, Accuracy: 99.18%, Precision: 99.79%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0466, Average Validation Loss: 0.0363, Accuracy: 99.28%, Precision: 99.93%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0359, Average Validation Loss: 0.0463, Accuracy: 99.20%, Precision: 99.98%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0442, Average Validation Loss: 0.0322, Accuracy: 99.29%, Precision: 99.89%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0613, Average Validation Loss: 0.0288, Accuracy: 99.35%, Precision: 99.97%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0322, Average Validation Loss: 0.0391, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.71%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0286, Average Validation Loss: 0.0377, Accuracy: 99.32%, Precision: 100.00%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0520, Average Validation Loss: 0.0277, Accuracy: 99.38%, Precision: 99.79%, Recall: 99.12%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0500, Average Validation Loss: 0.0336, Accuracy: 99.34%, Precision: 99.96%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0289, Average Validation Loss: 0.0276, Accuracy: 99.35%, Precision: 99.85%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0407, Average Validation Loss: 0.0277, Accuracy: 99.30%, Precision: 99.66%, Recall: 99.11%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0527, Average Validation Loss: 0.0397, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0240, Average Validation Loss: 0.0268, Accuracy: 99.40%, Precision: 99.96%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:51:43,584] Trial 34 finished with value: 0.026781683236461233 and parameters: {'vector_length': 1024, 'num_layers': 2, 'layer_size': 512, 'dropout': 0.30000000000000004, 'num_epochs': 3, 'lr': 7.646792764153977e-05, 'weight_decay': 1.140615903501801e-05, 'warmup_steps': 90}. Best is trial 33 with value: 0.01404915655038093.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 11,016,960 parameters\n","Num non-decayed parameter tensors: 2, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2749, Average Validation Loss: 0.0577, Accuracy: 98.39%, Precision: 98.11%, Recall: 99.06%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0197, Average Validation Loss: 0.0523, Accuracy: 99.22%, Precision: 99.92%, Recall: 98.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0855, Average Validation Loss: 0.0507, Accuracy: 99.29%, Precision: 99.95%, Recall: 98.82%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0355, Average Validation Loss: 0.0379, Accuracy: 99.33%, Precision: 99.91%, Recall: 98.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0499, Average Validation Loss: 0.0328, Accuracy: 99.22%, Precision: 99.50%, Recall: 99.13%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0445, Average Validation Loss: 0.0333, Accuracy: 99.33%, Precision: 99.90%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0689, Average Validation Loss: 0.0297, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0331, Average Validation Loss: 0.0283, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0449, Average Validation Loss: 0.0237, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0252, Average Validation Loss: 0.0215, Accuracy: 99.43%, Precision: 99.93%, Recall: 99.08%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0522, Average Validation Loss: 0.0262, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0326, Average Validation Loss: 0.0206, Accuracy: 99.49%, Precision: 99.96%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0302, Average Validation Loss: 0.0334, Accuracy: 99.35%, Precision: 100.00%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0423, Average Validation Loss: 0.0273, Accuracy: 99.33%, Precision: 99.42%, Recall: 99.41%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0225, Average Validation Loss: 0.0226, Accuracy: 99.42%, Precision: 99.98%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:52:58,309] Trial 35 finished with value: 0.022653540032538208 and parameters: {'vector_length': 256, 'num_layers': 1, 'layer_size': 128, 'dropout': 0.2, 'num_epochs': 5, 'lr': 0.000301922095277835, 'weight_decay': 5.7985312734793214e-06, 'warmup_steps': 70}. Best is trial 33 with value: 0.01404915655038093.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 6, with 5,560,960 parameters\n","Num non-decayed parameter tensors: 5, with 514 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5003, Average Validation Loss: 0.1693, Accuracy: 98.38%, Precision: 99.84%, Recall: 97.40%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0571, Average Validation Loss: 0.0432, Accuracy: 99.22%, Precision: 99.69%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0922, Average Validation Loss: 0.0310, Accuracy: 99.32%, Precision: 99.72%, Recall: 99.10%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0365, Average Validation Loss: 0.0302, Accuracy: 99.38%, Precision: 99.98%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0447, Average Validation Loss: 0.0249, Accuracy: 99.36%, Precision: 99.96%, Recall: 98.94%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0350, Average Validation Loss: 0.0325, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0359, Average Validation Loss: 0.0243, Accuracy: 99.38%, Precision: 99.98%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0083, Average Validation Loss: 0.0329, Accuracy: 99.26%, Precision: 100.00%, Recall: 98.73%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0248, Average Validation Loss: 0.0241, Accuracy: 99.38%, Precision: 99.59%, Recall: 99.32%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0505, Average Validation Loss: 0.0236, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.02%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0281, Average Validation Loss: 0.0211, Accuracy: 99.47%, Precision: 99.96%, Recall: 99.12%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0190, Average Validation Loss: 0.0224, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0240, Average Validation Loss: 0.0188, Accuracy: 99.50%, Precision: 99.93%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0229, Average Validation Loss: 0.0276, Accuracy: 99.43%, Precision: 99.99%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0359, Average Validation Loss: 0.0204, Accuracy: 99.49%, Precision: 99.98%, Recall: 99.14%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0203, Accuracy: 99.44%, Precision: 100.00%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0259, Average Validation Loss: 0.0166, Accuracy: 99.56%, Precision: 99.93%, Recall: 99.31%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0157, Accuracy: 99.56%, Precision: 99.95%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0144, Accuracy: 99.57%, Precision: 99.89%, Recall: 99.37%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0133, Average Validation Loss: 0.0147, Accuracy: 99.59%, Precision: 99.90%, Recall: 99.39%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0196, Average Validation Loss: 0.0129, Accuracy: 99.62%, Precision: 99.90%, Recall: 99.44%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0199, Average Validation Loss: 0.0133, Accuracy: 99.61%, Precision: 99.98%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0206, Average Validation Loss: 0.0131, Accuracy: 99.66%, Precision: 99.91%, Recall: 99.49%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0125, Average Validation Loss: 0.0121, Accuracy: 99.65%, Precision: 99.84%, Recall: 99.55%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0115, Accuracy: 99.68%, Precision: 99.88%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0200, Average Validation Loss: 0.0133, Accuracy: 99.68%, Precision: 99.99%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0204, Average Validation Loss: 0.0111, Accuracy: 99.71%, Precision: 99.89%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0207, Average Validation Loss: 0.0168, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.09%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0123, Accuracy: 99.64%, Precision: 100.00%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0217, Average Validation Loss: 0.0104, Accuracy: 99.74%, Precision: 99.99%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0098, Average Validation Loss: 0.0103, Accuracy: 99.73%, Precision: 99.96%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0216, Average Validation Loss: 0.0101, Accuracy: 99.73%, Precision: 99.94%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0141, Average Validation Loss: 0.0114, Accuracy: 99.71%, Precision: 99.81%, Recall: 99.68%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0078, Average Validation Loss: 0.0105, Accuracy: 99.73%, Precision: 99.94%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0321, Average Validation Loss: 0.0144, Accuracy: 99.65%, Precision: 100.00%, Recall: 99.40%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:55:51,552] Trial 36 finished with value: 0.01397774032745007 and parameters: {'vector_length': 128, 'num_layers': 4, 'layer_size': 128, 'dropout': 0.1, 'num_epochs': 1, 'lr': 0.0004667023685525831, 'weight_decay': 3.790633974149675e-06, 'warmup_steps': 80}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 6, with 18,901,120 parameters\n","Num non-decayed parameter tensors: 5, with 2,050 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2804, Average Validation Loss: 0.0840, Accuracy: 98.69%, Precision: 98.57%, Recall: 99.14%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2210, Average Validation Loss: 0.0632, Accuracy: 97.96%, Precision: 100.00%, Recall: 96.55%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0355, Average Validation Loss: 0.0401, Accuracy: 99.11%, Precision: 100.00%, Recall: 98.47%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0358, Average Validation Loss: 0.0375, Accuracy: 99.31%, Precision: 99.78%, Recall: 99.02%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0309, Average Validation Loss: 0.0385, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.74%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0496, Average Validation Loss: 0.0250, Accuracy: 99.38%, Precision: 99.99%, Recall: 98.94%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0281, Average Validation Loss: 0.0305, Accuracy: 99.16%, Precision: 99.18%, Recall: 99.36%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0178, Average Validation Loss: 0.0221, Accuracy: 99.44%, Precision: 99.81%, Recall: 99.20%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0345, Average Validation Loss: 0.0208, Accuracy: 99.47%, Precision: 99.95%, Recall: 99.12%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0233, Average Validation Loss: 0.0231, Accuracy: 99.40%, Precision: 99.51%, Recall: 99.44%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0184, Average Validation Loss: 0.0183, Accuracy: 99.52%, Precision: 99.81%, Recall: 99.34%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0226, Average Validation Loss: 0.0303, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0239, Average Validation Loss: 0.0246, Accuracy: 99.42%, Precision: 99.48%, Recall: 99.51%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0152, Average Validation Loss: 0.0281, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0203, Average Validation Loss: 0.0176, Accuracy: 99.57%, Precision: 99.91%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0121, Average Validation Loss: 0.0176, Accuracy: 99.56%, Precision: 99.79%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:57:12,001] Trial 37 finished with value: 0.017645871321469345 and parameters: {'vector_length': 128, 'num_layers': 4, 'layer_size': 512, 'dropout': 0.1, 'num_epochs': 1, 'lr': 0.0007744048659258925, 'weight_decay': 2.9132315370790403e-06, 'warmup_steps': 80}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 3,415,424 parameters\n","Num non-decayed parameter tensors: 3, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3859, Average Validation Loss: 0.1064, Accuracy: 97.89%, Precision: 99.82%, Recall: 96.61%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0591, Average Validation Loss: 0.0326, Accuracy: 99.23%, Precision: 99.79%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0341, Average Validation Loss: 0.0297, Accuracy: 99.31%, Precision: 99.90%, Recall: 98.90%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0573, Average Validation Loss: 0.0280, Accuracy: 99.32%, Precision: 99.93%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0404, Average Validation Loss: 0.0286, Accuracy: 99.30%, Precision: 99.96%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0293, Average Validation Loss: 0.0276, Accuracy: 99.33%, Precision: 99.96%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0276, Average Validation Loss: 0.0245, Accuracy: 99.31%, Precision: 99.57%, Recall: 99.23%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0216, Average Validation Loss: 0.0255, Accuracy: 99.40%, Precision: 99.93%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0363, Average Validation Loss: 0.0212, Accuracy: 99.43%, Precision: 99.85%, Recall: 99.15%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0202, Average Validation Loss: 0.0213, Accuracy: 99.43%, Precision: 99.90%, Recall: 99.11%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0301, Average Validation Loss: 0.0218, Accuracy: 99.45%, Precision: 99.73%, Recall: 99.32%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0221, Accuracy: 99.43%, Precision: 99.92%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0352, Average Validation Loss: 0.0223, Accuracy: 99.46%, Precision: 99.60%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0403, Average Validation Loss: 0.0179, Accuracy: 99.49%, Precision: 99.94%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0293, Average Validation Loss: 0.0197, Accuracy: 99.46%, Precision: 99.98%, Recall: 99.09%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0245, Average Validation Loss: 0.0233, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0300, Average Validation Loss: 0.0176, Accuracy: 99.61%, Precision: 99.80%, Recall: 99.52%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0150, Average Validation Loss: 0.0193, Accuracy: 99.50%, Precision: 99.99%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0199, Average Validation Loss: 0.0143, Accuracy: 99.64%, Precision: 99.82%, Recall: 99.54%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0137, Average Validation Loss: 0.0156, Accuracy: 99.58%, Precision: 99.94%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0173, Average Validation Loss: 0.0149, Accuracy: 99.57%, Precision: 99.67%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0283, Average Validation Loss: 0.0139, Accuracy: 99.58%, Precision: 99.87%, Recall: 99.41%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0179, Accuracy: 99.52%, Precision: 99.97%, Recall: 99.19%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0240, Average Validation Loss: 0.0175, Accuracy: 99.58%, Precision: 99.70%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 14:59:09,786] Trial 38 finished with value: 0.01678221602294896 and parameters: {'vector_length': 128, 'num_layers': 2, 'layer_size': 64, 'dropout': 0.1, 'num_epochs': 1, 'lr': 0.0004127168543723412, 'weight_decay': 4.1242107280084155e-06, 'warmup_steps': 100}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 6, with 5,560,960 parameters\n","Num non-decayed parameter tensors: 5, with 514 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6746, Average Validation Loss: 0.6441, Accuracy: 58.76%, Precision: 100.00%, Recall: 58.10%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.5978, Average Validation Loss: 0.5209, Accuracy: 79.04%, Precision: 100.00%, Recall: 73.18%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.4538, Average Validation Loss: 0.3346, Accuracy: 94.84%, Precision: 99.99%, Recall: 91.73%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2636, Average Validation Loss: 0.1601, Accuracy: 98.91%, Precision: 99.94%, Recall: 98.18%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1210, Average Validation Loss: 0.0646, Accuracy: 99.22%, Precision: 99.88%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0642, Average Validation Loss: 0.0366, Accuracy: 99.28%, Precision: 99.87%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0415, Average Validation Loss: 0.0302, Accuracy: 99.31%, Precision: 99.93%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0218, Average Validation Loss: 0.0287, Accuracy: 99.33%, Precision: 99.95%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0337, Average Validation Loss: 0.0295, Accuracy: 99.32%, Precision: 99.98%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0323, Average Validation Loss: 0.0270, Accuracy: 99.35%, Precision: 99.98%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0293, Average Validation Loss: 0.0265, Accuracy: 99.35%, Precision: 99.98%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0234, Average Validation Loss: 0.0222, Accuracy: 99.44%, Precision: 99.90%, Recall: 99.14%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0428, Average Validation Loss: 0.0222, Accuracy: 99.46%, Precision: 99.82%, Recall: 99.24%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0193, Average Validation Loss: 0.0249, Accuracy: 99.39%, Precision: 99.98%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0314, Average Validation Loss: 0.0206, Accuracy: 99.48%, Precision: 99.93%, Recall: 99.17%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0391, Average Validation Loss: 0.0206, Accuracy: 99.47%, Precision: 99.94%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0213, Average Validation Loss: 0.0221, Accuracy: 99.46%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0294, Average Validation Loss: 0.0184, Accuracy: 99.53%, Precision: 99.89%, Recall: 99.29%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0191, Average Validation Loss: 0.0210, Accuracy: 99.48%, Precision: 99.99%, Recall: 99.11%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0265, Average Validation Loss: 0.0176, Accuracy: 99.54%, Precision: 99.96%, Recall: 99.24%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0162, Average Validation Loss: 0.0224, Accuracy: 99.46%, Precision: 100.00%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0302, Average Validation Loss: 0.0174, Accuracy: 99.57%, Precision: 99.81%, Recall: 99.44%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0234, Average Validation Loss: 0.0193, Accuracy: 99.50%, Precision: 99.99%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0193, Average Validation Loss: 0.0169, Accuracy: 99.56%, Precision: 99.78%, Recall: 99.46%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0348, Average Validation Loss: 0.0183, Accuracy: 99.57%, Precision: 100.00%, Recall: 99.25%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0200, Average Validation Loss: 0.0200, Accuracy: 99.50%, Precision: 100.00%, Recall: 99.13%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0278, Average Validation Loss: 0.0173, Accuracy: 99.61%, Precision: 99.77%, Recall: 99.54%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:01:23,339] Trial 39 finished with value: 0.017387194521221762 and parameters: {'vector_length': 128, 'num_layers': 4, 'layer_size': 128, 'dropout': 0.1, 'num_epochs': 1, 'lr': 9.293086925261736e-05, 'weight_decay': 1.8153977518245334e-06, 'warmup_steps': 90}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 18,376,832 parameters\n","Num non-decayed parameter tensors: 3, with 1,026 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6834, Average Validation Loss: 0.6634, Accuracy: 61.69%, Precision: 99.99%, Recall: 59.89%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6463, Average Validation Loss: 0.6316, Accuracy: 60.94%, Precision: 100.00%, Recall: 59.42%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6175, Average Validation Loss: 0.5991, Accuracy: 62.60%, Precision: 100.00%, Recall: 60.46%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5874, Average Validation Loss: 0.5640, Accuracy: 66.32%, Precision: 100.00%, Recall: 62.93%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5445, Average Validation Loss: 0.5234, Accuracy: 71.89%, Precision: 100.00%, Recall: 67.04%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5066, Average Validation Loss: 0.4776, Accuracy: 84.78%, Precision: 100.00%, Recall: 78.98%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4527, Average Validation Loss: 0.4277, Accuracy: 91.17%, Precision: 100.00%, Recall: 86.63%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4086, Average Validation Loss: 0.3755, Accuracy: 93.50%, Precision: 100.00%, Recall: 89.79%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3416, Average Validation Loss: 0.3227, Accuracy: 94.80%, Precision: 100.00%, Recall: 91.67%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3034, Average Validation Loss: 0.2713, Accuracy: 96.34%, Precision: 99.99%, Recall: 93.98%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2650, Average Validation Loss: 0.2253, Accuracy: 97.90%, Precision: 99.97%, Recall: 96.48%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2134, Average Validation Loss: 0.1845, Accuracy: 98.27%, Precision: 99.97%, Recall: 97.10%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1712, Average Validation Loss: 0.1511, Accuracy: 98.24%, Precision: 99.97%, Recall: 97.03%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1543, Average Validation Loss: 0.1230, Accuracy: 98.83%, Precision: 99.96%, Recall: 98.03%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1118, Average Validation Loss: 0.1014, Accuracy: 98.97%, Precision: 99.96%, Recall: 98.27%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0954, Average Validation Loss: 0.0857, Accuracy: 99.02%, Precision: 99.96%, Recall: 98.34%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0850, Average Validation Loss: 0.0739, Accuracy: 99.08%, Precision: 99.97%, Recall: 98.45%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0683, Average Validation Loss: 0.0654, Accuracy: 99.12%, Precision: 99.97%, Recall: 98.52%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0811, Average Validation Loss: 0.0586, Accuracy: 99.23%, Precision: 99.96%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0488, Average Validation Loss: 0.0534, Accuracy: 99.26%, Precision: 99.95%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0630, Average Validation Loss: 0.0494, Accuracy: 99.23%, Precision: 99.98%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0448, Average Validation Loss: 0.0466, Accuracy: 99.25%, Precision: 99.97%, Recall: 98.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0571, Average Validation Loss: 0.0433, Accuracy: 99.27%, Precision: 99.96%, Recall: 98.79%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0432, Average Validation Loss: 0.0413, Accuracy: 99.25%, Precision: 99.98%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0325, Average Validation Loss: 0.0394, Accuracy: 99.26%, Precision: 99.98%, Recall: 98.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0627, Average Validation Loss: 0.0372, Accuracy: 99.32%, Precision: 99.97%, Recall: 98.85%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0468, Average Validation Loss: 0.0363, Accuracy: 99.32%, Precision: 99.95%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0423, Average Validation Loss: 0.0346, Accuracy: 99.32%, Precision: 99.97%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0361, Average Validation Loss: 0.0346, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0409, Average Validation Loss: 0.0332, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0343, Average Validation Loss: 0.0320, Accuracy: 99.33%, Precision: 99.98%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0228, Average Validation Loss: 0.0317, Accuracy: 99.33%, Precision: 99.98%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0377, Average Validation Loss: 0.0307, Accuracy: 99.33%, Precision: 99.98%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.0304, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0354, Average Validation Loss: 0.0297, Accuracy: 99.34%, Precision: 99.98%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0453, Average Validation Loss: 0.0288, Accuracy: 99.35%, Precision: 99.96%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0395, Average Validation Loss: 0.0287, Accuracy: 99.36%, Precision: 99.93%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0279, Average Validation Loss: 0.0279, Accuracy: 99.35%, Precision: 99.96%, Recall: 98.92%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0244, Average Validation Loss: 0.0281, Accuracy: 99.34%, Precision: 99.98%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0320, Average Validation Loss: 0.0281, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0374, Average Validation Loss: 0.0268, Accuracy: 99.37%, Precision: 99.96%, Recall: 98.94%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0247, Average Validation Loss: 0.0266, Accuracy: 99.36%, Precision: 99.96%, Recall: 98.92%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0250, Average Validation Loss: 0.0267, Accuracy: 99.35%, Precision: 99.96%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0304, Average Validation Loss: 0.0270, Accuracy: 99.34%, Precision: 99.98%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0374, Average Validation Loss: 0.0256, Accuracy: 99.37%, Precision: 99.96%, Recall: 98.95%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0252, Average Validation Loss: 0.0253, Accuracy: 99.39%, Precision: 99.96%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0290, Average Validation Loss: 0.0253, Accuracy: 99.36%, Precision: 99.97%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0230, Average Validation Loss: 0.0252, Accuracy: 99.36%, Precision: 99.97%, Recall: 98.92%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0376, Average Validation Loss: 0.0248, Accuracy: 99.37%, Precision: 99.97%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0294, Average Validation Loss: 0.0242, Accuracy: 99.41%, Precision: 99.96%, Recall: 99.02%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0370, Average Validation Loss: 0.0240, Accuracy: 99.41%, Precision: 99.96%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.0239, Accuracy: 99.40%, Precision: 99.97%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0316, Average Validation Loss: 0.0237, Accuracy: 99.41%, Precision: 99.96%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0234, Accuracy: 99.42%, Precision: 99.96%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0284, Average Validation Loss: 0.0235, Accuracy: 99.40%, Precision: 99.96%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:05:51,181] Trial 40 finished with value: 0.02346751859059205 and parameters: {'vector_length': 128, 'num_layers': 2, 'layer_size': 512, 'dropout': 0.30000000000000004, 'num_epochs': 1, 'lr': 6.3960962923017345e-06, 'weight_decay': 6.698426604128356e-06, 'warmup_steps': 90}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 3,415,424 parameters\n","Num non-decayed parameter tensors: 3, with 130 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3405, Average Validation Loss: 0.0619, Accuracy: 98.74%, Precision: 99.78%, Recall: 98.05%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0593, Average Validation Loss: 0.0302, Accuracy: 99.23%, Precision: 99.70%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0227, Average Validation Loss: 0.0302, Accuracy: 99.30%, Precision: 99.93%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0236, Average Validation Loss: 0.0302, Accuracy: 99.31%, Precision: 99.94%, Recall: 98.87%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.0403, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0295, Average Validation Loss: 0.0341, Accuracy: 99.29%, Precision: 100.00%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0278, Average Validation Loss: 0.0320, Accuracy: 99.28%, Precision: 100.00%, Recall: 98.76%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:06:27,435] Trial 41 finished with value: 0.03205034329203536 and parameters: {'vector_length': 128, 'num_layers': 2, 'layer_size': 64, 'dropout': 0.1, 'num_epochs': 1, 'lr': 0.00045022820768780933, 'weight_decay': 3.961444011122995e-06, 'warmup_steps': 100}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 3,411,328 parameters\n","Num non-decayed parameter tensors: 2, with 66 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2298, Average Validation Loss: 0.0472, Accuracy: 98.75%, Precision: 98.86%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0502, Average Validation Loss: 0.0375, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0241, Average Validation Loss: 0.0388, Accuracy: 99.23%, Precision: 99.96%, Recall: 98.71%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0424, Average Validation Loss: 0.0325, Accuracy: 99.18%, Precision: 99.40%, Recall: 99.16%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0363, Average Validation Loss: 0.0299, Accuracy: 99.34%, Precision: 99.87%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0173, Average Validation Loss: 0.0278, Accuracy: 99.27%, Precision: 99.59%, Recall: 99.14%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0269, Accuracy: 99.38%, Precision: 99.73%, Recall: 99.19%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0335, Average Validation Loss: 0.0250, Accuracy: 99.33%, Precision: 99.65%, Recall: 99.18%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0300, Average Validation Loss: 0.0245, Accuracy: 99.29%, Precision: 99.53%, Recall: 99.22%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0417, Average Validation Loss: 0.0220, Accuracy: 99.40%, Precision: 99.83%, Recall: 99.12%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0100, Average Validation Loss: 0.0228, Accuracy: 99.42%, Precision: 99.91%, Recall: 99.09%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0231, Accuracy: 99.44%, Precision: 99.95%, Recall: 99.09%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0190, Accuracy: 99.47%, Precision: 99.81%, Recall: 99.27%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0182, Average Validation Loss: 0.0219, Accuracy: 99.44%, Precision: 99.96%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0201, Average Validation Loss: 0.0191, Accuracy: 99.45%, Precision: 99.78%, Recall: 99.27%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0345, Average Validation Loss: 0.0256, Accuracy: 99.37%, Precision: 99.35%, Recall: 99.55%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0244, Average Validation Loss: 0.0212, Accuracy: 99.42%, Precision: 99.96%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0300, Average Validation Loss: 0.0385, Accuracy: 98.98%, Precision: 98.52%, Recall: 99.69%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:07:57,470] Trial 42 finished with value: 0.03825575506465661 and parameters: {'vector_length': 128, 'num_layers': 1, 'layer_size': 64, 'dropout': 0.1, 'num_epochs': 1, 'lr': 0.0004206172790091552, 'weight_decay': 3.789762971939161e-06, 'warmup_steps': 100}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 3,411,328 parameters\n","Num non-decayed parameter tensors: 2, with 66 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5586, Average Validation Loss: 0.3935, Accuracy: 90.82%, Precision: 100.00%, Recall: 86.17%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.2906, Average Validation Loss: 0.1764, Accuracy: 97.85%, Precision: 99.76%, Recall: 96.60%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1305, Average Validation Loss: 0.0848, Accuracy: 98.92%, Precision: 99.79%, Recall: 98.35%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0728, Average Validation Loss: 0.0531, Accuracy: 99.20%, Precision: 99.85%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0516, Average Validation Loss: 0.0403, Accuracy: 99.25%, Precision: 99.93%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.0349, Accuracy: 99.31%, Precision: 99.97%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0346, Average Validation Loss: 0.0321, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0333, Average Validation Loss: 0.0302, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0319, Average Validation Loss: 0.0290, Accuracy: 99.35%, Precision: 99.99%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0401, Average Validation Loss: 0.0281, Accuracy: 99.36%, Precision: 99.97%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0320, Average Validation Loss: 0.0270, Accuracy: 99.37%, Precision: 99.98%, Recall: 98.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0281, Average Validation Loss: 0.0265, Accuracy: 99.35%, Precision: 99.99%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0353, Average Validation Loss: 0.0257, Accuracy: 99.41%, Precision: 99.98%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0323, Average Validation Loss: 0.0250, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0261, Average Validation Loss: 0.0248, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0229, Average Validation Loss: 0.0236, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0340, Average Validation Loss: 0.0233, Accuracy: 99.45%, Precision: 99.98%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0198, Average Validation Loss: 0.0228, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0214, Average Validation Loss: 0.0223, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0317, Average Validation Loss: 0.0227, Accuracy: 99.47%, Precision: 99.96%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0285, Average Validation Loss: 0.0217, Accuracy: 99.43%, Precision: 99.98%, Recall: 99.03%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0213, Average Validation Loss: 0.0214, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0190, Average Validation Loss: 0.0210, Accuracy: 99.45%, Precision: 99.98%, Recall: 99.07%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0179, Average Validation Loss: 0.0208, Accuracy: 99.46%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0232, Average Validation Loss: 0.0212, Accuracy: 99.50%, Precision: 99.96%, Recall: 99.17%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0308, Average Validation Loss: 0.0203, Accuracy: 99.49%, Precision: 99.97%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0303, Average Validation Loss: 0.0208, Accuracy: 99.50%, Precision: 99.97%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0263, Average Validation Loss: 0.0199, Accuracy: 99.47%, Precision: 99.99%, Recall: 99.09%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0289, Average Validation Loss: 0.0195, Accuracy: 99.51%, Precision: 99.98%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0195, Average Validation Loss: 0.0197, Accuracy: 99.46%, Precision: 100.00%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0202, Average Validation Loss: 0.0187, Accuracy: 99.52%, Precision: 99.99%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0099, Average Validation Loss: 0.0200, Accuracy: 99.43%, Precision: 100.00%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0184, Average Validation Loss: 0.0188, Accuracy: 99.47%, Precision: 99.99%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0233, Average Validation Loss: 0.0180, Accuracy: 99.52%, Precision: 99.98%, Recall: 99.19%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0231, Average Validation Loss: 0.0178, Accuracy: 99.53%, Precision: 99.97%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0230, Average Validation Loss: 0.0175, Accuracy: 99.48%, Precision: 99.99%, Recall: 99.11%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0194, Average Validation Loss: 0.0171, Accuracy: 99.53%, Precision: 99.97%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0187, Average Validation Loss: 0.0169, Accuracy: 99.52%, Precision: 99.97%, Recall: 99.19%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0268, Average Validation Loss: 0.0169, Accuracy: 99.52%, Precision: 99.97%, Recall: 99.20%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0185, Average Validation Loss: 0.0176, Accuracy: 99.50%, Precision: 99.97%, Recall: 99.17%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0147, Average Validation Loss: 0.0169, Accuracy: 99.50%, Precision: 99.99%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:11:18,795] Trial 43 finished with value: 0.016905584166178832 and parameters: {'vector_length': 128, 'num_layers': 1, 'layer_size': 64, 'dropout': 0.1, 'num_epochs': 2, 'lr': 5.798780016095514e-05, 'weight_decay': 1.985426136207551e-06, 'warmup_steps': 100}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 13,635,328 parameters\n","Num non-decayed parameter tensors: 2, with 66 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2539, Average Validation Loss: 0.0365, Accuracy: 99.12%, Precision: 99.76%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0336, Average Validation Loss: 0.0302, Accuracy: 99.28%, Precision: 99.87%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0255, Average Validation Loss: 0.0296, Accuracy: 99.33%, Precision: 99.91%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0288, Average Validation Loss: 0.0398, Accuracy: 99.26%, Precision: 99.97%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0686, Average Validation Loss: 0.0275, Accuracy: 99.37%, Precision: 99.90%, Recall: 99.00%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0341, Average Validation Loss: 0.0258, Accuracy: 99.37%, Precision: 99.90%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0310, Average Validation Loss: 0.0260, Accuracy: 99.38%, Precision: 99.95%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0317, Average Validation Loss: 0.0277, Accuracy: 99.35%, Precision: 99.99%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0475, Average Validation Loss: 0.0318, Accuracy: 99.27%, Precision: 99.50%, Recall: 99.24%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0369, Average Validation Loss: 0.0236, Accuracy: 99.41%, Precision: 99.84%, Recall: 99.15%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0159, Average Validation Loss: 0.0252, Accuracy: 99.43%, Precision: 99.93%, Recall: 99.09%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0231, Average Validation Loss: 0.0229, Accuracy: 99.47%, Precision: 99.80%, Recall: 99.28%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0360, Average Validation Loss: 0.0217, Accuracy: 99.47%, Precision: 99.92%, Recall: 99.17%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0177, Average Validation Loss: 0.0233, Accuracy: 99.43%, Precision: 99.96%, Recall: 99.06%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0296, Average Validation Loss: 0.0207, Accuracy: 99.53%, Precision: 99.90%, Recall: 99.28%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0299, Average Validation Loss: 0.0241, Accuracy: 99.45%, Precision: 99.97%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0331, Average Validation Loss: 0.0205, Accuracy: 99.50%, Precision: 99.96%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0469, Average Validation Loss: 0.0269, Accuracy: 99.51%, Precision: 99.80%, Recall: 99.35%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0308, Average Validation Loss: 0.0339, Accuracy: 99.22%, Precision: 99.99%, Recall: 98.67%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0206, Average Validation Loss: 0.0207, Accuracy: 99.45%, Precision: 99.97%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0195, Average Validation Loss: 0.0190, Accuracy: 99.50%, Precision: 99.93%, Recall: 99.20%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0259, Average Validation Loss: 0.0182, Accuracy: 99.53%, Precision: 99.84%, Recall: 99.35%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0139, Average Validation Loss: 0.0233, Accuracy: 99.46%, Precision: 99.97%, Recall: 99.09%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.0180, Accuracy: 99.56%, Precision: 99.87%, Recall: 99.36%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0397, Average Validation Loss: 0.0182, Accuracy: 99.52%, Precision: 99.96%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0139, Average Validation Loss: 0.0170, Accuracy: 99.55%, Precision: 99.89%, Recall: 99.34%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0237, Average Validation Loss: 0.0168, Accuracy: 99.54%, Precision: 99.90%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0334, Average Validation Loss: 0.0165, Accuracy: 99.54%, Precision: 99.91%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0264, Average Validation Loss: 0.0171, Accuracy: 99.52%, Precision: 99.97%, Recall: 99.19%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0224, Average Validation Loss: 0.0166, Accuracy: 99.61%, Precision: 99.88%, Recall: 99.43%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0373, Average Validation Loss: 0.0170, Accuracy: 99.61%, Precision: 99.90%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:13:59,854] Trial 44 finished with value: 0.01701342050187491 and parameters: {'vector_length': 512, 'num_layers': 1, 'layer_size': 64, 'dropout': 0.2, 'num_epochs': 1, 'lr': 0.00012436691966422582, 'weight_decay': 1.3473532762338478e-05, 'warmup_steps': 80}. Best is trial 36 with value: 0.01397774032745007.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 9,778,304 parameters\n","Num non-decayed parameter tensors: 3, with 514 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4551, Average Validation Loss: 0.0473, Accuracy: 98.91%, Precision: 99.38%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0373, Average Validation Loss: 0.0387, Accuracy: 99.19%, Precision: 99.97%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0450, Average Validation Loss: 0.0303, Accuracy: 99.31%, Precision: 99.73%, Recall: 99.06%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0381, Average Validation Loss: 0.0323, Accuracy: 99.15%, Precision: 99.39%, Recall: 99.13%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0392, Average Validation Loss: 0.0309, Accuracy: 99.30%, Precision: 99.96%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0245, Average Validation Loss: 0.0354, Accuracy: 99.35%, Precision: 99.95%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0413, Average Validation Loss: 0.0232, Accuracy: 99.41%, Precision: 99.89%, Recall: 99.09%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0281, Average Validation Loss: 0.0218, Accuracy: 99.42%, Precision: 99.90%, Recall: 99.10%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0208, Accuracy: 99.43%, Precision: 99.89%, Recall: 99.12%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0251, Average Validation Loss: 0.0200, Accuracy: 99.47%, Precision: 99.87%, Recall: 99.20%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0303, Average Validation Loss: 0.0261, Accuracy: 99.33%, Precision: 99.46%, Recall: 99.36%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0276, Average Validation Loss: 0.0195, Accuracy: 99.45%, Precision: 99.80%, Recall: 99.24%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0136, Average Validation Loss: 0.0249, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0194, Average Validation Loss: 0.0213, Accuracy: 99.55%, Precision: 99.81%, Recall: 99.39%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0279, Average Validation Loss: 0.0171, Accuracy: 99.60%, Precision: 99.76%, Recall: 99.55%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0259, Average Validation Loss: 0.0208, Accuracy: 99.61%, Precision: 99.97%, Recall: 99.35%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0140, Accuracy: 99.62%, Precision: 99.92%, Recall: 99.42%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0174, Accuracy: 99.55%, Precision: 99.98%, Recall: 99.24%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0152, Average Validation Loss: 0.0158, Accuracy: 99.54%, Precision: 99.97%, Recall: 99.23%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0157, Average Validation Loss: 0.0145, Accuracy: 99.56%, Precision: 99.96%, Recall: 99.28%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0194, Average Validation Loss: 0.0193, Accuracy: 99.50%, Precision: 99.99%, Recall: 99.14%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0129, Accuracy: 99.69%, Precision: 99.87%, Recall: 99.59%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0110, Average Validation Loss: 0.0144, Accuracy: 99.61%, Precision: 99.71%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0240, Average Validation Loss: 0.0172, Accuracy: 99.50%, Precision: 99.46%, Recall: 99.66%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0188, Average Validation Loss: 0.0167, Accuracy: 99.58%, Precision: 99.77%, Recall: 99.49%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0239, Average Validation Loss: 0.0145, Accuracy: 99.66%, Precision: 99.84%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0202, Average Validation Loss: 0.0131, Accuracy: 99.57%, Precision: 99.98%, Recall: 99.27%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:16:11,874] Trial 45 finished with value: 0.013048752666627233 and parameters: {'vector_length': 128, 'num_layers': 2, 'layer_size': 256, 'dropout': 0.1, 'num_epochs': 2, 'lr': 0.0023658868578099314, 'weight_decay': 8.523268798897845e-06, 'warmup_steps': 80}. Best is trial 45 with value: 0.013048752666627233.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 77,608,960 parameters\n","Num non-decayed parameter tensors: 2, with 258 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 71.1761, Average Validation Loss: 33.5571, Accuracy: 72.23%, Precision: 99.99%, Recall: 67.31%, F1: 0.80\n","Epoch 0, Average Training Loss: 14.7377, Average Validation Loss: 2.4502, Accuracy: 97.25%, Precision: 99.11%, Recall: 96.19%, F1: 0.98\n","Epoch 0, Average Training Loss: 5.1454, Average Validation Loss: 1.6659, Accuracy: 98.95%, Precision: 99.60%, Recall: 98.58%, F1: 0.99\n","Epoch 0, Average Training Loss: 8.7193, Average Validation Loss: 1.9891, Accuracy: 99.04%, Precision: 99.68%, Recall: 98.66%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 2.9592, Average Validation Loss: 1.2121, Accuracy: 99.13%, Precision: 99.64%, Recall: 98.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 1.1076, Average Validation Loss: 1.1215, Accuracy: 99.14%, Precision: 99.89%, Recall: 98.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 2.6900, Average Validation Loss: 2.3802, Accuracy: 98.25%, Precision: 99.93%, Recall: 97.09%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 5.5359, Average Validation Loss: 1.2075, Accuracy: 97.54%, Precision: 96.43%, Recall: 99.26%, F1: 0.98\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 1.5681, Average Validation Loss: 0.9987, Accuracy: 99.22%, Precision: 99.99%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.7652, Average Validation Loss: 3.0842, Accuracy: 87.82%, Precision: 79.26%, Recall: 99.30%, F1: 0.88\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 4.5109, Average Validation Loss: 0.8523, Accuracy: 99.32%, Precision: 99.84%, Recall: 98.98%, F1: 0.99\n","Epoch 0, Average Training Loss: 1.0514, Average Validation Loss: 0.7841, Accuracy: 99.30%, Precision: 99.91%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.5526, Average Validation Loss: 0.8553, Accuracy: 99.28%, Precision: 99.92%, Recall: 98.84%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6611, Average Validation Loss: 1.7594, Accuracy: 93.63%, Precision: 89.48%, Recall: 99.32%, F1: 0.94\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 1.2686, Average Validation Loss: 0.5642, Accuracy: 96.12%, Precision: 93.83%, Recall: 99.34%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.7915, Average Validation Loss: 0.6191, Accuracy: 93.25%, Precision: 89.10%, Recall: 98.99%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.7084, Average Validation Loss: 0.1383, Accuracy: 99.33%, Precision: 99.94%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1959, Average Validation Loss: 0.1668, Accuracy: 99.23%, Precision: 99.93%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1949, Average Validation Loss: 0.2058, Accuracy: 98.96%, Precision: 99.50%, Recall: 98.69%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.2129, Average Validation Loss: 0.1571, Accuracy: 97.63%, Precision: 96.63%, Recall: 99.21%, F1: 0.98\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.1372, Average Validation Loss: 0.2419, Accuracy: 99.02%, Precision: 100.00%, Recall: 98.32%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.3167, Average Validation Loss: 0.1261, Accuracy: 99.10%, Precision: 99.99%, Recall: 98.45%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0654, Average Validation Loss: 0.0776, Accuracy: 98.97%, Precision: 99.18%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1071, Average Validation Loss: 0.1750, Accuracy: 98.92%, Precision: 99.30%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.2485, Average Validation Loss: 0.1111, Accuracy: 98.83%, Precision: 99.37%, Recall: 98.60%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.1956, Average Validation Loss: 0.0954, Accuracy: 99.08%, Precision: 99.33%, Recall: 99.06%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0801, Average Validation Loss: 0.2112, Accuracy: 99.33%, Precision: 99.96%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.2434, Average Validation Loss: 0.4605, Accuracy: 95.12%, Precision: 92.09%, Recall: 99.32%, F1: 0.96\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:18:42,861] Trial 46 finished with value: 0.45194342637786994 and parameters: {'vector_length': 1024, 'num_layers': 1, 'layer_size': 256, 'dropout': 0.2, 'num_epochs': 2, 'lr': 0.007357887607414087, 'weight_decay': 8.215274840596147e-06, 'warmup_steps': 70}. Best is trial 45 with value: 0.013048752666627233.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 9,778,304 parameters\n","Num non-decayed parameter tensors: 3, with 514 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4932, Average Validation Loss: 0.0453, Accuracy: 99.08%, Precision: 99.89%, Recall: 98.52%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0373, Average Validation Loss: 0.0318, Accuracy: 99.20%, Precision: 99.97%, Recall: 98.65%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0408, Average Validation Loss: 0.0521, Accuracy: 99.11%, Precision: 100.00%, Recall: 98.46%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0483, Average Validation Loss: 0.0246, Accuracy: 99.42%, Precision: 99.84%, Recall: 99.15%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0352, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0216, Average Validation Loss: 0.0247, Accuracy: 99.40%, Precision: 99.76%, Recall: 99.19%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0564, Average Validation Loss: 0.0340, Accuracy: 99.41%, Precision: 99.86%, Recall: 99.12%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0251, Average Validation Loss: 0.0284, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0132, Average Validation Loss: 0.0227, Accuracy: 99.46%, Precision: 99.92%, Recall: 99.14%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0086, Average Validation Loss: 0.0355, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0197, Average Validation Loss: 0.0270, Accuracy: 99.43%, Precision: 99.99%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0349, Average Validation Loss: 0.0238, Accuracy: 99.47%, Precision: 99.98%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0099, Average Validation Loss: 0.0250, Accuracy: 99.47%, Precision: 99.96%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0367, Average Validation Loss: 0.0442, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.69%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:19:52,724] Trial 47 finished with value: 0.04337844408394114 and parameters: {'vector_length': 128, 'num_layers': 2, 'layer_size': 256, 'dropout': 0.1, 'num_epochs': 2, 'lr': 0.00269777794049691, 'weight_decay': 2.481233015772333e-05, 'warmup_steps': 60}. Best is trial 45 with value: 0.013048752666627233.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 3, with 9,712,768 parameters\n","Num non-decayed parameter tensors: 2, with 258 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 3.5801, Average Validation Loss: 0.5047, Accuracy: 94.67%, Precision: 99.96%, Recall: 91.51%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.4296, Average Validation Loss: 0.1039, Accuracy: 98.89%, Precision: 99.95%, Recall: 98.14%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0975, Average Validation Loss: 0.0435, Accuracy: 99.18%, Precision: 99.62%, Recall: 98.95%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0399, Average Validation Loss: 0.0396, Accuracy: 99.10%, Precision: 99.21%, Recall: 99.21%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0399, Average Validation Loss: 0.0381, Accuracy: 99.25%, Precision: 99.73%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0647, Average Validation Loss: 0.0507, Accuracy: 99.23%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0423, Accuracy: 99.31%, Precision: 100.00%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0282, Average Validation Loss: 0.0263, Accuracy: 99.41%, Precision: 99.68%, Recall: 99.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0466, Average Validation Loss: 0.0426, Accuracy: 99.45%, Precision: 99.97%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1475, Average Validation Loss: 0.1354, Accuracy: 98.62%, Precision: 100.00%, Recall: 97.65%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0801, Average Validation Loss: 0.0280, Accuracy: 99.50%, Precision: 99.96%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0552, Average Validation Loss: 0.0203, Accuracy: 99.50%, Precision: 99.96%, Recall: 99.18%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0294, Average Validation Loss: 0.0288, Accuracy: 99.46%, Precision: 99.92%, Recall: 99.14%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0324, Average Validation Loss: 0.0241, Accuracy: 99.38%, Precision: 99.53%, Recall: 99.39%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0356, Average Validation Loss: 0.0226, Accuracy: 99.39%, Precision: 99.99%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0263, Average Validation Loss: 0.0217, Accuracy: 99.35%, Precision: 99.41%, Recall: 99.45%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0526, Average Validation Loss: 0.0472, Accuracy: 99.37%, Precision: 100.00%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:21:16,379] Trial 48 finished with value: 0.04708606728424481 and parameters: {'vector_length': 128, 'num_layers': 1, 'layer_size': 256, 'dropout': 0.2, 'num_epochs': 2, 'lr': 0.005861068002448314, 'weight_decay': 1.5399756401164783e-05, 'warmup_steps': 80}. Best is trial 45 with value: 0.013048752666627233.\n"]},{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 5, with 38,942,208 parameters\n","Num non-decayed parameter tensors: 4, with 770 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3688, Average Validation Loss: 0.0653, Accuracy: 99.06%, Precision: 99.93%, Recall: 98.45%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0556, Average Validation Loss: 0.0405, Accuracy: 99.25%, Precision: 99.90%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0355, Average Validation Loss: 0.0322, Accuracy: 99.27%, Precision: 99.87%, Recall: 98.85%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0577, Average Validation Loss: 0.0422, Accuracy: 99.22%, Precision: 99.70%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0424, Average Validation Loss: 0.0329, Accuracy: 99.24%, Precision: 99.75%, Recall: 98.93%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0530, Average Validation Loss: 0.0431, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0426, Average Validation Loss: 0.0476, Accuracy: 99.00%, Precision: 100.00%, Recall: 98.29%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0311, Average Validation Loss: 0.0299, Accuracy: 99.39%, Precision: 99.92%, Recall: 99.03%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0426, Average Validation Loss: 0.0272, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0489, Average Validation Loss: 0.0258, Accuracy: 99.38%, Precision: 99.97%, Recall: 98.95%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0467, Average Validation Loss: 0.0416, Accuracy: 99.41%, Precision: 99.94%, Recall: 99.04%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0398, Average Validation Loss: 0.0259, Accuracy: 99.36%, Precision: 99.99%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0314, Average Validation Loss: 0.0302, Accuracy: 99.35%, Precision: 99.99%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0399, Average Validation Loss: 0.0291, Accuracy: 99.38%, Precision: 99.99%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0230, Average Validation Loss: 0.0275, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"output_type":"stream","name":"stderr","text":["[I 2024-12-07 15:22:34,838] Trial 49 finished with value: 0.027518042294635763 and parameters: {'vector_length': 512, 'num_layers': 3, 'layer_size': 256, 'dropout': 0.30000000000000004, 'num_epochs': 2, 'lr': 0.0011847706167414473, 'weight_decay': 8.10229568366002e-06, 'warmup_steps': 50}. Best is trial 45 with value: 0.013048752666627233.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters:\n","vector_length: 128\n","num_layers: 2\n","layer_size: 256\n","dropout: 0.1\n","num_epochs: 2\n","lr: 0.0023658868578099314\n","weight_decay: 8.523268798897845e-06\n","warmup_steps: 80\n"]}]},{"cell_type":"code","source":["# Print the best hyperparameters\n","print(\"Best hyperparameters:\")\n","for key, value in study.best_params.items():\n","    print(f\"{key}: {value}\")"],"metadata":{"id":"IaquCmOvffIH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733598308286,"user_tz":-240,"elapsed":11,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}},"outputId":"8e0bd78a-2aca-45aa-8f90-20fe456aa72c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["vector_length: 128\n","num_layers: 2\n","layer_size: 256\n","dropout: 0.1\n","num_epochs: 2\n","lr: 0.0023658868578099314\n","weight_decay: 8.523268798897845e-06\n","warmup_steps: 80\n"]}]},{"cell_type":"code","source":["vector_length = 128\n","num_layers = 2\n","layer_size = 256\n","dropout = 0.1\n","num_epochs = 2\n","lr = 0.0023658868578099314\n","weight_decay = 8.523268798897845e-06\n","warmup_steps = 80\n","\n","scheduler_config = {\"warmup_steps\": warmup_steps,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": lr,\n","                    \"min_lr\": lr * 0.1}"],"metadata":{"id":"LFBX_w2xgzQs","executionInfo":{"status":"ok","timestamp":1733600281231,"user_tz":-240,"elapsed":6,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["model = MLP(vocab_size=10240, context_size=context_size, vector_length=vector_length, hidden_layers=hidden_layers, dropout=dropout, num_metadata_features=num_metadata_features, padding_idx=tokenizer.padding_idx).to(device)\n","model = torch.compile(model)\n","\n","optimizer = model.configure_optimizers(weight_decay=weight_decay, learning_rate=max_lr, device_type=device) # torch.optim.AdamW(model.parameters(), lr=max_lr)\n","\n","model = train_model(model, train_loader, val_loader, num_epochs=num_epochs, optimizer=optimizer, device=device, fp16=True, scheduler_config=scheduler_config, log_interval=10, early_stopping=True, patience=10, improvement_threshold=0.0001)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kh1q9DP4lWVY","outputId":"f10f8468-9619-4b2c-eb84-4941294eb8ee","executionInfo":{"status":"ok","timestamp":1733600750284,"user_tz":-240,"elapsed":469058,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 4, with 5,544,832 parameters\n","Num non-decayed parameter tensors: 3, with 386 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5399, Average Validation Loss: 0.1825, Accuracy: 98.04%, Precision: 99.85%, Recall: 96.82%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0651, Average Validation Loss: 0.0422, Accuracy: 99.27%, Precision: 99.90%, Recall: 98.85%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0627, Average Validation Loss: 0.0320, Accuracy: 99.40%, Precision: 99.90%, Recall: 99.07%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0583, Average Validation Loss: 0.0343, Accuracy: 99.16%, Precision: 99.62%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0686, Average Validation Loss: 0.0357, Accuracy: 99.01%, Precision: 99.18%, Recall: 99.09%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0396, Average Validation Loss: 0.0437, Accuracy: 98.91%, Precision: 99.98%, Recall: 98.16%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0377, Average Validation Loss: 0.0268, Accuracy: 99.27%, Precision: 99.63%, Recall: 99.10%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0181, Average Validation Loss: 0.0275, Accuracy: 99.33%, Precision: 99.73%, Recall: 99.09%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0326, Average Validation Loss: 0.0380, Accuracy: 99.24%, Precision: 99.98%, Recall: 98.71%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0295, Average Validation Loss: 0.0216, Accuracy: 99.40%, Precision: 99.69%, Recall: 99.26%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0347, Average Validation Loss: 0.0220, Accuracy: 99.43%, Precision: 99.86%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0342, Average Validation Loss: 0.0226, Accuracy: 99.42%, Precision: 99.98%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0313, Average Validation Loss: 0.0397, Accuracy: 99.15%, Precision: 100.00%, Recall: 98.54%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0244, Average Validation Loss: 0.0227, Accuracy: 99.41%, Precision: 99.98%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.0270, Accuracy: 99.52%, Precision: 99.83%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0194, Average Validation Loss: 0.0193, Accuracy: 99.48%, Precision: 99.93%, Recall: 99.16%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0280, Average Validation Loss: 0.0227, Accuracy: 99.41%, Precision: 100.00%, Recall: 98.98%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0178, Average Validation Loss: 0.0178, Accuracy: 99.49%, Precision: 99.84%, Recall: 99.27%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0195, Average Validation Loss: 0.0185, Accuracy: 99.50%, Precision: 99.78%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0333, Average Validation Loss: 0.0264, Accuracy: 99.50%, Precision: 99.74%, Recall: 99.39%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0350, Average Validation Loss: 0.0180, Accuracy: 99.58%, Precision: 99.98%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0282, Average Validation Loss: 0.0157, Accuracy: 99.56%, Precision: 99.94%, Recall: 99.30%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0247, Average Validation Loss: 0.0214, Accuracy: 99.50%, Precision: 100.00%, Recall: 99.13%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0338, Average Validation Loss: 0.0335, Accuracy: 99.30%, Precision: 99.11%, Recall: 99.66%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0212, Average Validation Loss: 0.0269, Accuracy: 99.34%, Precision: 100.00%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0313, Average Validation Loss: 0.0153, Accuracy: 99.62%, Precision: 99.93%, Recall: 99.42%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0122, Average Validation Loss: 0.0143, Accuracy: 99.64%, Precision: 99.94%, Recall: 99.44%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0164, Average Validation Loss: 0.0163, Accuracy: 99.62%, Precision: 99.96%, Recall: 99.39%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0192, Average Validation Loss: 0.0139, Accuracy: 99.66%, Precision: 99.88%, Recall: 99.53%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0286, Average Validation Loss: 0.0145, Accuracy: 99.59%, Precision: 99.99%, Recall: 99.31%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0250, Average Validation Loss: 0.0148, Accuracy: 99.62%, Precision: 99.99%, Recall: 99.36%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0165, Average Validation Loss: 0.0146, Accuracy: 99.55%, Precision: 99.62%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0124, Average Validation Loss: 0.0164, Accuracy: 99.62%, Precision: 99.98%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0117, Accuracy: 99.69%, Precision: 99.87%, Recall: 99.59%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0119, Accuracy: 99.68%, Precision: 99.83%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0081, Average Validation Loss: 0.0113, Accuracy: 99.71%, Precision: 99.91%, Recall: 99.59%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0185, Average Validation Loss: 0.0127, Accuracy: 99.67%, Precision: 99.93%, Recall: 99.50%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0110, Average Validation Loss: 0.0119, Accuracy: 99.66%, Precision: 99.86%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0230, Average Validation Loss: 0.0135, Accuracy: 99.72%, Precision: 99.90%, Recall: 99.61%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0209, Average Validation Loss: 0.0127, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.32%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0093, Average Validation Loss: 0.0152, Accuracy: 99.64%, Precision: 100.00%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0348, Average Validation Loss: 0.0235, Accuracy: 99.47%, Precision: 99.30%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 6 step(s).\n","Epoch 0, Average Training Loss: 0.0151, Average Validation Loss: 0.0160, Accuracy: 99.53%, Precision: 100.00%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 7 step(s).\n","Epoch 0, Average Training Loss: 0.0089, Average Validation Loss: 0.0099, Accuracy: 99.73%, Precision: 99.90%, Recall: 99.64%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0078, Average Validation Loss: 0.0211, Accuracy: 99.57%, Precision: 100.00%, Recall: 99.26%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0286, Average Validation Loss: 0.0205, Accuracy: 99.64%, Precision: 99.64%, Recall: 99.74%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0200, Average Validation Loss: 0.0105, Accuracy: 99.69%, Precision: 99.99%, Recall: 99.47%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0170, Average Validation Loss: 0.0111, Accuracy: 99.72%, Precision: 99.78%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0092, Accuracy: 99.74%, Precision: 99.90%, Recall: 99.64%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0167, Average Validation Loss: 0.0094, Accuracy: 99.76%, Precision: 99.86%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0093, Average Validation Loss: 0.0124, Accuracy: 99.67%, Precision: 99.99%, Recall: 99.44%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0083, Average Validation Loss: 0.0094, Accuracy: 99.77%, Precision: 99.90%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0094, Accuracy: 99.76%, Precision: 99.86%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0072, Average Validation Loss: 0.0105, Accuracy: 99.71%, Precision: 99.76%, Recall: 99.74%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0166, Average Validation Loss: 0.0104, Accuracy: 99.73%, Precision: 99.96%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 6 step(s).\n","Epoch 0, Average Training Loss: 0.0114, Average Validation Loss: 0.0151, Accuracy: 99.58%, Precision: 100.00%, Recall: 99.28%, F1: 1.00\n","No significant improvement in validation loss for 7 step(s).\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.0114, Accuracy: 99.74%, Precision: 99.88%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 8 step(s).\n","Epoch 0, Average Training Loss: 0.0118, Average Validation Loss: 0.0096, Accuracy: 99.73%, Precision: 99.99%, Recall: 99.54%, F1: 1.00\n","No significant improvement in validation loss for 9 step(s).\n","Epoch 0, Average Training Loss: 0.0051, Average Validation Loss: 0.0091, Accuracy: 99.76%, Precision: 99.94%, Recall: 99.65%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0101, Accuracy: 99.76%, Precision: 99.96%, Recall: 99.63%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0138, Average Validation Loss: 0.0115, Accuracy: 99.74%, Precision: 99.98%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0086, Accuracy: 99.73%, Precision: 99.96%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0217, Average Validation Loss: 0.0127, Accuracy: 99.75%, Precision: 99.87%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0113, Average Validation Loss: 0.0094, Accuracy: 99.73%, Precision: 99.99%, Recall: 99.55%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0163, Average Validation Loss: 0.0068, Accuracy: 99.81%, Precision: 99.90%, Recall: 99.77%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0089, Accuracy: 99.75%, Precision: 99.97%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0198, Average Validation Loss: 0.0113, Accuracy: 99.69%, Precision: 99.65%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0217, Average Validation Loss: 0.0125, Accuracy: 99.65%, Precision: 100.00%, Recall: 99.39%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0186, Average Validation Loss: 0.0110, Accuracy: 99.75%, Precision: 99.97%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0090, Average Validation Loss: 0.0073, Accuracy: 99.76%, Precision: 99.99%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0090, Average Validation Loss: 0.0067, Accuracy: 99.79%, Precision: 99.97%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0068, Average Validation Loss: 0.0074, Accuracy: 99.78%, Precision: 99.76%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0090, Average Validation Loss: 0.0082, Accuracy: 99.79%, Precision: 99.99%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0113, Average Validation Loss: 0.0070, Accuracy: 99.80%, Precision: 99.94%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0077, Accuracy: 99.76%, Precision: 99.99%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0204, Average Validation Loss: 0.0073, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0071, Accuracy: 99.78%, Precision: 99.99%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 6 step(s).\n","Epoch 0, Average Training Loss: 0.0136, Average Validation Loss: 0.0060, Accuracy: 99.86%, Precision: 99.94%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0128, Average Validation Loss: 0.0064, Accuracy: 99.83%, Precision: 99.81%, Recall: 99.89%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0058, Accuracy: 99.86%, Precision: 99.98%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0219, Average Validation Loss: 0.0061, Accuracy: 99.81%, Precision: 99.99%, Recall: 99.68%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0120, Accuracy: 99.60%, Precision: 100.00%, Recall: 99.31%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0130, Average Validation Loss: 0.0075, Accuracy: 99.85%, Precision: 99.91%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0110, Average Validation Loss: 0.0143, Accuracy: 99.66%, Precision: 100.00%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0089, Average Validation Loss: 0.0068, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0077, Average Validation Loss: 0.0054, Accuracy: 99.85%, Precision: 99.97%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0029, Average Validation Loss: 0.0060, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0040, Average Validation Loss: 0.0092, Accuracy: 99.79%, Precision: 99.99%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0096, Average Validation Loss: 0.0052, Accuracy: 99.86%, Precision: 99.96%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0127, Average Validation Loss: 0.0059, Accuracy: 99.85%, Precision: 99.90%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0083, Average Validation Loss: 0.0068, Accuracy: 99.80%, Precision: 99.99%, Recall: 99.66%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0083, Average Validation Loss: 0.0056, Accuracy: 99.83%, Precision: 99.95%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0200, Average Validation Loss: 0.0062, Accuracy: 99.83%, Precision: 99.96%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0097, Average Validation Loss: 0.0067, Accuracy: 99.79%, Precision: 99.97%, Recall: 99.66%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0085, Average Validation Loss: 0.0103, Accuracy: 99.66%, Precision: 99.99%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 6 step(s).\n","Epoch 0, Average Training Loss: 0.0131, Average Validation Loss: 0.0061, Accuracy: 99.85%, Precision: 99.96%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 7 step(s).\n","Epoch 0, Average Training Loss: 0.0111, Average Validation Loss: 0.0066, Accuracy: 99.80%, Precision: 99.99%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 8 step(s).\n","Epoch 0, Average Training Loss: 0.0088, Average Validation Loss: 0.0053, Accuracy: 99.85%, Precision: 99.89%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 9 step(s).\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0062, Accuracy: 99.84%, Precision: 99.98%, Recall: 99.74%, F1: 1.00\n","No significant improvement in validation loss for 10 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 10 steps.\n"]}]},{"cell_type":"code","source":["test_results = run_inference_and_collect_results(model, test_loader, device, fp16=True)\n","test_loss = test_model(model, test_loader, device, fp16=False)\n","\n","accuracy = accuracy_score(test_results['Predicted Outputs'], test_results['True Labels']) * 100\n","precision = precision_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","recall = recall_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","f1 = f1_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","\n","print(f'Final Test Loss: {test_loss:.4f}')\n","print(f\"Final Accuracy: {accuracy:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kun0xTY3Oud1","outputId":"58331ff7-2023-4449-9631-86efb69b61d2","executionInfo":{"status":"ok","timestamp":1733599965419,"user_tz":-240,"elapsed":8308,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Test Loss: 0.0072\n","Final Accuracy: 99.82%\n","Precision: 1.00\n","Recall: 1.00\n","F1 Score: 1.00\n"]}]},{"cell_type":"code","source":["auc = calculate_auc_roc(model, test_loader, device)\n","plot_confusion_matrix(model, test_loader, device)\n","print(f'The Area Under Curve (AUC) is: {auc:.2f}')"],"metadata":{"id":"gHGB2OmuDvgw","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"514f82c5-e8d4-4e19-f0e3-2dae5862598b","executionInfo":{"status":"ok","timestamp":1733599971132,"user_tz":-240,"elapsed":5715,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["The Area Under Curve (AUC) is: 1.00\n"]}]},{"cell_type":"code","source":["adversarial_tokenized_dataset = load_from_disk(path+\"Datasets/TransformedDataset/\")\n","\n","adversarial_train_dataset = adversarial_tokenized_dataset['train']\n","adversarial_val_dataset = adversarial_tokenized_dataset['validation']\n","adversarial_test_dataset = adversarial_tokenized_dataset['test']\n","\n","batch_size = 128\n","\n","# Prepare dataloaders for batching the data during training and evaluation\n","adversarial_train_loader = DataLoader(adversarial_train_dataset, batch_size=batch_size, shuffle=True)\n","adversarial_val_loader = DataLoader(adversarial_val_dataset, batch_size=batch_size, shuffle=True)\n","adversarial_test_loader = DataLoader(adversarial_test_dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"AQeLMjnPE3AA","executionInfo":{"status":"ok","timestamp":1733599984185,"user_tz":-240,"elapsed":13055,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["adversarial_losses = test_model_adversarial(model, adversarial_test_loader, device, fp16=True)\n","adversarial_results = run_inference_and_collect_results_adversarial(model, adversarial_test_loader, device, fp16=True)"],"metadata":{"id":"527ilmeFKzUm","executionInfo":{"status":"ok","timestamp":1733600001937,"user_tz":-240,"elapsed":17754,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(\"Adversarial Losses:\")\n","print(f\"Original Loss: {adversarial_losses['original_loss']:.4f}\")\n","print(f\"Similar Characters Loss: {adversarial_losses['similar_loss']:.4f}\")\n","print(f\"Case Symbols Loss: {adversarial_losses['case_symbols_loss']:.4f}\")\n","print(f\"Unicode Replacement Loss: {adversarial_losses['unicode_loss']:.4f}\\n\")\n","\n","# Evaluate metrics for each type\n","for key in adversarial_results:\n","    predictions = adversarial_results[key][\"predictions\"]\n","    labels = adversarial_results[key][\"labels\"]\n","\n","    accuracy = accuracy_score(labels, predictions) * 100\n","    precision = precision_score(labels, predictions)\n","    recall = recall_score(labels, predictions)\n","    f1 = f1_score(labels, predictions)\n","\n","    print(f\"Results for {key.capitalize()} Inputs:\")\n","    print(f\"  Accuracy: {accuracy:.2f}%\")\n","    print(f\"  Precision: {precision:.2f}\")\n","    print(f\"  Recall: {recall:.2f}\")\n","    print(f\"  F1 Score: {f1:.2f}\")\n","    print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMHU93MYR6D9","outputId":"eafef61b-f3c8-45e1-aef3-cc4eb5bddfc2","executionInfo":{"status":"ok","timestamp":1733600002211,"user_tz":-240,"elapsed":282,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Adversarial Losses:\n","Original Loss: 0.0072\n","Similar Characters Loss: 0.5172\n","Case Symbols Loss: 0.0183\n","Unicode Replacement Loss: 0.5848\n","\n","Results for Original Inputs:\n","  Accuracy: 99.82%\n","  Precision: 1.00\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n","Results for Similar Inputs:\n","  Accuracy: 87.28%\n","  Precision: 0.98\n","  Recall: 0.80\n","  F1 Score: 0.88\n","\n","\n","Results for Case symbols Inputs:\n","  Accuracy: 99.42%\n","  Precision: 1.00\n","  Recall: 0.99\n","  F1 Score: 0.99\n","\n","\n","Results for Unicode Inputs:\n","  Accuracy: 80.63%\n","  Precision: 0.99\n","  Recall: 0.67\n","  F1 Score: 0.80\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Am2bN2givqYG"},"execution_count":null,"outputs":[]}]}