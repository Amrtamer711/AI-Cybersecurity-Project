{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18283,"status":"ok","timestamp":1733602749426,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"cNHp-qi0iO-b","outputId":"625b566e-159b-4079-93a0-e0862d5b184f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/364.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/233.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install optuna -q\n","!pip install --upgrade datasets -q\n","!pip install --upgrade triton -q"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100023,"status":"ok","timestamp":1733602849445,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"6MsVjKl7huMh","outputId":"230f89eb-4c02-491e-a191-4f79538182b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') # mounting drive where files are stored"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"IkmIgn4QEt86","executionInfo":{"status":"ok","timestamp":1733602849445,"user_tz":-240,"elapsed":2,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["import sys\n","path = \"/content/drive/MyDrive/AI_Cybersecurity/Project/\"\n","sys.path.append(path)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"CLBHtY71hlUj","executionInfo":{"status":"ok","timestamp":1733602859365,"user_tz":-240,"elapsed":9922,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F # loading libraries\n","from sklearn.datasets import load_iris\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import optuna\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset, DatasetDict, load_from_disk\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import roc_curve, auc\n","from contextlib import nullcontext\n","from utils import BPE_Tokenizer, Transformer, train_model, test_model, run_inference_and_collect_results, calculate_auc_roc, plot_confusion_matrix, test_model_adversarial, run_inference_and_collect_results_adversarial, multiples_of_two"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PRi6tZmEzEa6","executionInfo":{"status":"ok","timestamp":1733602859365,"user_tz":-240,"elapsed":3,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["torch.set_float32_matmul_precision('high')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3132,"status":"ok","timestamp":1733602862494,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"3WlYkCSQvBDQ","outputId":"620e7cfa-6300-4030-92d0-66e2e3d0404a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size is 10007\n"]}],"source":["tokenizer = BPE_Tokenizer(directory=path+'Tokenizer')\n","vocab = tokenizer.vocab\n","vocab_size = len(vocab) + 1\n","print(\"Vocab size is\", vocab_size)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"GBTLpoNqEir8","executionInfo":{"status":"ok","timestamp":1733602880890,"user_tz":-240,"elapsed":18400,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["tokenized_dataset = load_from_disk(path+\"Datasets/FinalDataset/\")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"rQOhXEj-zSiM","executionInfo":{"status":"ok","timestamp":1733602880891,"user_tz":-240,"elapsed":3,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["train_dataset = tokenized_dataset['train']\n","val_dataset = tokenized_dataset['validation']\n","test_dataset = tokenized_dataset['test']"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZsFSGRx9zU_R","executionInfo":{"status":"ok","timestamp":1733602880891,"user_tz":-240,"elapsed":2,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["batch_size = 128\n","\n","# Prepare dataloaders for batching the data during training and evaluation\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Qb_t-4L44G6V","executionInfo":{"status":"ok","timestamp":1733602881603,"user_tz":-240,"elapsed":714,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","vector_length = 1024\n","num_blocks = 1\n","num_heads = 4\n","dropout = 0.2\n","metadata_vector_length = 1024\n","num_metadata_features = len(train_dataset['metadata'][0])\n","max_context_size = 256\n","num_epochs = 1\n","max_lr = 2e-4\n","scheduler_config = {\"warmup_steps\": 5,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": max_lr,\n","                    \"min_lr\": max_lr * 0.1}"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34094,"status":"ok","timestamp":1733602915695,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"HyeHO1bs3qvb","outputId":"5e1ef374-2103-4fb6-e4be-3011b7eb1a8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([128, 2])\n","Initial Training Loss 0.7237\n"]}],"source":["# Initialize the model for binary classification of class 0\n","model = Transformer(vocab_size, vector_length, max_context_size, num_blocks, num_heads, dropout, num_metadata_features, metadata_vector_length).to(device)\n","\n","# Test the model with the initial untrained state and compute training loss\n","for batch in train_loader:\n","    inputs = batch[\"input_ids\"].to(device)\n","    attention_mask = batch[\"attention_mask\"].to(device)\n","    metadata = batch[\"metadata\"].to(device)\n","    labels = batch[\"label\"].to(device)\n","    logits, _ = model(inputs, attention_mask, metadata, labels)  # Forward pass through the model\n","    print(logits.shape)\n","    break\n","\n","torch.cuda.empty_cache()\n","\n","loss = test_model(model, train_loader, fp16=True, device=\"cuda\")  # Compute the loss on the training dataset\n","print(f\"Initial Training Loss {loss:.4f}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"cxaqmsgrWvra","executionInfo":{"status":"ok","timestamp":1733602915695,"user_tz":-240,"elapsed":2,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["def objective(trial):\n","    # Define hyperparameters to optimize\n","    vector_length = trial.suggest_categorical(\"vector_length\", multiples_of_two(128, 2048))\n","    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n","    num_heads = trial.suggest_categorical(\"num_heads\", multiples_of_two(2, 8))\n","    num_epochs = trial.suggest_int(\"num_epochs\", 1, 5)\n","    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n","    metadata_vector_length = trial.suggest_categorical(\"metadata_vector_length\", multiples_of_two(128, 2048))\n","    lr = trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True)\n","    warmup_steps = trial.suggest_int(\"warmup_steps\", 10, 100, step=10)\n","\n","    # Create the model\n","    model = Transformer(\n","        vocab_size=10240,\n","        vector_length=vector_length,\n","        context_size=max_context_size,\n","        num_blocks=num_blocks,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        padding_idx=tokenizer.padding_idx,\n","        num_metadata_features=num_metadata_features,\n","        metadata_vector_length=metadata_vector_length,\n","        num_classes=2\n","    ).to(device)\n","    model = torch.compile(model)\n","\n","    # Optimizer\n","    optimizer = model.configure_optimizers(weight_decay=0.01, learning_rate=lr, device_type=device)\n","\n","    scheduler_config = {\"warmup_steps\": warmup_steps,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": lr,\n","                    \"min_lr\": lr * 0.1}\n","\n","    # Train the model\n","    model = train_model(\n","        model=model,\n","        train_dataloader=train_loader,\n","        val_dataloader=val_loader,\n","        num_epochs=num_epochs,\n","        optimizer=optimizer,\n","        device=device,\n","        fp16=True,\n","        scheduler_config=scheduler_config,\n","        log_interval=10,\n","        early_stopping=True,\n","    )\n","\n","    # Evaluate on the validation set\n","    val_loss = test_model(model, val_loader, device, fp16=True)\n","\n","    # Return the validation loss as the objective to minimize\n","    return val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"z-sWVWASYNVB","outputId":"7896d734-a3f3-4d1b-8067-994dd2f6127c"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 15:13:40,017] A new study created in memory with name: no-name-6face86c-7840-468f-9371-bc966a4347d2\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 9, with 24,435,712 parameters\n","Num non-decayed parameter tensors: 13, with 17,410 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6846, Average Validation Loss: 0.6805, Accuracy: 63.37%, Precision: 47.74%, Recall: 80.18%, F1: 0.60\n","Epoch 0, Average Training Loss: 0.6785, Average Validation Loss: 0.6641, Accuracy: 73.08%, Precision: 88.26%, Recall: 71.41%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.6568, Average Validation Loss: 0.6428, Accuracy: 63.68%, Precision: 99.52%, Recall: 61.23%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6340, Average Validation Loss: 0.6212, Accuracy: 59.37%, Precision: 99.96%, Recall: 58.47%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6103, Average Validation Loss: 0.5985, Accuracy: 59.29%, Precision: 99.98%, Recall: 58.42%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.5853, Average Validation Loss: 0.5720, Accuracy: 60.93%, Precision: 99.99%, Recall: 59.41%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5580, Average Validation Loss: 0.5406, Accuracy: 66.89%, Precision: 99.99%, Recall: 63.33%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5312, Average Validation Loss: 0.5005, Accuracy: 87.01%, Precision: 99.98%, Recall: 81.51%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.4918, Average Validation Loss: 0.4623, Accuracy: 92.34%, Precision: 99.94%, Recall: 88.22%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4568, Average Validation Loss: 0.4255, Accuracy: 93.48%, Precision: 99.93%, Recall: 89.81%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4244, Average Validation Loss: 0.3936, Accuracy: 93.09%, Precision: 99.96%, Recall: 89.25%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.3859, Average Validation Loss: 0.3626, Accuracy: 93.78%, Precision: 99.95%, Recall: 90.23%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3520, Average Validation Loss: 0.3345, Accuracy: 93.77%, Precision: 99.96%, Recall: 90.21%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3301, Average Validation Loss: 0.3052, Accuracy: 95.05%, Precision: 99.93%, Recall: 92.09%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3019, Average Validation Loss: 0.2769, Accuracy: 96.76%, Precision: 99.90%, Recall: 94.71%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2815, Average Validation Loss: 0.2511, Accuracy: 97.01%, Precision: 99.92%, Recall: 95.10%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2607, Average Validation Loss: 0.2263, Accuracy: 96.94%, Precision: 99.94%, Recall: 94.97%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2354, Average Validation Loss: 0.2034, Accuracy: 96.29%, Precision: 99.97%, Recall: 93.93%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2100, Average Validation Loss: 0.1867, Accuracy: 95.09%, Precision: 100.00%, Recall: 92.09%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.1903, Average Validation Loss: 0.1854, Accuracy: 93.35%, Precision: 100.00%, Recall: 89.58%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.1670, Average Validation Loss: 0.1766, Accuracy: 92.58%, Precision: 100.00%, Recall: 88.52%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.1463, Average Validation Loss: 0.1803, Accuracy: 90.89%, Precision: 100.00%, Recall: 86.27%, F1: 0.93\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1256, Average Validation Loss: 0.1803, Accuracy: 90.56%, Precision: 100.00%, Recall: 85.84%, F1: 0.92\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0967, Average Validation Loss: 0.1674, Accuracy: 92.17%, Precision: 100.00%, Recall: 87.96%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.0770, Average Validation Loss: 0.1835, Accuracy: 91.45%, Precision: 100.00%, Recall: 86.99%, F1: 0.93\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0651, Average Validation Loss: 0.1793, Accuracy: 92.62%, Precision: 100.00%, Recall: 88.57%, F1: 0.94\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0469, Average Validation Loss: 0.1439, Accuracy: 95.94%, Precision: 100.00%, Recall: 93.37%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.0411, Average Validation Loss: 0.1329, Accuracy: 97.11%, Precision: 100.00%, Recall: 95.19%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0393, Average Validation Loss: 0.1229, Accuracy: 97.64%, Precision: 100.00%, Recall: 96.03%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0342, Average Validation Loss: 0.1069, Accuracy: 98.07%, Precision: 100.00%, Recall: 96.73%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0252, Average Validation Loss: 0.1107, Accuracy: 98.07%, Precision: 100.00%, Recall: 96.74%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0242, Average Validation Loss: 0.1055, Accuracy: 98.25%, Precision: 100.00%, Recall: 97.03%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0287, Average Validation Loss: 0.0889, Accuracy: 98.50%, Precision: 100.00%, Recall: 97.44%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0230, Average Validation Loss: 0.0877, Accuracy: 98.53%, Precision: 100.00%, Recall: 97.50%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0234, Average Validation Loss: 0.0893, Accuracy: 98.55%, Precision: 100.00%, Recall: 97.52%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0227, Average Validation Loss: 0.0882, Accuracy: 98.58%, Precision: 100.00%, Recall: 97.58%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0258, Average Validation Loss: 0.0814, Accuracy: 98.60%, Precision: 100.00%, Recall: 97.61%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0254, Average Validation Loss: 0.0774, Accuracy: 98.61%, Precision: 100.00%, Recall: 97.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0167, Average Validation Loss: 0.0854, Accuracy: 98.59%, Precision: 100.00%, Recall: 97.60%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0260, Average Validation Loss: 0.0843, Accuracy: 98.59%, Precision: 100.00%, Recall: 97.60%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0248, Average Validation Loss: 0.0824, Accuracy: 98.61%, Precision: 100.00%, Recall: 97.63%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0153, Average Validation Loss: 0.0820, Accuracy: 98.61%, Precision: 100.00%, Recall: 97.63%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0182, Average Validation Loss: 0.0850, Accuracy: 98.60%, Precision: 100.00%, Recall: 97.61%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 15:20:42,028] Trial 0 finished with value: 0.08501243356653061 and parameters: {'vector_length': 1024, 'num_blocks': 1, 'num_heads': 4, 'num_epochs': 5, 'dropout': 0.4, 'metadata_vector_length': 1024, 'lr': 7.471456961536299e-06, 'warmup_steps': 90}. Best is trial 0 with value: 0.08501243356653061.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 49,601,536 parameters\n","Num non-decayed parameter tensors: 29, with 44,034 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6876, Average Validation Loss: 0.6699, Accuracy: 57.17%, Precision: 99.95%, Recall: 57.19%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6391, Average Validation Loss: 0.6313, Accuracy: 57.35%, Precision: 99.96%, Recall: 57.28%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6025, Average Validation Loss: 0.5636, Accuracy: 69.68%, Precision: 99.96%, Recall: 65.37%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5469, Average Validation Loss: 0.5430, Accuracy: 62.95%, Precision: 99.99%, Recall: 60.69%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5140, Average Validation Loss: 0.4882, Accuracy: 74.02%, Precision: 99.99%, Recall: 68.76%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.4830, Average Validation Loss: 0.4423, Accuracy: 84.26%, Precision: 99.99%, Recall: 78.42%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4459, Average Validation Loss: 0.4090, Accuracy: 85.15%, Precision: 99.99%, Recall: 79.39%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.4204, Average Validation Loss: 0.3708, Accuracy: 92.30%, Precision: 99.93%, Recall: 88.18%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.3866, Average Validation Loss: 0.3721, Accuracy: 80.39%, Precision: 100.00%, Recall: 74.47%, F1: 0.85\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.3566, Average Validation Loss: 0.3090, Accuracy: 93.45%, Precision: 99.92%, Recall: 89.78%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3237, Average Validation Loss: 0.3016, Accuracy: 86.62%, Precision: 100.00%, Recall: 81.04%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.2932, Average Validation Loss: 0.2640, Accuracy: 89.76%, Precision: 99.98%, Recall: 84.83%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.2770, Average Validation Loss: 0.2290, Accuracy: 92.31%, Precision: 99.92%, Recall: 88.20%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.2514, Average Validation Loss: 0.2205, Accuracy: 89.25%, Precision: 99.99%, Recall: 84.19%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.2283, Average Validation Loss: 0.2676, Accuracy: 84.97%, Precision: 100.00%, Recall: 79.19%, F1: 0.88\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.2104, Average Validation Loss: 0.1815, Accuracy: 89.71%, Precision: 99.99%, Recall: 84.76%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.1795, Average Validation Loss: 0.3254, Accuracy: 84.16%, Precision: 100.00%, Recall: 78.31%, F1: 0.88\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1498, Average Validation Loss: 0.4389, Accuracy: 82.97%, Precision: 100.00%, Recall: 77.06%, F1: 0.87\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0956, Average Validation Loss: 0.3849, Accuracy: 84.33%, Precision: 100.00%, Recall: 78.50%, F1: 0.88\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0501, Average Validation Loss: 0.4317, Accuracy: 84.13%, Precision: 100.00%, Recall: 78.28%, F1: 0.88\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0209, Average Validation Loss: 0.3063, Accuracy: 89.69%, Precision: 100.00%, Recall: 84.73%, F1: 0.92\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["W1206 15:27:08.604000 523 torch/_dynamo/convert_frame.py:844] [0/8] torch._dynamo hit config.cache_size_limit (8)\n","W1206 15:27:08.604000 523 torch/_dynamo/convert_frame.py:844] [0/8]    function: 'forward' (/content/drive/MyDrive/AI_Cybersecurity/Project/utils.py:777)\n","W1206 15:27:08.604000 523 torch/_dynamo/convert_frame.py:844] [0/8]    last reason: 0/1: GLOBAL_STATE changed: grad_mode \n","W1206 15:27:08.604000 523 torch/_dynamo/convert_frame.py:844] [0/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n","W1206 15:27:08.604000 523 torch/_dynamo/convert_frame.py:844] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n","[I 2024-12-06 15:27:08,613] Trial 1 finished with value: 0.30669411376521394 and parameters: {'vector_length': 1024, 'num_blocks': 3, 'num_heads': 8, 'num_epochs': 5, 'dropout': 0.4, 'metadata_vector_length': 1024, 'lr': 6.351891365972909e-06, 'warmup_steps': 10}. Best is trial 0 with value: 0.08501243356653061.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 4,339,456 parameters\n","Num non-decayed parameter tensors: 21, with 7,682 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7384, Average Validation Loss: 0.7291, Accuracy: 23.89%, Precision: 34.67%, Recall: 33.85%, F1: 0.34\n","Epoch 0, Average Training Loss: 0.7214, Average Validation Loss: 0.7009, Accuracy: 57.13%, Precision: 99.83%, Recall: 57.17%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6949, Average Validation Loss: 0.6736, Accuracy: 57.20%, Precision: 99.96%, Recall: 57.20%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6630, Average Validation Loss: 0.6289, Accuracy: 59.18%, Precision: 99.96%, Recall: 58.36%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6091, Average Validation Loss: 0.5876, Accuracy: 59.51%, Precision: 99.99%, Recall: 58.55%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.5627, Average Validation Loss: 0.5278, Accuracy: 71.54%, Precision: 100.00%, Recall: 66.77%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.4995, Average Validation Loss: 0.4705, Accuracy: 76.42%, Precision: 100.00%, Recall: 70.81%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.4526, Average Validation Loss: 0.3946, Accuracy: 91.04%, Precision: 99.93%, Recall: 86.50%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.3917, Average Validation Loss: 0.3321, Accuracy: 92.60%, Precision: 99.92%, Recall: 88.60%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.3364, Average Validation Loss: 0.2605, Accuracy: 94.67%, Precision: 99.93%, Recall: 91.53%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2761, Average Validation Loss: 0.2134, Accuracy: 88.82%, Precision: 100.00%, Recall: 83.65%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.1980, Average Validation Loss: 0.2492, Accuracy: 84.87%, Precision: 100.00%, Recall: 79.08%, F1: 0.88\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1059, Average Validation Loss: 0.2768, Accuracy: 85.41%, Precision: 100.00%, Recall: 79.67%, F1: 0.89\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0429, Average Validation Loss: 0.2624, Accuracy: 87.93%, Precision: 100.00%, Recall: 82.57%, F1: 0.90\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0231, Average Validation Loss: 0.0930, Accuracy: 97.45%, Precision: 100.00%, Recall: 95.73%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0248, Average Validation Loss: 0.0718, Accuracy: 98.11%, Precision: 100.00%, Recall: 96.81%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0239, Average Validation Loss: 0.0692, Accuracy: 98.18%, Precision: 100.00%, Recall: 96.92%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0273, Average Validation Loss: 0.0577, Accuracy: 98.38%, Precision: 100.00%, Recall: 97.25%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0232, Average Validation Loss: 0.0768, Accuracy: 97.77%, Precision: 100.00%, Recall: 96.25%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0233, Average Validation Loss: 0.0568, Accuracy: 98.34%, Precision: 100.00%, Recall: 97.18%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0196, Average Validation Loss: 0.0719, Accuracy: 97.89%, Precision: 100.00%, Recall: 96.45%, F1: 0.98\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0307, Average Validation Loss: 0.0449, Accuracy: 98.49%, Precision: 100.00%, Recall: 97.43%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0121, Average Validation Loss: 0.0789, Accuracy: 97.56%, Precision: 100.00%, Recall: 95.91%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0306, Average Validation Loss: 0.0618, Accuracy: 98.05%, Precision: 100.00%, Recall: 96.70%, F1: 0.98\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0162, Average Validation Loss: 0.0470, Accuracy: 98.42%, Precision: 100.00%, Recall: 97.31%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0236, Average Validation Loss: 0.0442, Accuracy: 98.48%, Precision: 100.00%, Recall: 97.41%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0160, Average Validation Loss: 0.0440, Accuracy: 98.46%, Precision: 100.00%, Recall: 97.39%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 15:30:04,652] Trial 2 finished with value: 0.04401034031698883 and parameters: {'vector_length': 256, 'num_blocks': 2, 'num_heads': 2, 'num_epochs': 2, 'dropout': 0.4, 'metadata_vector_length': 256, 'lr': 7.39852280408785e-05, 'warmup_steps': 70}. Best is trial 2 with value: 0.04401034031698883.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 9, with 3,553,024 parameters\n","Num non-decayed parameter tensors: 13, with 4,354 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7280, Average Validation Loss: 0.7240, Accuracy: 23.08%, Precision: 8.34%, Recall: 16.30%, F1: 0.11\n","Epoch 0, Average Training Loss: 0.7226, Average Validation Loss: 0.7230, Accuracy: 23.02%, Precision: 9.89%, Recall: 18.19%, F1: 0.13\n","Epoch 0, Average Training Loss: 0.7214, Average Validation Loss: 0.7213, Accuracy: 22.95%, Precision: 12.62%, Recall: 21.05%, F1: 0.16\n","Epoch 0, Average Training Loss: 0.7232, Average Validation Loss: 0.7190, Accuracy: 23.72%, Precision: 17.46%, Recall: 25.56%, F1: 0.21\n","Epoch 0, Average Training Loss: 0.7179, Average Validation Loss: 0.7160, Accuracy: 26.64%, Precision: 25.90%, Recall: 32.35%, F1: 0.29\n","Epoch 0, Average Training Loss: 0.7146, Average Validation Loss: 0.7126, Accuracy: 32.13%, Precision: 38.03%, Recall: 40.14%, F1: 0.39\n","Epoch 0, Average Training Loss: 0.7121, Average Validation Loss: 0.7087, Accuracy: 39.84%, Precision: 54.18%, Recall: 47.71%, F1: 0.51\n","Epoch 0, Average Training Loss: 0.7071, Average Validation Loss: 0.7044, Accuracy: 47.77%, Precision: 72.02%, Recall: 53.20%, F1: 0.61\n","Epoch 0, Average Training Loss: 0.7003, Average Validation Loss: 0.6998, Accuracy: 53.44%, Precision: 85.41%, Recall: 56.11%, F1: 0.68\n","Epoch 0, Average Training Loss: 0.6982, Average Validation Loss: 0.6950, Accuracy: 57.28%, Precision: 93.78%, Recall: 57.80%, F1: 0.72\n","Epoch 0, Average Training Loss: 0.6974, Average Validation Loss: 0.6901, Accuracy: 58.56%, Precision: 97.46%, Recall: 58.22%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6919, Average Validation Loss: 0.6855, Accuracy: 58.91%, Precision: 98.88%, Recall: 58.30%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6861, Average Validation Loss: 0.6811, Accuracy: 58.99%, Precision: 99.35%, Recall: 58.30%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6789, Average Validation Loss: 0.6769, Accuracy: 59.04%, Precision: 99.61%, Recall: 58.30%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6780, Average Validation Loss: 0.6728, Accuracy: 59.03%, Precision: 99.73%, Recall: 58.29%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6731, Average Validation Loss: 0.6689, Accuracy: 59.04%, Precision: 99.78%, Recall: 58.29%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6715, Average Validation Loss: 0.6649, Accuracy: 59.06%, Precision: 99.82%, Recall: 58.30%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6601, Average Validation Loss: 0.6612, Accuracy: 59.12%, Precision: 99.86%, Recall: 58.33%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6611, Average Validation Loss: 0.6575, Accuracy: 59.12%, Precision: 99.88%, Recall: 58.33%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6580, Average Validation Loss: 0.6538, Accuracy: 59.09%, Precision: 99.90%, Recall: 58.31%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6550, Average Validation Loss: 0.6503, Accuracy: 59.09%, Precision: 99.90%, Recall: 58.31%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6444, Average Validation Loss: 0.6469, Accuracy: 59.11%, Precision: 99.90%, Recall: 58.32%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6427, Average Validation Loss: 0.6434, Accuracy: 59.15%, Precision: 99.91%, Recall: 58.34%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6405, Average Validation Loss: 0.6395, Accuracy: 59.18%, Precision: 99.91%, Recall: 58.36%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6391, Average Validation Loss: 0.6364, Accuracy: 59.33%, Precision: 99.92%, Recall: 58.45%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6368, Average Validation Loss: 0.6328, Accuracy: 59.43%, Precision: 99.93%, Recall: 58.51%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6312, Average Validation Loss: 0.6296, Accuracy: 59.46%, Precision: 99.93%, Recall: 58.53%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6251, Average Validation Loss: 0.6263, Accuracy: 59.53%, Precision: 99.93%, Recall: 58.57%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6276, Average Validation Loss: 0.6231, Accuracy: 59.57%, Precision: 99.93%, Recall: 58.59%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6189, Average Validation Loss: 0.6198, Accuracy: 59.63%, Precision: 99.93%, Recall: 58.63%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6173, Average Validation Loss: 0.6169, Accuracy: 59.75%, Precision: 99.93%, Recall: 58.70%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6196, Average Validation Loss: 0.6135, Accuracy: 59.97%, Precision: 99.93%, Recall: 58.83%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6210, Average Validation Loss: 0.6102, Accuracy: 60.27%, Precision: 99.93%, Recall: 59.01%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6088, Average Validation Loss: 0.6070, Accuracy: 60.50%, Precision: 99.93%, Recall: 59.16%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6144, Average Validation Loss: 0.6036, Accuracy: 60.85%, Precision: 99.93%, Recall: 59.37%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6014, Average Validation Loss: 0.6004, Accuracy: 61.05%, Precision: 99.93%, Recall: 59.49%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6015, Average Validation Loss: 0.5975, Accuracy: 61.34%, Precision: 99.93%, Recall: 59.68%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5969, Average Validation Loss: 0.5943, Accuracy: 61.60%, Precision: 99.93%, Recall: 59.83%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5964, Average Validation Loss: 0.5912, Accuracy: 61.99%, Precision: 99.93%, Recall: 60.08%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5910, Average Validation Loss: 0.5883, Accuracy: 62.34%, Precision: 99.93%, Recall: 60.31%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5905, Average Validation Loss: 0.5851, Accuracy: 63.15%, Precision: 99.93%, Recall: 60.82%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5829, Average Validation Loss: 0.5822, Accuracy: 63.87%, Precision: 99.93%, Recall: 61.29%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5883, Average Validation Loss: 0.5791, Accuracy: 64.75%, Precision: 99.93%, Recall: 61.88%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5810, Average Validation Loss: 0.5764, Accuracy: 65.56%, Precision: 99.93%, Recall: 62.42%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5789, Average Validation Loss: 0.5733, Accuracy: 66.43%, Precision: 99.93%, Recall: 63.02%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5760, Average Validation Loss: 0.5703, Accuracy: 67.21%, Precision: 99.93%, Recall: 63.57%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5745, Average Validation Loss: 0.5677, Accuracy: 68.23%, Precision: 99.93%, Recall: 64.30%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5689, Average Validation Loss: 0.5645, Accuracy: 69.38%, Precision: 99.93%, Recall: 65.14%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5640, Average Validation Loss: 0.5619, Accuracy: 69.82%, Precision: 99.93%, Recall: 65.47%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5650, Average Validation Loss: 0.5590, Accuracy: 70.64%, Precision: 99.93%, Recall: 66.09%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5630, Average Validation Loss: 0.5565, Accuracy: 71.83%, Precision: 99.93%, Recall: 67.01%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5576, Average Validation Loss: 0.5536, Accuracy: 72.74%, Precision: 99.93%, Recall: 67.74%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5581, Average Validation Loss: 0.5510, Accuracy: 73.64%, Precision: 99.93%, Recall: 68.47%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5486, Average Validation Loss: 0.5482, Accuracy: 74.18%, Precision: 99.93%, Recall: 68.92%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5587, Average Validation Loss: 0.5455, Accuracy: 75.72%, Precision: 99.93%, Recall: 70.21%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5520, Average Validation Loss: 0.5430, Accuracy: 77.45%, Precision: 99.93%, Recall: 71.74%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5448, Average Validation Loss: 0.5405, Accuracy: 78.95%, Precision: 99.93%, Recall: 73.12%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5399, Average Validation Loss: 0.5379, Accuracy: 79.74%, Precision: 99.93%, Recall: 73.86%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.5456, Average Validation Loss: 0.5355, Accuracy: 80.67%, Precision: 99.93%, Recall: 74.77%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.5391, Average Validation Loss: 0.5330, Accuracy: 81.29%, Precision: 99.94%, Recall: 75.37%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.5407, Average Validation Loss: 0.5305, Accuracy: 82.18%, Precision: 99.94%, Recall: 76.27%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.5347, Average Validation Loss: 0.5280, Accuracy: 83.49%, Precision: 99.94%, Recall: 77.62%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.5301, Average Validation Loss: 0.5255, Accuracy: 84.19%, Precision: 99.94%, Recall: 78.37%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.5313, Average Validation Loss: 0.5237, Accuracy: 85.37%, Precision: 99.94%, Recall: 79.66%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.5345, Average Validation Loss: 0.5211, Accuracy: 86.40%, Precision: 99.94%, Recall: 80.82%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.5220, Average Validation Loss: 0.5187, Accuracy: 86.84%, Precision: 99.94%, Recall: 81.33%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.5259, Average Validation Loss: 0.5165, Accuracy: 87.30%, Precision: 99.94%, Recall: 81.86%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.5221, Average Validation Loss: 0.5145, Accuracy: 87.37%, Precision: 99.94%, Recall: 81.94%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.5159, Average Validation Loss: 0.5123, Accuracy: 88.03%, Precision: 99.94%, Recall: 82.72%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.5212, Average Validation Loss: 0.5100, Accuracy: 88.86%, Precision: 99.94%, Recall: 83.73%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.5160, Average Validation Loss: 0.5081, Accuracy: 89.51%, Precision: 99.94%, Recall: 84.53%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.5083, Average Validation Loss: 0.5060, Accuracy: 89.52%, Precision: 99.94%, Recall: 84.54%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.5068, Average Validation Loss: 0.5043, Accuracy: 89.48%, Precision: 99.94%, Recall: 84.50%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.5068, Average Validation Loss: 0.5023, Accuracy: 89.18%, Precision: 99.94%, Recall: 84.13%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.5039, Average Validation Loss: 0.5002, Accuracy: 88.63%, Precision: 99.94%, Recall: 83.44%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.5081, Average Validation Loss: 0.4985, Accuracy: 88.43%, Precision: 99.95%, Recall: 83.21%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.4952, Average Validation Loss: 0.4966, Accuracy: 88.63%, Precision: 99.95%, Recall: 83.44%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.5022, Average Validation Loss: 0.4946, Accuracy: 88.87%, Precision: 99.96%, Recall: 83.73%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.5056, Average Validation Loss: 0.4930, Accuracy: 89.48%, Precision: 99.96%, Recall: 84.49%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.4963, Average Validation Loss: 0.4913, Accuracy: 90.05%, Precision: 99.96%, Recall: 85.21%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.4959, Average Validation Loss: 0.4894, Accuracy: 90.43%, Precision: 99.96%, Recall: 85.69%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.4902, Average Validation Loss: 0.4877, Accuracy: 90.61%, Precision: 99.96%, Recall: 85.92%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.4902, Average Validation Loss: 0.4860, Accuracy: 90.78%, Precision: 99.96%, Recall: 86.14%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4887, Average Validation Loss: 0.4845, Accuracy: 90.89%, Precision: 99.96%, Recall: 86.29%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4861, Average Validation Loss: 0.4827, Accuracy: 91.19%, Precision: 99.96%, Recall: 86.68%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4835, Average Validation Loss: 0.4814, Accuracy: 91.01%, Precision: 99.96%, Recall: 86.45%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4863, Average Validation Loss: 0.4799, Accuracy: 91.11%, Precision: 99.96%, Recall: 86.58%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4869, Average Validation Loss: 0.4783, Accuracy: 91.31%, Precision: 99.96%, Recall: 86.84%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4857, Average Validation Loss: 0.4769, Accuracy: 91.70%, Precision: 99.96%, Recall: 87.35%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4798, Average Validation Loss: 0.4755, Accuracy: 91.77%, Precision: 99.96%, Recall: 87.45%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4807, Average Validation Loss: 0.4741, Accuracy: 92.01%, Precision: 99.96%, Recall: 87.77%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4814, Average Validation Loss: 0.4728, Accuracy: 92.20%, Precision: 99.95%, Recall: 88.03%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4819, Average Validation Loss: 0.4713, Accuracy: 92.43%, Precision: 99.95%, Recall: 88.35%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4705, Average Validation Loss: 0.4701, Accuracy: 92.45%, Precision: 99.95%, Recall: 88.37%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4665, Average Validation Loss: 0.4687, Accuracy: 92.33%, Precision: 99.95%, Recall: 88.21%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4695, Average Validation Loss: 0.4679, Accuracy: 92.20%, Precision: 99.95%, Recall: 88.03%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4654, Average Validation Loss: 0.4664, Accuracy: 92.17%, Precision: 99.95%, Recall: 87.99%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4701, Average Validation Loss: 0.4654, Accuracy: 92.22%, Precision: 99.95%, Recall: 88.06%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4691, Average Validation Loss: 0.4641, Accuracy: 92.29%, Precision: 99.95%, Recall: 88.15%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4668, Average Validation Loss: 0.4631, Accuracy: 92.37%, Precision: 99.95%, Recall: 88.27%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4651, Average Validation Loss: 0.4623, Accuracy: 92.43%, Precision: 99.95%, Recall: 88.35%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4650, Average Validation Loss: 0.4609, Accuracy: 92.44%, Precision: 99.95%, Recall: 88.36%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4622, Average Validation Loss: 0.4597, Accuracy: 92.51%, Precision: 99.95%, Recall: 88.46%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4609, Average Validation Loss: 0.4591, Accuracy: 92.55%, Precision: 99.95%, Recall: 88.51%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4666, Average Validation Loss: 0.4580, Accuracy: 92.74%, Precision: 99.95%, Recall: 88.76%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4609, Average Validation Loss: 0.4568, Accuracy: 92.85%, Precision: 99.95%, Recall: 88.92%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4588, Average Validation Loss: 0.4561, Accuracy: 93.04%, Precision: 99.95%, Recall: 89.19%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4512, Average Validation Loss: 0.4550, Accuracy: 93.03%, Precision: 99.95%, Recall: 89.17%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4615, Average Validation Loss: 0.4541, Accuracy: 93.03%, Precision: 99.95%, Recall: 89.18%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4567, Average Validation Loss: 0.4533, Accuracy: 93.10%, Precision: 99.95%, Recall: 89.27%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.4592, Average Validation Loss: 0.4525, Accuracy: 93.27%, Precision: 99.95%, Recall: 89.51%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4637, Average Validation Loss: 0.4517, Accuracy: 93.43%, Precision: 99.95%, Recall: 89.73%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4579, Average Validation Loss: 0.4508, Accuracy: 93.53%, Precision: 99.94%, Recall: 89.88%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4552, Average Validation Loss: 0.4501, Accuracy: 93.60%, Precision: 99.94%, Recall: 89.98%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4503, Average Validation Loss: 0.4492, Accuracy: 93.67%, Precision: 99.94%, Recall: 90.07%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4503, Average Validation Loss: 0.4487, Accuracy: 93.71%, Precision: 99.94%, Recall: 90.14%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4562, Average Validation Loss: 0.4480, Accuracy: 93.79%, Precision: 99.94%, Recall: 90.25%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4480, Average Validation Loss: 0.4474, Accuracy: 93.84%, Precision: 99.94%, Recall: 90.32%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4510, Average Validation Loss: 0.4469, Accuracy: 93.86%, Precision: 99.94%, Recall: 90.35%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4521, Average Validation Loss: 0.4462, Accuracy: 93.92%, Precision: 99.94%, Recall: 90.43%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4540, Average Validation Loss: 0.4458, Accuracy: 93.95%, Precision: 99.94%, Recall: 90.48%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4530, Average Validation Loss: 0.4449, Accuracy: 93.93%, Precision: 99.94%, Recall: 90.44%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4572, Average Validation Loss: 0.4446, Accuracy: 93.98%, Precision: 99.94%, Recall: 90.52%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4509, Average Validation Loss: 0.4439, Accuracy: 94.09%, Precision: 99.94%, Recall: 90.67%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4487, Average Validation Loss: 0.4435, Accuracy: 94.14%, Precision: 99.94%, Recall: 90.75%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4493, Average Validation Loss: 0.4429, Accuracy: 94.21%, Precision: 99.94%, Recall: 90.85%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4453, Average Validation Loss: 0.4425, Accuracy: 94.27%, Precision: 99.94%, Recall: 90.94%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4497, Average Validation Loss: 0.4420, Accuracy: 94.33%, Precision: 99.94%, Recall: 91.02%, F1: 0.95\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.4473, Average Validation Loss: 0.4416, Accuracy: 94.36%, Precision: 99.94%, Recall: 91.07%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4513, Average Validation Loss: 0.4409, Accuracy: 94.40%, Precision: 99.94%, Recall: 91.13%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4487, Average Validation Loss: 0.4406, Accuracy: 94.43%, Precision: 99.94%, Recall: 91.17%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4439, Average Validation Loss: 0.4403, Accuracy: 94.44%, Precision: 99.94%, Recall: 91.19%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4395, Average Validation Loss: 0.4397, Accuracy: 94.44%, Precision: 99.94%, Recall: 91.18%, F1: 0.95\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.4506, Average Validation Loss: 0.4395, Accuracy: 94.44%, Precision: 99.94%, Recall: 91.19%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4421, Average Validation Loss: 0.4389, Accuracy: 94.44%, Precision: 99.94%, Recall: 91.19%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4432, Average Validation Loss: 0.4387, Accuracy: 94.46%, Precision: 99.94%, Recall: 91.21%, F1: 0.95\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.4495, Average Validation Loss: 0.4382, Accuracy: 94.47%, Precision: 99.94%, Recall: 91.23%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4457, Average Validation Loss: 0.4379, Accuracy: 94.47%, Precision: 99.94%, Recall: 91.23%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4432, Average Validation Loss: 0.4377, Accuracy: 94.47%, Precision: 99.94%, Recall: 91.22%, F1: 0.95\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.4445, Average Validation Loss: 0.4372, Accuracy: 94.50%, Precision: 99.94%, Recall: 91.28%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4452, Average Validation Loss: 0.4368, Accuracy: 94.50%, Precision: 99.94%, Recall: 91.28%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4401, Average Validation Loss: 0.4367, Accuracy: 94.52%, Precision: 99.94%, Recall: 91.31%, F1: 0.95\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.4400, Average Validation Loss: 0.4364, Accuracy: 94.52%, Precision: 99.94%, Recall: 91.31%, F1: 0.95\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.4413, Average Validation Loss: 0.4360, Accuracy: 94.55%, Precision: 99.94%, Recall: 91.35%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.4446, Average Validation Loss: 0.4358, Accuracy: 94.59%, Precision: 99.94%, Recall: 91.41%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.4380, Average Validation Loss: 0.4351, Accuracy: 94.63%, Precision: 99.94%, Recall: 91.46%, F1: 0.96\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.4424, Average Validation Loss: 0.4349, Accuracy: 94.64%, Precision: 99.94%, Recall: 91.47%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.1327, Average Validation Loss: 0.4349, Accuracy: 94.64%, Precision: 99.94%, Recall: 91.48%, F1: 0.96\n","No significant improvement in validation loss for 1 step(s).\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 15:45:02,628] Trial 3 finished with value: 0.43941709077036056 and parameters: {'vector_length': 256, 'num_blocks': 1, 'num_heads': 8, 'num_epochs': 1, 'dropout': 0.2, 'metadata_vector_length': 256, 'lr': 3.5121611335096927e-06, 'warmup_steps': 100}. Best is trial 2 with value: 0.04401034031698883.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 9, with 1,723,008 parameters\n","Num non-decayed parameter tensors: 13, with 3,074 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6308, Average Validation Loss: 0.5283, Accuracy: 87.59%, Precision: 99.96%, Recall: 82.19%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.4068, Average Validation Loss: 0.2602, Accuracy: 98.67%, Precision: 99.62%, Recall: 98.09%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1784, Average Validation Loss: 0.1140, Accuracy: 99.11%, Precision: 99.26%, Recall: 99.19%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0898, Average Validation Loss: 0.0600, Accuracy: 99.34%, Precision: 99.56%, Recall: 99.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0518, Average Validation Loss: 0.0381, Accuracy: 99.48%, Precision: 99.70%, Recall: 99.39%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0305, Average Validation Loss: 0.0275, Accuracy: 99.58%, Precision: 99.77%, Recall: 99.49%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0249, Average Validation Loss: 0.0218, Accuracy: 99.65%, Precision: 99.83%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0181, Accuracy: 99.73%, Precision: 99.85%, Recall: 99.68%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0197, Average Validation Loss: 0.0155, Accuracy: 99.77%, Precision: 99.87%, Recall: 99.72%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0135, Average Validation Loss: 0.0135, Accuracy: 99.80%, Precision: 99.90%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0101, Average Validation Loss: 0.0120, Accuracy: 99.82%, Precision: 99.90%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0107, Average Validation Loss: 0.0105, Accuracy: 99.85%, Precision: 99.95%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0092, Average Validation Loss: 0.0093, Accuracy: 99.85%, Precision: 99.95%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0087, Average Validation Loss: 0.0084, Accuracy: 99.85%, Precision: 99.96%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0073, Accuracy: 99.86%, Precision: 99.96%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0097, Average Validation Loss: 0.0063, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0071, Average Validation Loss: 0.0055, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0049, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0048, Average Validation Loss: 0.0043, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0034, Average Validation Loss: 0.0040, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0035, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.83%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0030, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0025, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.89%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0023, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0022, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.89%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0023, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0035, Average Validation Loss: 0.0020, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0019, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 15:47:45,753] Trial 4 finished with value: 0.0019219860409361285 and parameters: {'vector_length': 128, 'num_blocks': 1, 'num_heads': 8, 'num_epochs': 5, 'dropout': 0.1, 'metadata_vector_length': 1024, 'lr': 0.00022661022513990387, 'warmup_steps': 20}. Best is trial 4 with value: 0.0019219860409361285.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 9, with 4,101,376 parameters\n","Num non-decayed parameter tensors: 13, with 6,146 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6587, Average Validation Loss: 0.5936, Accuracy: 92.77%, Precision: 97.37%, Recall: 90.67%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.5106, Average Validation Loss: 0.3963, Accuracy: 93.56%, Precision: 99.87%, Recall: 89.97%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3153, Average Validation Loss: 0.2131, Accuracy: 98.22%, Precision: 99.69%, Recall: 97.27%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1647, Average Validation Loss: 0.1165, Accuracy: 99.17%, Precision: 99.33%, Recall: 99.22%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0942, Average Validation Loss: 0.0743, Accuracy: 99.33%, Precision: 99.61%, Recall: 99.21%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0737, Average Validation Loss: 0.0542, Accuracy: 99.44%, Precision: 99.81%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0495, Average Validation Loss: 0.0412, Accuracy: 99.56%, Precision: 99.83%, Recall: 99.40%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0399, Average Validation Loss: 0.0335, Accuracy: 99.66%, Precision: 99.83%, Recall: 99.59%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0357, Average Validation Loss: 0.0279, Accuracy: 99.75%, Precision: 99.87%, Recall: 99.68%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0277, Average Validation Loss: 0.0241, Accuracy: 99.79%, Precision: 99.92%, Recall: 99.72%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0228, Average Validation Loss: 0.0208, Accuracy: 99.82%, Precision: 99.93%, Recall: 99.75%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0211, Average Validation Loss: 0.0185, Accuracy: 99.82%, Precision: 99.93%, Recall: 99.75%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0164, Accuracy: 99.84%, Precision: 99.94%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0163, Average Validation Loss: 0.0149, Accuracy: 99.84%, Precision: 99.94%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0136, Accuracy: 99.83%, Precision: 99.95%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0152, Average Validation Loss: 0.0126, Accuracy: 99.83%, Precision: 99.97%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0102, Average Validation Loss: 0.0114, Accuracy: 99.85%, Precision: 99.98%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0112, Average Validation Loss: 0.0104, Accuracy: 99.87%, Precision: 99.98%, Recall: 99.80%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0124, Average Validation Loss: 0.0092, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.82%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0108, Average Validation Loss: 0.0083, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0075, Average Validation Loss: 0.0079, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0088, Average Validation Loss: 0.0072, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0068, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.77%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0044, Average Validation Loss: 0.0062, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0038, Average Validation Loss: 0.0061, Accuracy: 99.85%, Precision: 99.99%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0055, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0051, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0044, Average Validation Loss: 0.0048, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0047, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0034, Average Validation Loss: 0.0049, Accuracy: 99.85%, Precision: 99.99%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0046, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 15:50:56,462] Trial 5 finished with value: 0.004531388479675091 and parameters: {'vector_length': 256, 'num_blocks': 1, 'num_heads': 8, 'num_epochs': 2, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 7.191901791978916e-05, 'warmup_steps': 30}. Best is trial 4 with value: 0.0019219860409361285.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 1,760,128 parameters\n","Num non-decayed parameter tensors: 21, with 3,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7137, Average Validation Loss: 0.7183, Accuracy: 34.39%, Precision: 52.33%, Recall: 43.84%, F1: 0.48\n","Epoch 0, Average Training Loss: 0.7162, Average Validation Loss: 0.7179, Accuracy: 34.94%, Precision: 53.71%, Recall: 44.32%, F1: 0.49\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.7218, Average Validation Loss: 0.7172, Accuracy: 35.91%, Precision: 55.89%, Recall: 45.13%, F1: 0.50\n","Epoch 0, Average Training Loss: 0.7143, Average Validation Loss: 0.7164, Accuracy: 37.16%, Precision: 58.60%, Recall: 46.12%, F1: 0.52\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.7186, Average Validation Loss: 0.7153, Accuracy: 38.98%, Precision: 62.51%, Recall: 47.46%, F1: 0.54\n","Epoch 0, Average Training Loss: 0.7106, Average Validation Loss: 0.7137, Accuracy: 41.15%, Precision: 67.28%, Recall: 48.94%, F1: 0.57\n","Epoch 0, Average Training Loss: 0.7095, Average Validation Loss: 0.7119, Accuracy: 43.89%, Precision: 73.12%, Recall: 50.66%, F1: 0.60\n","Epoch 0, Average Training Loss: 0.7063, Average Validation Loss: 0.7101, Accuracy: 47.06%, Precision: 79.70%, Recall: 52.44%, F1: 0.63\n","Epoch 0, Average Training Loss: 0.7115, Average Validation Loss: 0.7081, Accuracy: 49.82%, Precision: 85.08%, Recall: 53.88%, F1: 0.66\n","Epoch 0, Average Training Loss: 0.7044, Average Validation Loss: 0.7060, Accuracy: 52.47%, Precision: 90.34%, Recall: 55.15%, F1: 0.68\n","Epoch 0, Average Training Loss: 0.7053, Average Validation Loss: 0.7041, Accuracy: 54.38%, Precision: 93.90%, Recall: 56.04%, F1: 0.70\n","Epoch 0, Average Training Loss: 0.7018, Average Validation Loss: 0.7024, Accuracy: 55.53%, Precision: 96.11%, Recall: 56.54%, F1: 0.71\n","Epoch 0, Average Training Loss: 0.7007, Average Validation Loss: 0.7005, Accuracy: 56.12%, Precision: 97.22%, Recall: 56.80%, F1: 0.72\n","Epoch 0, Average Training Loss: 0.6961, Average Validation Loss: 0.6990, Accuracy: 56.59%, Precision: 98.16%, Recall: 56.99%, F1: 0.72\n","Epoch 0, Average Training Loss: 0.6962, Average Validation Loss: 0.6975, Accuracy: 56.82%, Precision: 98.60%, Recall: 57.09%, F1: 0.72\n","Epoch 0, Average Training Loss: 0.7013, Average Validation Loss: 0.6957, Accuracy: 56.90%, Precision: 98.81%, Recall: 57.12%, F1: 0.72\n","Epoch 0, Average Training Loss: 0.6905, Average Validation Loss: 0.6943, Accuracy: 57.07%, Precision: 99.10%, Recall: 57.20%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6930, Average Validation Loss: 0.6930, Accuracy: 57.13%, Precision: 99.24%, Recall: 57.22%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6917, Average Validation Loss: 0.6914, Accuracy: 57.21%, Precision: 99.39%, Recall: 57.25%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6898, Average Validation Loss: 0.6902, Accuracy: 57.22%, Precision: 99.47%, Recall: 57.25%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6932, Average Validation Loss: 0.6887, Accuracy: 57.26%, Precision: 99.54%, Recall: 57.27%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6856, Average Validation Loss: 0.6872, Accuracy: 57.27%, Precision: 99.58%, Recall: 57.27%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6842, Average Validation Loss: 0.6856, Accuracy: 57.28%, Precision: 99.61%, Recall: 57.27%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6775, Average Validation Loss: 0.6845, Accuracy: 57.28%, Precision: 99.63%, Recall: 57.28%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6848, Average Validation Loss: 0.6832, Accuracy: 57.30%, Precision: 99.66%, Recall: 57.28%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6845, Average Validation Loss: 0.6816, Accuracy: 57.31%, Precision: 99.67%, Recall: 57.28%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6828, Average Validation Loss: 0.6804, Accuracy: 57.34%, Precision: 99.70%, Recall: 57.30%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6746, Average Validation Loss: 0.6789, Accuracy: 57.35%, Precision: 99.73%, Recall: 57.30%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6744, Average Validation Loss: 0.6778, Accuracy: 57.35%, Precision: 99.73%, Recall: 57.31%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6824, Average Validation Loss: 0.6764, Accuracy: 57.37%, Precision: 99.74%, Recall: 57.32%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6809, Average Validation Loss: 0.6751, Accuracy: 57.38%, Precision: 99.76%, Recall: 57.32%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6765, Average Validation Loss: 0.6737, Accuracy: 57.40%, Precision: 99.76%, Recall: 57.33%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6644, Average Validation Loss: 0.6726, Accuracy: 57.40%, Precision: 99.76%, Recall: 57.33%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6675, Average Validation Loss: 0.6711, Accuracy: 57.40%, Precision: 99.77%, Recall: 57.33%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6679, Average Validation Loss: 0.6700, Accuracy: 57.40%, Precision: 99.78%, Recall: 57.33%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6745, Average Validation Loss: 0.6687, Accuracy: 57.41%, Precision: 99.79%, Recall: 57.33%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6642, Average Validation Loss: 0.6676, Accuracy: 57.42%, Precision: 99.80%, Recall: 57.34%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6605, Average Validation Loss: 0.6662, Accuracy: 57.44%, Precision: 99.81%, Recall: 57.35%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6646, Average Validation Loss: 0.6647, Accuracy: 57.45%, Precision: 99.82%, Recall: 57.35%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6598, Average Validation Loss: 0.6636, Accuracy: 57.46%, Precision: 99.84%, Recall: 57.36%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6710, Average Validation Loss: 0.6622, Accuracy: 57.47%, Precision: 99.85%, Recall: 57.37%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6612, Average Validation Loss: 0.6611, Accuracy: 57.50%, Precision: 99.85%, Recall: 57.38%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6579, Average Validation Loss: 0.6600, Accuracy: 57.53%, Precision: 99.87%, Recall: 57.40%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6632, Average Validation Loss: 0.6586, Accuracy: 57.56%, Precision: 99.87%, Recall: 57.41%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6590, Average Validation Loss: 0.6572, Accuracy: 57.58%, Precision: 99.88%, Recall: 57.42%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6488, Average Validation Loss: 0.6562, Accuracy: 57.59%, Precision: 99.89%, Recall: 57.43%, F1: 0.73\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6528, Average Validation Loss: 0.6545, Accuracy: 57.59%, Precision: 99.90%, Recall: 57.43%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6619, Average Validation Loss: 0.6540, Accuracy: 57.61%, Precision: 99.89%, Recall: 57.44%, F1: 0.73\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6513, Average Validation Loss: 0.6521, Accuracy: 57.63%, Precision: 99.89%, Recall: 57.45%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6545, Average Validation Loss: 0.6511, Accuracy: 57.65%, Precision: 99.89%, Recall: 57.46%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6575, Average Validation Loss: 0.6496, Accuracy: 57.70%, Precision: 99.89%, Recall: 57.49%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6492, Average Validation Loss: 0.6484, Accuracy: 57.75%, Precision: 99.89%, Recall: 57.52%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6428, Average Validation Loss: 0.6470, Accuracy: 57.81%, Precision: 99.89%, Recall: 57.56%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6545, Average Validation Loss: 0.6457, Accuracy: 57.87%, Precision: 99.89%, Recall: 57.59%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6492, Average Validation Loss: 0.6446, Accuracy: 57.98%, Precision: 99.90%, Recall: 57.65%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6450, Average Validation Loss: 0.6432, Accuracy: 58.06%, Precision: 99.90%, Recall: 57.70%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6432, Average Validation Loss: 0.6421, Accuracy: 58.12%, Precision: 99.90%, Recall: 57.73%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6432, Average Validation Loss: 0.6410, Accuracy: 58.18%, Precision: 99.90%, Recall: 57.77%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6383, Average Validation Loss: 0.6397, Accuracy: 58.24%, Precision: 99.91%, Recall: 57.81%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6395, Average Validation Loss: 0.6385, Accuracy: 58.29%, Precision: 99.91%, Recall: 57.84%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6390, Average Validation Loss: 0.6374, Accuracy: 58.36%, Precision: 99.91%, Recall: 57.87%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6359, Average Validation Loss: 0.6361, Accuracy: 58.39%, Precision: 99.92%, Recall: 57.89%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6326, Average Validation Loss: 0.6346, Accuracy: 58.46%, Precision: 99.92%, Recall: 57.93%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6361, Average Validation Loss: 0.6335, Accuracy: 58.53%, Precision: 99.92%, Recall: 57.98%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6384, Average Validation Loss: 0.6322, Accuracy: 58.68%, Precision: 99.92%, Recall: 58.06%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6243, Average Validation Loss: 0.6310, Accuracy: 58.76%, Precision: 99.93%, Recall: 58.11%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6358, Average Validation Loss: 0.6300, Accuracy: 58.85%, Precision: 99.93%, Recall: 58.16%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6308, Average Validation Loss: 0.6286, Accuracy: 58.96%, Precision: 99.93%, Recall: 58.23%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6345, Average Validation Loss: 0.6273, Accuracy: 59.23%, Precision: 99.93%, Recall: 58.39%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6250, Average Validation Loss: 0.6262, Accuracy: 59.45%, Precision: 99.93%, Recall: 58.52%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6269, Average Validation Loss: 0.6249, Accuracy: 59.57%, Precision: 99.93%, Recall: 58.59%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6245, Average Validation Loss: 0.6236, Accuracy: 59.58%, Precision: 99.93%, Recall: 58.60%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6166, Average Validation Loss: 0.6225, Accuracy: 59.56%, Precision: 99.93%, Recall: 58.59%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6224, Average Validation Loss: 0.6214, Accuracy: 59.52%, Precision: 99.93%, Recall: 58.56%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6308, Average Validation Loss: 0.6202, Accuracy: 59.69%, Precision: 99.93%, Recall: 58.66%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6219, Average Validation Loss: 0.6191, Accuracy: 59.91%, Precision: 99.94%, Recall: 58.80%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6239, Average Validation Loss: 0.6180, Accuracy: 60.30%, Precision: 99.94%, Recall: 59.03%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6243, Average Validation Loss: 0.6166, Accuracy: 60.82%, Precision: 99.94%, Recall: 59.35%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6194, Average Validation Loss: 0.6154, Accuracy: 61.20%, Precision: 99.93%, Recall: 59.59%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6100, Average Validation Loss: 0.6139, Accuracy: 61.52%, Precision: 99.93%, Recall: 59.78%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6088, Average Validation Loss: 0.6129, Accuracy: 61.51%, Precision: 99.95%, Recall: 59.78%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6184, Average Validation Loss: 0.6115, Accuracy: 61.52%, Precision: 99.95%, Recall: 59.78%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6112, Average Validation Loss: 0.6106, Accuracy: 61.53%, Precision: 99.95%, Recall: 59.79%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6114, Average Validation Loss: 0.6093, Accuracy: 61.74%, Precision: 99.95%, Recall: 59.92%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6071, Average Validation Loss: 0.6083, Accuracy: 61.82%, Precision: 99.96%, Recall: 59.97%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6120, Average Validation Loss: 0.6070, Accuracy: 62.19%, Precision: 99.96%, Recall: 60.20%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6153, Average Validation Loss: 0.6058, Accuracy: 62.64%, Precision: 99.95%, Recall: 60.50%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6066, Average Validation Loss: 0.6046, Accuracy: 63.22%, Precision: 99.95%, Recall: 60.87%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6111, Average Validation Loss: 0.6034, Accuracy: 63.70%, Precision: 99.94%, Recall: 61.18%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6029, Average Validation Loss: 0.6020, Accuracy: 63.96%, Precision: 99.95%, Recall: 61.35%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5998, Average Validation Loss: 0.6010, Accuracy: 64.16%, Precision: 99.96%, Recall: 61.48%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6022, Average Validation Loss: 0.5997, Accuracy: 64.22%, Precision: 99.96%, Recall: 61.52%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6014, Average Validation Loss: 0.5986, Accuracy: 64.30%, Precision: 99.96%, Recall: 61.57%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6052, Average Validation Loss: 0.5975, Accuracy: 64.66%, Precision: 99.96%, Recall: 61.82%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6007, Average Validation Loss: 0.5960, Accuracy: 64.92%, Precision: 99.96%, Recall: 61.99%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.6042, Average Validation Loss: 0.5952, Accuracy: 65.61%, Precision: 99.96%, Recall: 62.46%, F1: 0.77\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5914, Average Validation Loss: 0.5940, Accuracy: 65.89%, Precision: 99.96%, Recall: 62.65%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5908, Average Validation Loss: 0.5926, Accuracy: 65.89%, Precision: 99.96%, Recall: 62.65%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5964, Average Validation Loss: 0.5916, Accuracy: 66.22%, Precision: 99.96%, Recall: 62.88%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5974, Average Validation Loss: 0.5906, Accuracy: 66.52%, Precision: 99.96%, Recall: 63.08%, F1: 0.77\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5950, Average Validation Loss: 0.5893, Accuracy: 66.96%, Precision: 99.96%, Recall: 63.39%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5953, Average Validation Loss: 0.5883, Accuracy: 67.63%, Precision: 99.96%, Recall: 63.86%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5889, Average Validation Loss: 0.5869, Accuracy: 67.96%, Precision: 99.96%, Recall: 64.10%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5875, Average Validation Loss: 0.5857, Accuracy: 68.19%, Precision: 99.96%, Recall: 64.27%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5919, Average Validation Loss: 0.5844, Accuracy: 69.01%, Precision: 99.96%, Recall: 64.87%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5906, Average Validation Loss: 0.5833, Accuracy: 69.78%, Precision: 99.96%, Recall: 65.43%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5869, Average Validation Loss: 0.5823, Accuracy: 70.40%, Precision: 99.96%, Recall: 65.90%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5802, Average Validation Loss: 0.5809, Accuracy: 70.72%, Precision: 99.96%, Recall: 66.15%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5798, Average Validation Loss: 0.5798, Accuracy: 70.73%, Precision: 99.96%, Recall: 66.16%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5825, Average Validation Loss: 0.5786, Accuracy: 70.58%, Precision: 99.96%, Recall: 66.04%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5766, Average Validation Loss: 0.5774, Accuracy: 70.47%, Precision: 99.96%, Recall: 65.96%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5842, Average Validation Loss: 0.5765, Accuracy: 70.60%, Precision: 99.96%, Recall: 66.05%, F1: 0.80\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5722, Average Validation Loss: 0.5752, Accuracy: 70.26%, Precision: 99.96%, Recall: 65.80%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5803, Average Validation Loss: 0.5741, Accuracy: 70.00%, Precision: 99.96%, Recall: 65.60%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5770, Average Validation Loss: 0.5732, Accuracy: 70.22%, Precision: 99.96%, Recall: 65.77%, F1: 0.79\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5731, Average Validation Loss: 0.5722, Accuracy: 70.52%, Precision: 99.96%, Recall: 65.99%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5705, Average Validation Loss: 0.5710, Accuracy: 70.51%, Precision: 99.96%, Recall: 65.98%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5743, Average Validation Loss: 0.5698, Accuracy: 70.54%, Precision: 99.96%, Recall: 66.01%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5734, Average Validation Loss: 0.5689, Accuracy: 71.02%, Precision: 99.96%, Recall: 66.37%, F1: 0.80\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5735, Average Validation Loss: 0.5678, Accuracy: 71.47%, Precision: 99.96%, Recall: 66.73%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5718, Average Validation Loss: 0.5666, Accuracy: 71.92%, Precision: 99.96%, Recall: 67.08%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.5687, Average Validation Loss: 0.5652, Accuracy: 72.49%, Precision: 99.96%, Recall: 67.53%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5692, Average Validation Loss: 0.5640, Accuracy: 72.98%, Precision: 99.96%, Recall: 67.93%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5717, Average Validation Loss: 0.5630, Accuracy: 73.70%, Precision: 99.96%, Recall: 68.51%, F1: 0.81\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5656, Average Validation Loss: 0.5619, Accuracy: 74.28%, Precision: 99.96%, Recall: 68.99%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5641, Average Validation Loss: 0.5606, Accuracy: 74.62%, Precision: 99.96%, Recall: 69.27%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5550, Average Validation Loss: 0.5597, Accuracy: 74.55%, Precision: 99.96%, Recall: 69.21%, F1: 0.82\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5542, Average Validation Loss: 0.5586, Accuracy: 74.14%, Precision: 99.98%, Recall: 68.87%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5619, Average Validation Loss: 0.5576, Accuracy: 74.07%, Precision: 99.98%, Recall: 68.81%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5534, Average Validation Loss: 0.5566, Accuracy: 73.88%, Precision: 99.98%, Recall: 68.65%, F1: 0.81\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5644, Average Validation Loss: 0.5551, Accuracy: 74.15%, Precision: 99.98%, Recall: 68.87%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5503, Average Validation Loss: 0.5543, Accuracy: 74.41%, Precision: 99.99%, Recall: 69.09%, F1: 0.82\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5552, Average Validation Loss: 0.5532, Accuracy: 74.81%, Precision: 99.99%, Recall: 69.43%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5595, Average Validation Loss: 0.5519, Accuracy: 75.41%, Precision: 99.99%, Recall: 69.94%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5514, Average Validation Loss: 0.5510, Accuracy: 75.77%, Precision: 99.99%, Recall: 70.24%, F1: 0.83\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5496, Average Validation Loss: 0.5500, Accuracy: 75.89%, Precision: 99.99%, Recall: 70.34%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.5569, Average Validation Loss: 0.5487, Accuracy: 76.25%, Precision: 99.99%, Recall: 70.67%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.5473, Average Validation Loss: 0.5478, Accuracy: 76.45%, Precision: 99.99%, Recall: 70.84%, F1: 0.83\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5595, Average Validation Loss: 0.5466, Accuracy: 77.12%, Precision: 99.99%, Recall: 71.43%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.5463, Average Validation Loss: 0.5456, Accuracy: 77.52%, Precision: 99.98%, Recall: 71.79%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5465, Average Validation Loss: 0.5444, Accuracy: 77.67%, Precision: 99.98%, Recall: 71.93%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5519, Average Validation Loss: 0.5434, Accuracy: 77.96%, Precision: 99.98%, Recall: 72.19%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5471, Average Validation Loss: 0.5422, Accuracy: 78.41%, Precision: 99.98%, Recall: 72.60%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5460, Average Validation Loss: 0.5412, Accuracy: 78.81%, Precision: 99.98%, Recall: 72.97%, F1: 0.84\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5406, Average Validation Loss: 0.5401, Accuracy: 78.72%, Precision: 99.98%, Recall: 72.89%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5393, Average Validation Loss: 0.5388, Accuracy: 78.54%, Precision: 99.98%, Recall: 72.73%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5463, Average Validation Loss: 0.5380, Accuracy: 78.55%, Precision: 99.98%, Recall: 72.73%, F1: 0.84\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1617, Average Validation Loss: 0.5376, Accuracy: 78.65%, Precision: 99.98%, Recall: 72.82%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5338, Average Validation Loss: 0.5377, Accuracy: 78.68%, Precision: 99.98%, Recall: 72.85%, F1: 0.84\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5418, Average Validation Loss: 0.5375, Accuracy: 78.71%, Precision: 99.98%, Recall: 72.88%, F1: 0.84\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.5421, Average Validation Loss: 0.5370, Accuracy: 78.86%, Precision: 99.98%, Recall: 73.02%, F1: 0.84\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 1, Average Training Loss: 0.5404, Average Validation Loss: 0.5362, Accuracy: 79.00%, Precision: 99.98%, Recall: 73.15%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5420, Average Validation Loss: 0.5359, Accuracy: 79.19%, Precision: 99.98%, Recall: 73.33%, F1: 0.85\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5395, Average Validation Loss: 0.5347, Accuracy: 79.37%, Precision: 99.98%, Recall: 73.50%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5328, Average Validation Loss: 0.5339, Accuracy: 79.44%, Precision: 99.98%, Recall: 73.56%, F1: 0.85\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5272, Average Validation Loss: 0.5327, Accuracy: 79.32%, Precision: 99.98%, Recall: 73.45%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5337, Average Validation Loss: 0.5314, Accuracy: 79.59%, Precision: 99.98%, Recall: 73.70%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5340, Average Validation Loss: 0.5301, Accuracy: 80.03%, Precision: 99.97%, Recall: 74.13%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5363, Average Validation Loss: 0.5287, Accuracy: 80.39%, Precision: 99.97%, Recall: 74.47%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5324, Average Validation Loss: 0.5273, Accuracy: 81.23%, Precision: 99.97%, Recall: 75.30%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5328, Average Validation Loss: 0.5261, Accuracy: 81.83%, Precision: 99.97%, Recall: 75.90%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5203, Average Validation Loss: 0.5245, Accuracy: 81.60%, Precision: 99.97%, Recall: 75.67%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5290, Average Validation Loss: 0.5234, Accuracy: 81.20%, Precision: 99.97%, Recall: 75.27%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5290, Average Validation Loss: 0.5221, Accuracy: 81.41%, Precision: 99.97%, Recall: 75.48%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5250, Average Validation Loss: 0.5209, Accuracy: 81.48%, Precision: 99.97%, Recall: 75.54%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5226, Average Validation Loss: 0.5193, Accuracy: 81.53%, Precision: 99.97%, Recall: 75.60%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5152, Average Validation Loss: 0.5179, Accuracy: 81.49%, Precision: 99.97%, Recall: 75.56%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5229, Average Validation Loss: 0.5168, Accuracy: 81.50%, Precision: 99.97%, Recall: 75.57%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5200, Average Validation Loss: 0.5152, Accuracy: 81.87%, Precision: 99.97%, Recall: 75.94%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5160, Average Validation Loss: 0.5139, Accuracy: 82.43%, Precision: 99.97%, Recall: 76.51%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.5129, Average Validation Loss: 0.5126, Accuracy: 82.64%, Precision: 99.97%, Recall: 76.73%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.5078, Average Validation Loss: 0.5112, Accuracy: 82.48%, Precision: 99.97%, Recall: 76.56%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.5168, Average Validation Loss: 0.5101, Accuracy: 82.77%, Precision: 99.97%, Recall: 76.86%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.5150, Average Validation Loss: 0.5085, Accuracy: 83.13%, Precision: 99.97%, Recall: 77.23%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.5079, Average Validation Loss: 0.5072, Accuracy: 83.42%, Precision: 99.97%, Recall: 77.53%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.5106, Average Validation Loss: 0.5059, Accuracy: 83.77%, Precision: 99.97%, Recall: 77.91%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.5128, Average Validation Loss: 0.5044, Accuracy: 84.33%, Precision: 99.97%, Recall: 78.51%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.5084, Average Validation Loss: 0.5027, Accuracy: 84.48%, Precision: 99.97%, Recall: 78.67%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.5048, Average Validation Loss: 0.5014, Accuracy: 84.56%, Precision: 99.97%, Recall: 78.75%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.5051, Average Validation Loss: 0.5000, Accuracy: 84.51%, Precision: 99.97%, Recall: 78.70%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.5074, Average Validation Loss: 0.4989, Accuracy: 84.67%, Precision: 99.96%, Recall: 78.88%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.5054, Average Validation Loss: 0.4977, Accuracy: 85.23%, Precision: 99.96%, Recall: 79.50%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4934, Average Validation Loss: 0.4961, Accuracy: 85.25%, Precision: 99.96%, Recall: 79.52%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4959, Average Validation Loss: 0.4946, Accuracy: 85.10%, Precision: 99.96%, Recall: 79.35%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.5036, Average Validation Loss: 0.4934, Accuracy: 85.46%, Precision: 99.96%, Recall: 79.74%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4971, Average Validation Loss: 0.4918, Accuracy: 85.78%, Precision: 99.96%, Recall: 80.11%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4955, Average Validation Loss: 0.4906, Accuracy: 85.92%, Precision: 99.96%, Recall: 80.27%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4874, Average Validation Loss: 0.4892, Accuracy: 85.95%, Precision: 99.96%, Recall: 80.29%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4942, Average Validation Loss: 0.4878, Accuracy: 85.75%, Precision: 99.96%, Recall: 80.07%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4898, Average Validation Loss: 0.4865, Accuracy: 85.69%, Precision: 99.96%, Recall: 80.00%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4923, Average Validation Loss: 0.4850, Accuracy: 85.83%, Precision: 99.96%, Recall: 80.16%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4894, Average Validation Loss: 0.4836, Accuracy: 86.28%, Precision: 99.95%, Recall: 80.68%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4933, Average Validation Loss: 0.4825, Accuracy: 86.77%, Precision: 99.95%, Recall: 81.24%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4799, Average Validation Loss: 0.4811, Accuracy: 86.58%, Precision: 99.95%, Recall: 81.02%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4836, Average Validation Loss: 0.4795, Accuracy: 86.65%, Precision: 99.95%, Recall: 81.10%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4886, Average Validation Loss: 0.4781, Accuracy: 87.03%, Precision: 99.94%, Recall: 81.54%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4775, Average Validation Loss: 0.4768, Accuracy: 87.28%, Precision: 99.93%, Recall: 81.84%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4764, Average Validation Loss: 0.4753, Accuracy: 87.27%, Precision: 99.94%, Recall: 81.83%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4807, Average Validation Loss: 0.4740, Accuracy: 87.27%, Precision: 99.94%, Recall: 81.83%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4711, Average Validation Loss: 0.4725, Accuracy: 87.27%, Precision: 99.94%, Recall: 81.82%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4759, Average Validation Loss: 0.4714, Accuracy: 87.47%, Precision: 99.93%, Recall: 82.07%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4781, Average Validation Loss: 0.4695, Accuracy: 87.70%, Precision: 99.93%, Recall: 82.34%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.4683, Average Validation Loss: 0.4682, Accuracy: 88.01%, Precision: 99.93%, Recall: 82.71%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4731, Average Validation Loss: 0.4667, Accuracy: 88.29%, Precision: 99.92%, Recall: 83.04%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4703, Average Validation Loss: 0.4655, Accuracy: 88.57%, Precision: 99.92%, Recall: 83.39%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4731, Average Validation Loss: 0.4639, Accuracy: 89.02%, Precision: 99.92%, Recall: 83.93%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4660, Average Validation Loss: 0.4626, Accuracy: 89.09%, Precision: 99.92%, Recall: 84.03%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4675, Average Validation Loss: 0.4608, Accuracy: 89.21%, Precision: 99.92%, Recall: 84.18%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4624, Average Validation Loss: 0.4599, Accuracy: 89.19%, Precision: 99.92%, Recall: 84.15%, F1: 0.91\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.4713, Average Validation Loss: 0.4585, Accuracy: 89.08%, Precision: 99.92%, Recall: 84.02%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4643, Average Validation Loss: 0.4571, Accuracy: 89.42%, Precision: 99.92%, Recall: 84.43%, F1: 0.92\n","Epoch 1, Average Training Loss: 0.4597, Average Validation Loss: 0.4557, Accuracy: 89.37%, Precision: 99.92%, Recall: 84.37%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4593, Average Validation Loss: 0.4542, Accuracy: 89.38%, Precision: 99.92%, Recall: 84.38%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4600, Average Validation Loss: 0.4529, Accuracy: 89.33%, Precision: 99.92%, Recall: 84.33%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4531, Average Validation Loss: 0.4515, Accuracy: 89.37%, Precision: 99.92%, Recall: 84.37%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4572, Average Validation Loss: 0.4502, Accuracy: 89.61%, Precision: 99.92%, Recall: 84.68%, F1: 0.92\n","Epoch 1, Average Training Loss: 0.4541, Average Validation Loss: 0.4488, Accuracy: 89.41%, Precision: 99.92%, Recall: 84.42%, F1: 0.92\n","Epoch 1, Average Training Loss: 0.4540, Average Validation Loss: 0.4474, Accuracy: 88.98%, Precision: 99.92%, Recall: 83.89%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4520, Average Validation Loss: 0.4461, Accuracy: 88.73%, Precision: 99.93%, Recall: 83.58%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4502, Average Validation Loss: 0.4449, Accuracy: 88.74%, Precision: 99.93%, Recall: 83.59%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4507, Average Validation Loss: 0.4432, Accuracy: 88.86%, Precision: 99.93%, Recall: 83.74%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4513, Average Validation Loss: 0.4420, Accuracy: 89.01%, Precision: 99.93%, Recall: 83.92%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4513, Average Validation Loss: 0.4405, Accuracy: 89.06%, Precision: 99.93%, Recall: 83.98%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4420, Average Validation Loss: 0.4390, Accuracy: 89.36%, Precision: 99.93%, Recall: 84.36%, F1: 0.91\n","Epoch 1, Average Training Loss: 0.4443, Average Validation Loss: 0.4377, Accuracy: 89.49%, Precision: 99.93%, Recall: 84.52%, F1: 0.92\n","Epoch 1, Average Training Loss: 0.4455, Average Validation Loss: 0.4362, Accuracy: 89.61%, Precision: 99.93%, Recall: 84.66%, F1: 0.92\n","Epoch 1, Average Training Loss: 0.4458, Average Validation Loss: 0.4348, Accuracy: 90.01%, Precision: 99.92%, Recall: 85.18%, F1: 0.92\n","Epoch 1, Average Training Loss: 0.4474, Average Validation Loss: 0.4335, Accuracy: 90.75%, Precision: 99.90%, Recall: 86.14%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4415, Average Validation Loss: 0.4320, Accuracy: 91.26%, Precision: 99.87%, Recall: 86.83%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4349, Average Validation Loss: 0.4305, Accuracy: 91.28%, Precision: 99.87%, Recall: 86.86%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4382, Average Validation Loss: 0.4289, Accuracy: 91.59%, Precision: 99.87%, Recall: 87.26%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4336, Average Validation Loss: 0.4275, Accuracy: 91.51%, Precision: 99.87%, Recall: 87.16%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4335, Average Validation Loss: 0.4261, Accuracy: 91.43%, Precision: 99.87%, Recall: 87.06%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4289, Average Validation Loss: 0.4248, Accuracy: 91.19%, Precision: 99.87%, Recall: 86.73%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4320, Average Validation Loss: 0.4235, Accuracy: 91.22%, Precision: 99.87%, Recall: 86.77%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4315, Average Validation Loss: 0.4221, Accuracy: 91.18%, Precision: 99.88%, Recall: 86.72%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4230, Average Validation Loss: 0.4207, Accuracy: 91.09%, Precision: 99.89%, Recall: 86.60%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4304, Average Validation Loss: 0.4192, Accuracy: 91.20%, Precision: 99.88%, Recall: 86.73%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4259, Average Validation Loss: 0.4177, Accuracy: 91.50%, Precision: 99.87%, Recall: 87.14%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4254, Average Validation Loss: 0.4163, Accuracy: 91.48%, Precision: 99.87%, Recall: 87.12%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4204, Average Validation Loss: 0.4150, Accuracy: 91.49%, Precision: 99.87%, Recall: 87.13%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4202, Average Validation Loss: 0.4136, Accuracy: 91.44%, Precision: 99.87%, Recall: 87.07%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4119, Average Validation Loss: 0.4126, Accuracy: 91.18%, Precision: 99.88%, Recall: 86.72%, F1: 0.93\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.4224, Average Validation Loss: 0.4106, Accuracy: 91.23%, Precision: 99.88%, Recall: 86.77%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4171, Average Validation Loss: 0.4094, Accuracy: 91.50%, Precision: 99.86%, Recall: 87.15%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4109, Average Validation Loss: 0.4075, Accuracy: 91.76%, Precision: 99.86%, Recall: 87.50%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4119, Average Validation Loss: 0.4066, Accuracy: 91.91%, Precision: 99.86%, Recall: 87.70%, F1: 0.93\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.4159, Average Validation Loss: 0.4051, Accuracy: 91.93%, Precision: 99.86%, Recall: 87.73%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4090, Average Validation Loss: 0.4035, Accuracy: 91.95%, Precision: 99.86%, Recall: 87.75%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4047, Average Validation Loss: 0.4020, Accuracy: 91.85%, Precision: 99.86%, Recall: 87.62%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4054, Average Validation Loss: 0.4007, Accuracy: 91.50%, Precision: 99.86%, Recall: 87.15%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4115, Average Validation Loss: 0.3992, Accuracy: 91.72%, Precision: 99.86%, Recall: 87.44%, F1: 0.93\n","Epoch 1, Average Training Loss: 0.4173, Average Validation Loss: 0.3976, Accuracy: 92.35%, Precision: 99.86%, Recall: 88.30%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.4049, Average Validation Loss: 0.3960, Accuracy: 92.59%, Precision: 99.86%, Recall: 88.63%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.4009, Average Validation Loss: 0.3946, Accuracy: 92.82%, Precision: 99.86%, Recall: 88.94%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.4003, Average Validation Loss: 0.3933, Accuracy: 93.10%, Precision: 99.86%, Recall: 89.33%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3994, Average Validation Loss: 0.3918, Accuracy: 93.35%, Precision: 99.85%, Recall: 89.69%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3947, Average Validation Loss: 0.3904, Accuracy: 93.13%, Precision: 99.85%, Recall: 89.37%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.4021, Average Validation Loss: 0.3890, Accuracy: 92.86%, Precision: 99.86%, Recall: 89.00%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.4007, Average Validation Loss: 0.3876, Accuracy: 92.78%, Precision: 99.86%, Recall: 88.88%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.4003, Average Validation Loss: 0.3859, Accuracy: 92.85%, Precision: 99.86%, Recall: 88.98%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3940, Average Validation Loss: 0.3851, Accuracy: 92.64%, Precision: 99.86%, Recall: 88.69%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.3838, Average Validation Loss: 0.3836, Accuracy: 92.25%, Precision: 99.86%, Recall: 88.16%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3952, Average Validation Loss: 0.3819, Accuracy: 92.37%, Precision: 99.86%, Recall: 88.32%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3917, Average Validation Loss: 0.3805, Accuracy: 92.54%, Precision: 99.86%, Recall: 88.56%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3857, Average Validation Loss: 0.3789, Accuracy: 92.85%, Precision: 99.86%, Recall: 88.98%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3867, Average Validation Loss: 0.3775, Accuracy: 93.03%, Precision: 99.86%, Recall: 89.23%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3773, Average Validation Loss: 0.3758, Accuracy: 93.13%, Precision: 99.86%, Recall: 89.38%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3886, Average Validation Loss: 0.3745, Accuracy: 93.03%, Precision: 99.86%, Recall: 89.24%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3933, Average Validation Loss: 0.3729, Accuracy: 93.35%, Precision: 99.86%, Recall: 89.68%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3849, Average Validation Loss: 0.3715, Accuracy: 93.63%, Precision: 99.84%, Recall: 90.09%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3794, Average Validation Loss: 0.3702, Accuracy: 93.56%, Precision: 99.85%, Recall: 89.98%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3829, Average Validation Loss: 0.3686, Accuracy: 93.80%, Precision: 99.84%, Recall: 90.34%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3767, Average Validation Loss: 0.3670, Accuracy: 93.95%, Precision: 99.83%, Recall: 90.56%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3749, Average Validation Loss: 0.3658, Accuracy: 93.80%, Precision: 99.84%, Recall: 90.33%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3760, Average Validation Loss: 0.3643, Accuracy: 93.62%, Precision: 99.85%, Recall: 90.07%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3713, Average Validation Loss: 0.3629, Accuracy: 93.57%, Precision: 99.85%, Recall: 90.00%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3722, Average Validation Loss: 0.3614, Accuracy: 93.18%, Precision: 99.86%, Recall: 89.45%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3822, Average Validation Loss: 0.3598, Accuracy: 93.39%, Precision: 99.86%, Recall: 89.74%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3695, Average Validation Loss: 0.3583, Accuracy: 93.85%, Precision: 99.83%, Recall: 90.42%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3693, Average Validation Loss: 0.3569, Accuracy: 93.93%, Precision: 99.83%, Recall: 90.53%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3623, Average Validation Loss: 0.3553, Accuracy: 93.88%, Precision: 99.83%, Recall: 90.46%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3670, Average Validation Loss: 0.3540, Accuracy: 93.84%, Precision: 99.85%, Recall: 90.39%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3619, Average Validation Loss: 0.3522, Accuracy: 93.74%, Precision: 99.85%, Recall: 90.25%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3639, Average Validation Loss: 0.3508, Accuracy: 93.75%, Precision: 99.85%, Recall: 90.26%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3549, Average Validation Loss: 0.3494, Accuracy: 93.72%, Precision: 99.85%, Recall: 90.21%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3583, Average Validation Loss: 0.3476, Accuracy: 93.56%, Precision: 99.85%, Recall: 89.98%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3615, Average Validation Loss: 0.3468, Accuracy: 93.29%, Precision: 99.86%, Recall: 89.61%, F1: 0.94\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.3543, Average Validation Loss: 0.3448, Accuracy: 93.35%, Precision: 99.86%, Recall: 89.68%, F1: 0.94\n","Epoch 1, Average Training Loss: 0.3590, Average Validation Loss: 0.3440, Accuracy: 93.42%, Precision: 99.85%, Recall: 89.78%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.3605, Average Validation Loss: 0.3420, Accuracy: 93.83%, Precision: 99.85%, Recall: 90.36%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3524, Average Validation Loss: 0.3404, Accuracy: 93.87%, Precision: 99.85%, Recall: 90.43%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3497, Average Validation Loss: 0.3389, Accuracy: 93.88%, Precision: 99.86%, Recall: 90.44%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3507, Average Validation Loss: 0.3372, Accuracy: 93.91%, Precision: 99.85%, Recall: 90.48%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.3537, Average Validation Loss: 0.3358, Accuracy: 93.85%, Precision: 99.86%, Recall: 90.40%, F1: 0.95\n","Epoch 1, Average Training Loss: 0.1089, Average Validation Loss: 0.3354, Accuracy: 93.89%, Precision: 99.86%, Recall: 90.45%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.3485, Average Validation Loss: 0.3353, Accuracy: 93.90%, Precision: 99.86%, Recall: 90.47%, F1: 0.95\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.3499, Average Validation Loss: 0.3347, Accuracy: 93.91%, Precision: 99.86%, Recall: 90.47%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3429, Average Validation Loss: 0.3341, Accuracy: 93.86%, Precision: 99.86%, Recall: 90.41%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.3469, Average Validation Loss: 0.3335, Accuracy: 93.81%, Precision: 99.86%, Recall: 90.33%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3372, Average Validation Loss: 0.3326, Accuracy: 93.74%, Precision: 99.86%, Recall: 90.23%, F1: 0.95\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.3368, Average Validation Loss: 0.3316, Accuracy: 93.63%, Precision: 99.86%, Recall: 90.08%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3365, Average Validation Loss: 0.3302, Accuracy: 93.50%, Precision: 99.87%, Recall: 89.89%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3404, Average Validation Loss: 0.3284, Accuracy: 93.46%, Precision: 99.87%, Recall: 89.83%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3391, Average Validation Loss: 0.3268, Accuracy: 93.64%, Precision: 99.87%, Recall: 90.09%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3326, Average Validation Loss: 0.3246, Accuracy: 93.64%, Precision: 99.87%, Recall: 90.09%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3424, Average Validation Loss: 0.3227, Accuracy: 93.39%, Precision: 99.87%, Recall: 89.73%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3355, Average Validation Loss: 0.3209, Accuracy: 93.24%, Precision: 99.88%, Recall: 89.52%, F1: 0.94\n","Epoch 2, Average Training Loss: 0.3284, Average Validation Loss: 0.3189, Accuracy: 93.30%, Precision: 99.87%, Recall: 89.60%, F1: 0.94\n","Epoch 2, Average Training Loss: 0.3328, Average Validation Loss: 0.3170, Accuracy: 93.45%, Precision: 99.87%, Recall: 89.82%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3251, Average Validation Loss: 0.3149, Accuracy: 93.46%, Precision: 99.87%, Recall: 89.82%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3221, Average Validation Loss: 0.3127, Accuracy: 93.56%, Precision: 99.87%, Recall: 89.97%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3194, Average Validation Loss: 0.3106, Accuracy: 93.60%, Precision: 99.87%, Recall: 90.03%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3206, Average Validation Loss: 0.3087, Accuracy: 93.55%, Precision: 99.88%, Recall: 89.94%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3135, Average Validation Loss: 0.3066, Accuracy: 93.53%, Precision: 99.88%, Recall: 89.92%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3185, Average Validation Loss: 0.3046, Accuracy: 93.46%, Precision: 99.88%, Recall: 89.83%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3179, Average Validation Loss: 0.3028, Accuracy: 93.33%, Precision: 99.90%, Recall: 89.63%, F1: 0.94\n","Epoch 2, Average Training Loss: 0.3197, Average Validation Loss: 0.3003, Accuracy: 93.63%, Precision: 99.88%, Recall: 90.06%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3100, Average Validation Loss: 0.2976, Accuracy: 93.83%, Precision: 99.88%, Recall: 90.35%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3076, Average Validation Loss: 0.2958, Accuracy: 93.78%, Precision: 99.88%, Recall: 90.28%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3091, Average Validation Loss: 0.2938, Accuracy: 93.80%, Precision: 99.88%, Recall: 90.31%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3051, Average Validation Loss: 0.2916, Accuracy: 93.43%, Precision: 99.91%, Recall: 89.75%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3061, Average Validation Loss: 0.2895, Accuracy: 93.37%, Precision: 99.92%, Recall: 89.67%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3072, Average Validation Loss: 0.2871, Accuracy: 93.67%, Precision: 99.90%, Recall: 90.11%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.3008, Average Validation Loss: 0.2845, Accuracy: 93.91%, Precision: 99.90%, Recall: 90.44%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2966, Average Validation Loss: 0.2822, Accuracy: 94.18%, Precision: 99.90%, Recall: 90.84%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2984, Average Validation Loss: 0.2794, Accuracy: 94.27%, Precision: 99.90%, Recall: 90.96%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2945, Average Validation Loss: 0.2776, Accuracy: 94.16%, Precision: 99.90%, Recall: 90.80%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2992, Average Validation Loss: 0.2750, Accuracy: 94.30%, Precision: 99.90%, Recall: 91.00%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2827, Average Validation Loss: 0.2727, Accuracy: 94.41%, Precision: 99.90%, Recall: 91.16%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2865, Average Validation Loss: 0.2702, Accuracy: 94.33%, Precision: 99.90%, Recall: 91.05%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2876, Average Validation Loss: 0.2680, Accuracy: 94.22%, Precision: 99.91%, Recall: 90.88%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2866, Average Validation Loss: 0.2654, Accuracy: 94.50%, Precision: 99.90%, Recall: 91.30%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2852, Average Validation Loss: 0.2628, Accuracy: 94.58%, Precision: 99.91%, Recall: 91.41%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2807, Average Validation Loss: 0.2606, Accuracy: 94.58%, Precision: 99.91%, Recall: 91.42%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2745, Average Validation Loss: 0.2583, Accuracy: 94.42%, Precision: 99.91%, Recall: 91.18%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2749, Average Validation Loss: 0.2564, Accuracy: 93.90%, Precision: 99.93%, Recall: 90.41%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2847, Average Validation Loss: 0.2542, Accuracy: 93.72%, Precision: 99.93%, Recall: 90.16%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2748, Average Validation Loss: 0.2518, Accuracy: 93.84%, Precision: 99.93%, Recall: 90.33%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2676, Average Validation Loss: 0.2497, Accuracy: 93.73%, Precision: 99.93%, Recall: 90.17%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2663, Average Validation Loss: 0.2475, Accuracy: 93.72%, Precision: 99.93%, Recall: 90.16%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2628, Average Validation Loss: 0.2451, Accuracy: 93.58%, Precision: 99.93%, Recall: 89.96%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2600, Average Validation Loss: 0.2426, Accuracy: 93.61%, Precision: 99.94%, Recall: 90.00%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2604, Average Validation Loss: 0.2403, Accuracy: 93.62%, Precision: 99.94%, Recall: 90.00%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2559, Average Validation Loss: 0.2372, Accuracy: 93.96%, Precision: 99.94%, Recall: 90.50%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2548, Average Validation Loss: 0.2351, Accuracy: 94.07%, Precision: 99.94%, Recall: 90.65%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2539, Average Validation Loss: 0.2321, Accuracy: 94.22%, Precision: 99.94%, Recall: 90.86%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2537, Average Validation Loss: 0.2295, Accuracy: 94.45%, Precision: 99.94%, Recall: 91.20%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2422, Average Validation Loss: 0.2267, Accuracy: 94.72%, Precision: 99.94%, Recall: 91.60%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2510, Average Validation Loss: 0.2242, Accuracy: 94.68%, Precision: 99.95%, Recall: 91.53%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2384, Average Validation Loss: 0.2217, Accuracy: 94.68%, Precision: 99.95%, Recall: 91.53%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2376, Average Validation Loss: 0.2193, Accuracy: 94.72%, Precision: 99.95%, Recall: 91.58%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2368, Average Validation Loss: 0.2167, Accuracy: 94.96%, Precision: 99.95%, Recall: 91.94%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2398, Average Validation Loss: 0.2138, Accuracy: 95.30%, Precision: 99.95%, Recall: 92.44%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2259, Average Validation Loss: 0.2115, Accuracy: 95.22%, Precision: 99.96%, Recall: 92.33%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2274, Average Validation Loss: 0.2098, Accuracy: 95.01%, Precision: 99.96%, Recall: 92.00%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2299, Average Validation Loss: 0.2077, Accuracy: 94.87%, Precision: 99.97%, Recall: 91.79%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2246, Average Validation Loss: 0.2062, Accuracy: 94.58%, Precision: 99.97%, Recall: 91.37%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2165, Average Validation Loss: 0.2045, Accuracy: 94.33%, Precision: 99.97%, Recall: 91.01%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2187, Average Validation Loss: 0.2020, Accuracy: 94.50%, Precision: 99.98%, Recall: 91.25%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2174, Average Validation Loss: 0.1987, Accuracy: 94.92%, Precision: 99.97%, Recall: 91.87%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2114, Average Validation Loss: 0.1966, Accuracy: 94.95%, Precision: 99.98%, Recall: 91.90%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2088, Average Validation Loss: 0.1944, Accuracy: 94.96%, Precision: 99.98%, Recall: 91.91%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2032, Average Validation Loss: 0.1912, Accuracy: 95.26%, Precision: 99.98%, Recall: 92.37%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2030, Average Validation Loss: 0.1888, Accuracy: 95.44%, Precision: 99.98%, Recall: 92.63%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2134, Average Validation Loss: 0.1852, Accuracy: 95.81%, Precision: 99.98%, Recall: 93.20%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2052, Average Validation Loss: 0.1825, Accuracy: 96.11%, Precision: 99.98%, Recall: 93.65%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1935, Average Validation Loss: 0.1810, Accuracy: 95.97%, Precision: 99.98%, Recall: 93.43%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1977, Average Validation Loss: 0.1793, Accuracy: 95.81%, Precision: 99.98%, Recall: 93.19%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.1821, Average Validation Loss: 0.1783, Accuracy: 95.72%, Precision: 99.99%, Recall: 93.05%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.1897, Average Validation Loss: 0.1750, Accuracy: 95.89%, Precision: 99.99%, Recall: 93.31%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1910, Average Validation Loss: 0.1734, Accuracy: 95.87%, Precision: 99.99%, Recall: 93.27%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1887, Average Validation Loss: 0.1710, Accuracy: 95.96%, Precision: 99.99%, Recall: 93.41%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1835, Average Validation Loss: 0.1688, Accuracy: 96.14%, Precision: 99.99%, Recall: 93.69%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1927, Average Validation Loss: 0.1659, Accuracy: 96.34%, Precision: 99.99%, Recall: 94.00%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1745, Average Validation Loss: 0.1637, Accuracy: 96.46%, Precision: 99.99%, Recall: 94.18%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1846, Average Validation Loss: 0.1619, Accuracy: 96.51%, Precision: 99.99%, Recall: 94.26%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1802, Average Validation Loss: 0.1597, Accuracy: 96.64%, Precision: 99.99%, Recall: 94.46%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1769, Average Validation Loss: 0.1567, Accuracy: 96.80%, Precision: 99.99%, Recall: 94.70%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1699, Average Validation Loss: 0.1542, Accuracy: 97.00%, Precision: 99.99%, Recall: 95.02%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1644, Average Validation Loss: 0.1526, Accuracy: 96.98%, Precision: 99.99%, Recall: 94.98%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1652, Average Validation Loss: 0.1504, Accuracy: 97.04%, Precision: 99.99%, Recall: 95.08%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1577, Average Validation Loss: 0.1485, Accuracy: 97.11%, Precision: 99.99%, Recall: 95.19%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1636, Average Validation Loss: 0.1468, Accuracy: 97.13%, Precision: 99.99%, Recall: 95.23%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1640, Average Validation Loss: 0.1459, Accuracy: 97.05%, Precision: 99.99%, Recall: 95.11%, F1: 0.97\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.1589, Average Validation Loss: 0.1443, Accuracy: 97.01%, Precision: 99.99%, Recall: 95.04%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1618, Average Validation Loss: 0.1426, Accuracy: 97.02%, Precision: 99.99%, Recall: 95.06%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1573, Average Validation Loss: 0.1408, Accuracy: 97.09%, Precision: 99.99%, Recall: 95.17%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1557, Average Validation Loss: 0.1378, Accuracy: 97.23%, Precision: 99.99%, Recall: 95.39%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1542, Average Validation Loss: 0.1339, Accuracy: 97.57%, Precision: 99.99%, Recall: 95.94%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1483, Average Validation Loss: 0.1320, Accuracy: 97.72%, Precision: 99.99%, Recall: 96.18%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1477, Average Validation Loss: 0.1296, Accuracy: 97.74%, Precision: 99.99%, Recall: 96.20%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1422, Average Validation Loss: 0.1281, Accuracy: 97.73%, Precision: 99.99%, Recall: 96.18%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1412, Average Validation Loss: 0.1266, Accuracy: 97.71%, Precision: 99.99%, Recall: 96.16%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1412, Average Validation Loss: 0.1255, Accuracy: 97.70%, Precision: 99.99%, Recall: 96.14%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1375, Average Validation Loss: 0.1243, Accuracy: 97.68%, Precision: 99.99%, Recall: 96.11%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1367, Average Validation Loss: 0.1228, Accuracy: 97.70%, Precision: 99.99%, Recall: 96.14%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1341, Average Validation Loss: 0.1207, Accuracy: 97.79%, Precision: 99.99%, Recall: 96.28%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1296, Average Validation Loss: 0.1192, Accuracy: 97.78%, Precision: 99.99%, Recall: 96.27%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1372, Average Validation Loss: 0.1168, Accuracy: 97.87%, Precision: 99.99%, Recall: 96.42%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1244, Average Validation Loss: 0.1145, Accuracy: 97.93%, Precision: 99.99%, Recall: 96.51%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1265, Average Validation Loss: 0.1125, Accuracy: 97.98%, Precision: 99.99%, Recall: 96.59%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1250, Average Validation Loss: 0.1115, Accuracy: 97.98%, Precision: 100.00%, Recall: 96.58%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.1273, Average Validation Loss: 0.1103, Accuracy: 97.98%, Precision: 100.00%, Recall: 96.58%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1173, Average Validation Loss: 0.1089, Accuracy: 98.03%, Precision: 100.00%, Recall: 96.67%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1208, Average Validation Loss: 0.1068, Accuracy: 98.07%, Precision: 100.00%, Recall: 96.74%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1207, Average Validation Loss: 0.1046, Accuracy: 98.12%, Precision: 100.00%, Recall: 96.81%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1134, Average Validation Loss: 0.1037, Accuracy: 98.13%, Precision: 100.00%, Recall: 96.83%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.1147, Average Validation Loss: 0.1014, Accuracy: 98.19%, Precision: 100.00%, Recall: 96.94%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1148, Average Validation Loss: 0.1008, Accuracy: 98.20%, Precision: 100.00%, Recall: 96.95%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.1178, Average Validation Loss: 0.0995, Accuracy: 98.17%, Precision: 100.00%, Recall: 96.90%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1070, Average Validation Loss: 0.0979, Accuracy: 98.19%, Precision: 100.00%, Recall: 96.93%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1081, Average Validation Loss: 0.0971, Accuracy: 98.20%, Precision: 100.00%, Recall: 96.94%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.1106, Average Validation Loss: 0.0957, Accuracy: 98.20%, Precision: 100.00%, Recall: 96.94%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1072, Average Validation Loss: 0.0940, Accuracy: 98.22%, Precision: 100.00%, Recall: 96.98%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1015, Average Validation Loss: 0.0921, Accuracy: 98.24%, Precision: 100.00%, Recall: 97.01%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.0999, Average Validation Loss: 0.0911, Accuracy: 98.25%, Precision: 100.00%, Recall: 97.03%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.0968, Average Validation Loss: 0.0903, Accuracy: 98.25%, Precision: 100.00%, Recall: 97.03%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.1063, Average Validation Loss: 0.0889, Accuracy: 98.27%, Precision: 100.00%, Recall: 97.06%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0989, Average Validation Loss: 0.0874, Accuracy: 98.30%, Precision: 100.00%, Recall: 97.11%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0958, Average Validation Loss: 0.0866, Accuracy: 98.30%, Precision: 100.00%, Recall: 97.11%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0979, Average Validation Loss: 0.0856, Accuracy: 98.31%, Precision: 100.00%, Recall: 97.13%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1015, Average Validation Loss: 0.0843, Accuracy: 98.33%, Precision: 100.00%, Recall: 97.17%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0935, Average Validation Loss: 0.0829, Accuracy: 98.37%, Precision: 100.00%, Recall: 97.22%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0913, Average Validation Loss: 0.0815, Accuracy: 98.38%, Precision: 100.00%, Recall: 97.25%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0861, Average Validation Loss: 0.0814, Accuracy: 98.36%, Precision: 100.00%, Recall: 97.22%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0896, Average Validation Loss: 0.0815, Accuracy: 98.34%, Precision: 100.00%, Recall: 97.18%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0816, Average Validation Loss: 0.0808, Accuracy: 98.34%, Precision: 100.00%, Recall: 97.18%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 2, Average Training Loss: 0.0853, Average Validation Loss: 0.0797, Accuracy: 98.34%, Precision: 100.00%, Recall: 97.18%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0880, Average Validation Loss: 0.0782, Accuracy: 98.38%, Precision: 100.00%, Recall: 97.24%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0879, Average Validation Loss: 0.0769, Accuracy: 98.40%, Precision: 100.00%, Recall: 97.28%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0871, Average Validation Loss: 0.0759, Accuracy: 98.41%, Precision: 100.00%, Recall: 97.29%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0859, Average Validation Loss: 0.0745, Accuracy: 98.43%, Precision: 100.00%, Recall: 97.33%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0781, Average Validation Loss: 0.0735, Accuracy: 98.43%, Precision: 100.00%, Recall: 97.33%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0886, Average Validation Loss: 0.0724, Accuracy: 98.44%, Precision: 100.00%, Recall: 97.34%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0783, Average Validation Loss: 0.0714, Accuracy: 98.44%, Precision: 100.00%, Recall: 97.34%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0755, Average Validation Loss: 0.0706, Accuracy: 98.46%, Precision: 100.00%, Recall: 97.37%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0830, Average Validation Loss: 0.0701, Accuracy: 98.47%, Precision: 100.00%, Recall: 97.40%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0730, Average Validation Loss: 0.0691, Accuracy: 98.47%, Precision: 100.00%, Recall: 97.39%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0753, Average Validation Loss: 0.0684, Accuracy: 98.47%, Precision: 100.00%, Recall: 97.39%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0784, Average Validation Loss: 0.0675, Accuracy: 98.48%, Precision: 100.00%, Recall: 97.41%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0694, Average Validation Loss: 0.0667, Accuracy: 98.49%, Precision: 100.00%, Recall: 97.43%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0773, Average Validation Loss: 0.0656, Accuracy: 98.51%, Precision: 100.00%, Recall: 97.46%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0210, Average Validation Loss: 0.0652, Accuracy: 98.51%, Precision: 100.00%, Recall: 97.46%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 16:33:43,305] Trial 6 finished with value: 0.07074965492293642 and parameters: {'vector_length': 128, 'num_blocks': 2, 'num_heads': 2, 'num_epochs': 3, 'dropout': 0.1, 'metadata_vector_length': 128, 'lr': 2.478348022388534e-06, 'warmup_steps': 90}. Best is trial 4 with value: 0.0019219860409361285.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 9, with 3,788,032 parameters\n","Num non-decayed parameter tensors: 13, with 5,122 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6998, Average Validation Loss: 0.6539, Accuracy: 85.63%, Precision: 83.05%, Recall: 91.04%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.5936, Average Validation Loss: 0.5211, Accuracy: 85.27%, Precision: 100.00%, Recall: 79.52%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.4562, Average Validation Loss: 0.3661, Accuracy: 95.00%, Precision: 99.97%, Recall: 91.98%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3095, Average Validation Loss: 0.2226, Accuracy: 99.13%, Precision: 99.55%, Recall: 98.95%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1698, Average Validation Loss: 0.1263, Accuracy: 99.28%, Precision: 99.64%, Recall: 99.11%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0988, Average Validation Loss: 0.0728, Accuracy: 99.43%, Precision: 99.76%, Recall: 99.25%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0559, Average Validation Loss: 0.0448, Accuracy: 99.56%, Precision: 99.78%, Recall: 99.45%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0398, Average Validation Loss: 0.0304, Accuracy: 99.65%, Precision: 99.78%, Recall: 99.60%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0305, Average Validation Loss: 0.0217, Accuracy: 99.74%, Precision: 99.87%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0200, Average Validation Loss: 0.0166, Accuracy: 99.72%, Precision: 99.96%, Recall: 99.55%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0118, Average Validation Loss: 0.0129, Accuracy: 99.78%, Precision: 99.99%, Recall: 99.63%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0127, Average Validation Loss: 0.0091, Accuracy: 99.84%, Precision: 99.96%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0085, Average Validation Loss: 0.0071, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0059, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0054, Average Validation Loss: 0.0050, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0072, Average Validation Loss: 0.0044, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0043, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0043, Average Validation Loss: 0.0040, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0036, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0039, Average Validation Loss: 0.0034, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0037, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 16:35:52,828] Trial 7 finished with value: 0.0036780581474886278 and parameters: {'vector_length': 256, 'num_blocks': 1, 'num_heads': 8, 'num_epochs': 5, 'dropout': 0.1, 'metadata_vector_length': 1024, 'lr': 0.0001734508801688089, 'warmup_steps': 70}. Best is trial 4 with value: 0.0019219860409361285.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 21, with 18,103,296 parameters\n","Num non-decayed parameter tensors: 37, with 28,418 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6880, Average Validation Loss: 0.6802, Accuracy: 57.24%, Precision: 99.96%, Recall: 57.22%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6294, Average Validation Loss: 0.5744, Accuracy: 66.25%, Precision: 99.93%, Recall: 62.90%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5717, Average Validation Loss: 0.5104, Accuracy: 74.86%, Precision: 99.92%, Recall: 69.49%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5263, Average Validation Loss: 0.5075, Accuracy: 69.59%, Precision: 99.99%, Recall: 65.29%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.4671, Average Validation Loss: 0.3993, Accuracy: 80.75%, Precision: 99.94%, Recall: 74.84%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4106, Average Validation Loss: 0.4005, Accuracy: 80.27%, Precision: 99.94%, Recall: 74.37%, F1: 0.85\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.3481, Average Validation Loss: 0.4240, Accuracy: 82.55%, Precision: 99.91%, Recall: 76.66%, F1: 0.87\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.2881, Average Validation Loss: 0.8513, Accuracy: 81.33%, Precision: 99.99%, Recall: 75.39%, F1: 0.86\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.2213, Average Validation Loss: 1.3480, Accuracy: 79.50%, Precision: 100.00%, Recall: 73.61%, F1: 0.85\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.1186, Average Validation Loss: 0.7306, Accuracy: 82.48%, Precision: 100.00%, Recall: 76.55%, F1: 0.87\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 16:37:43,877] Trial 8 finished with value: 0.7327266821990142 and parameters: {'vector_length': 512, 'num_blocks': 4, 'num_heads': 4, 'num_epochs': 5, 'dropout': 0.5, 'metadata_vector_length': 256, 'lr': 3.9629625087059624e-05, 'warmup_steps': 10}. Best is trial 4 with value: 0.0019219860409361285.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 9, with 25,535,488 parameters\n","Num non-decayed parameter tensors: 13, with 18,434 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6655, Average Validation Loss: 0.6372, Accuracy: 61.92%, Precision: 99.99%, Recall: 60.03%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6124, Average Validation Loss: 0.5784, Accuracy: 59.37%, Precision: 100.00%, Recall: 58.47%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.5490, Average Validation Loss: 0.4924, Accuracy: 79.99%, Precision: 100.00%, Recall: 74.09%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.4495, Average Validation Loss: 0.3900, Accuracy: 96.10%, Precision: 99.90%, Recall: 93.70%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3542, Average Validation Loss: 0.3085, Accuracy: 94.86%, Precision: 99.96%, Recall: 91.79%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2874, Average Validation Loss: 0.2392, Accuracy: 98.23%, Precision: 99.88%, Recall: 97.11%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2124, Average Validation Loss: 0.1948, Accuracy: 97.89%, Precision: 99.92%, Recall: 96.51%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1834, Average Validation Loss: 0.1541, Accuracy: 99.17%, Precision: 99.81%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1519, Average Validation Loss: 0.1285, Accuracy: 99.22%, Precision: 99.82%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1179, Average Validation Loss: 0.1113, Accuracy: 99.16%, Precision: 99.90%, Recall: 98.66%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1092, Average Validation Loss: 0.0970, Accuracy: 99.20%, Precision: 99.91%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0899, Average Validation Loss: 0.0829, Accuracy: 99.43%, Precision: 99.88%, Recall: 99.13%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0886, Average Validation Loss: 0.0740, Accuracy: 99.41%, Precision: 99.93%, Recall: 99.04%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0779, Average Validation Loss: 0.0663, Accuracy: 99.39%, Precision: 99.96%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0644, Average Validation Loss: 0.0560, Accuracy: 99.48%, Precision: 99.96%, Recall: 99.14%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0617, Average Validation Loss: 0.0523, Accuracy: 99.34%, Precision: 99.97%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0543, Average Validation Loss: 0.0505, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0444, Average Validation Loss: 0.0637, Accuracy: 98.24%, Precision: 100.00%, Recall: 97.01%, F1: 0.98\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0319, Average Validation Loss: 0.0671, Accuracy: 97.90%, Precision: 100.00%, Recall: 96.45%, F1: 0.98\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0309, Average Validation Loss: 0.0678, Accuracy: 97.84%, Precision: 100.00%, Recall: 96.36%, F1: 0.98\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0200, Average Validation Loss: 0.0630, Accuracy: 98.17%, Precision: 100.00%, Recall: 96.90%, F1: 0.98\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0510, Accuracy: 98.57%, Precision: 100.00%, Recall: 97.56%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 16:41:05,002] Trial 9 finished with value: 0.051026709740226335 and parameters: {'vector_length': 1024, 'num_blocks': 1, 'num_heads': 8, 'num_epochs': 2, 'dropout': 0.4, 'metadata_vector_length': 2048, 'lr': 1.3476024898920556e-05, 'warmup_steps': 40}. Best is trial 4 with value: 0.0019219860409361285.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 173,575,168 parameters\n","Num non-decayed parameter tensors: 29, with 86,530 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5755, Average Validation Loss: 0.2162, Accuracy: 91.26%, Precision: 99.99%, Recall: 86.75%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.0653, Average Validation Loss: 0.0070, Accuracy: 99.78%, Precision: 99.96%, Recall: 99.66%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0108, Average Validation Loss: 0.0039, Accuracy: 99.87%, Precision: 99.96%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0055, Average Validation Loss: 0.0030, Accuracy: 99.92%, Precision: 99.93%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0043, Average Validation Loss: 0.0030, Accuracy: 99.94%, Precision: 99.98%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0106, Average Validation Loss: 0.0023, Accuracy: 99.92%, Precision: 99.90%, Recall: 99.97%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0022, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0012, Accuracy: 99.94%, Precision: 99.95%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0019, Accuracy: 99.92%, Precision: 99.91%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0021, Accuracy: 99.91%, Precision: 99.96%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0018, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0017, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0009, Accuracy: 99.96%, Precision: 99.98%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 16:50:32,531] Trial 10 finished with value: 0.0009231988737758149 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 512, 'lr': 0.0008722723666139161, 'warmup_steps': 30}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 173,575,168 parameters\n","Num non-decayed parameter tensors: 29, with 86,530 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6032, Average Validation Loss: 0.1532, Accuracy: 98.63%, Precision: 99.87%, Recall: 97.79%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0688, Average Validation Loss: 0.0268, Accuracy: 99.11%, Precision: 98.47%, Recall: 99.98%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0094, Average Validation Loss: 0.0047, Accuracy: 99.86%, Precision: 99.95%, Recall: 99.80%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0088, Average Validation Loss: 0.0036, Accuracy: 99.88%, Precision: 99.85%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0089, Average Validation Loss: 0.0076, Accuracy: 99.82%, Precision: 99.99%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0090, Average Validation Loss: 0.0031, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0054, Average Validation Loss: 0.0028, Accuracy: 99.89%, Precision: 99.87%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0051, Average Validation Loss: 0.0023, Accuracy: 99.92%, Precision: 99.88%, Recall: 99.97%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0015, Accuracy: 99.94%, Precision: 99.97%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0043, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0024, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0015, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0043, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 16:59:59,605] Trial 11 finished with value: 0.004301505866791453 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 512, 'lr': 0.0009956929648335094, 'warmup_steps': 30}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 21, with 2,221,696 parameters\n","Num non-decayed parameter tensors: 37, with 7,554 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6119, Average Validation Loss: 0.5257, Accuracy: 87.96%, Precision: 99.99%, Recall: 82.62%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.4253, Average Validation Loss: 0.2762, Accuracy: 98.58%, Precision: 99.69%, Recall: 97.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1844, Average Validation Loss: 0.0888, Accuracy: 99.24%, Precision: 99.70%, Recall: 98.97%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0551, Average Validation Loss: 0.0271, Accuracy: 99.43%, Precision: 99.96%, Recall: 99.06%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0144, Average Validation Loss: 0.0066, Accuracy: 99.78%, Precision: 99.99%, Recall: 99.62%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0039, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0047, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0030, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0043, Average Validation Loss: 0.0035, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0029, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0032, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0032, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0025, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0025, Accuracy: 99.94%, Precision: 99.98%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0034, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 17:01:41,373] Trial 12 finished with value: 0.003432781191116413 and parameters: {'vector_length': 128, 'num_blocks': 4, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.1, 'metadata_vector_length': 512, 'lr': 0.0006981260035110475, 'warmup_steps': 40}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 173,575,168 parameters\n","Num non-decayed parameter tensors: 29, with 86,530 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5886, Average Validation Loss: 0.3457, Accuracy: 78.55%, Precision: 100.00%, Recall: 72.72%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.1622, Average Validation Loss: 0.0114, Accuracy: 99.80%, Precision: 99.99%, Recall: 99.66%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0125, Average Validation Loss: 0.0056, Accuracy: 99.80%, Precision: 99.99%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0072, Average Validation Loss: 0.0105, Accuracy: 99.74%, Precision: 99.58%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0040, Accuracy: 99.90%, Precision: 99.95%, Recall: 99.88%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0035, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0048, Accuracy: 99.90%, Precision: 99.87%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0031, Average Validation Loss: 0.0026, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0029, Average Validation Loss: 0.0028, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0023, Accuracy: 99.94%, Precision: 99.97%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0060, Average Validation Loss: 0.0027, Accuracy: 99.94%, Precision: 99.93%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0038, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0020, Accuracy: 99.94%, Precision: 99.97%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 17:11:08,158] Trial 13 finished with value: 0.0019971391274216208 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 512, 'lr': 0.0003161107407077119, 'warmup_steps': 20}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 1,760,128 parameters\n","Num non-decayed parameter tensors: 21, with 3,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6726, Average Validation Loss: 0.6521, Accuracy: 60.37%, Precision: 99.66%, Recall: 59.10%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6249, Average Validation Loss: 0.6314, Accuracy: 57.88%, Precision: 99.96%, Recall: 57.59%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6064, Average Validation Loss: 0.5476, Accuracy: 84.18%, Precision: 99.90%, Recall: 78.37%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.5166, Average Validation Loss: 0.4570, Accuracy: 84.41%, Precision: 99.96%, Recall: 78.59%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4175, Average Validation Loss: 0.3318, Accuracy: 97.42%, Precision: 99.93%, Recall: 95.74%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2865, Average Validation Loss: 0.2078, Accuracy: 98.34%, Precision: 99.90%, Recall: 97.27%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1740, Average Validation Loss: 0.1191, Accuracy: 98.30%, Precision: 99.96%, Recall: 97.15%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1010, Average Validation Loss: 0.0522, Accuracy: 99.07%, Precision: 99.99%, Recall: 98.42%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0395, Average Validation Loss: 0.0153, Accuracy: 99.44%, Precision: 100.00%, Recall: 99.04%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0141, Average Validation Loss: 0.0172, Accuracy: 99.31%, Precision: 100.00%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0132, Average Validation Loss: 0.0140, Accuracy: 99.42%, Precision: 100.00%, Recall: 99.00%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0086, Average Validation Loss: 0.0137, Accuracy: 99.43%, Precision: 100.00%, Recall: 99.01%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0113, Average Validation Loss: 0.0126, Accuracy: 99.49%, Precision: 100.00%, Recall: 99.12%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0127, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0086, Average Validation Loss: 0.0070, Accuracy: 99.72%, Precision: 100.00%, Recall: 99.51%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0078, Average Validation Loss: 0.0104, Accuracy: 99.54%, Precision: 100.00%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0129, Accuracy: 99.50%, Precision: 100.00%, Recall: 99.13%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0075, Accuracy: 99.68%, Precision: 100.00%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0048, Average Validation Loss: 0.0077, Accuracy: 99.68%, Precision: 100.00%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0144, Average Validation Loss: 0.0077, Accuracy: 99.68%, Precision: 100.00%, Recall: 99.44%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 17:13:10,081] Trial 14 finished with value: 0.007704460798334834 and parameters: {'vector_length': 128, 'num_blocks': 2, 'num_heads': 4, 'num_epochs': 4, 'dropout': 0.30000000000000004, 'metadata_vector_length': 128, 'lr': 0.00030565510553749904, 'warmup_steps': 50}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 174,649,344 parameters\n","Num non-decayed parameter tensors: 29, with 87,042 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5594, Average Validation Loss: 0.5194, Accuracy: 72.04%, Precision: 100.00%, Recall: 67.16%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.1758, Average Validation Loss: 0.0545, Accuracy: 98.71%, Precision: 100.00%, Recall: 97.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0075, Average Validation Loss: 0.0142, Accuracy: 99.65%, Precision: 100.00%, Recall: 99.39%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0105, Average Validation Loss: 0.0050, Accuracy: 99.81%, Precision: 99.99%, Recall: 99.69%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0318, Average Validation Loss: 0.0047, Accuracy: 99.87%, Precision: 99.95%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0092, Average Validation Loss: 0.0036, Accuracy: 99.89%, Precision: 99.94%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0072, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0039, Average Validation Loss: 0.0026, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0068, Accuracy: 99.78%, Precision: 100.00%, Recall: 99.61%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0020, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0035, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0029, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0018, Accuracy: 99.95%, Precision: 99.96%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0018, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0013, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 17:24:10,445] Trial 15 finished with value: 0.0013538243400084006 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 8, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 1024, 'lr': 0.00018273809384487596, 'warmup_steps': 20}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 173,575,168 parameters\n","Num non-decayed parameter tensors: 29, with 86,530 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5830, Average Validation Loss: 0.2440, Accuracy: 88.74%, Precision: 99.38%, Recall: 83.90%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.1323, Average Validation Loss: 0.1381, Accuracy: 98.61%, Precision: 100.00%, Recall: 97.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0248, Average Validation Loss: 0.0297, Accuracy: 99.10%, Precision: 100.00%, Recall: 98.45%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0159, Average Validation Loss: 0.0103, Accuracy: 99.59%, Precision: 100.00%, Recall: 99.29%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0088, Average Validation Loss: 0.0076, Accuracy: 99.81%, Precision: 99.99%, Recall: 99.69%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0088, Average Validation Loss: 0.0050, Accuracy: 99.85%, Precision: 100.00%, Recall: 99.73%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0035, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0104, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.33%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0028, Accuracy: 99.93%, Precision: 99.97%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0188, Accuracy: 99.41%, Precision: 99.99%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0113, Average Validation Loss: 0.0025, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0017, Accuracy: 99.95%, Precision: 99.98%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0030, Accuracy: 99.92%, Precision: 99.95%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0032, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0023, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0008, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0013, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 17:36:27,101] Trial 16 finished with value: 0.0012696250236429575 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 512, 'lr': 0.0005697577154768624, 'warmup_steps': 60}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 21, with 223,906,816 parameters\n","Num non-decayed parameter tensors: 37, with 113,154 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7211, Average Validation Loss: 0.4217, Accuracy: 96.81%, Precision: 95.71%, Recall: 98.66%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.3528, Average Validation Loss: 0.0457, Accuracy: 98.73%, Precision: 99.99%, Recall: 97.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0738, Average Validation Loss: 0.0157, Accuracy: 99.49%, Precision: 99.99%, Recall: 99.13%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0083, Accuracy: 99.76%, Precision: 99.98%, Recall: 99.60%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0060, Accuracy: 99.83%, Precision: 99.96%, Recall: 99.75%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0045, Accuracy: 99.86%, Precision: 99.96%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0030, Accuracy: 99.90%, Precision: 99.96%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0035, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0071, Accuracy: 99.75%, Precision: 99.99%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0035, Average Validation Loss: 0.0024, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0030, Accuracy: 99.94%, Precision: 99.93%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0021, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 17:47:45,726] Trial 17 finished with value: 0.002092582936598479 and parameters: {'vector_length': 2048, 'num_blocks': 4, 'num_heads': 2, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 512, 'lr': 0.0005741521135210169, 'warmup_steps': 60}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 173,575,168 parameters\n","Num non-decayed parameter tensors: 29, with 86,530 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6513, Average Validation Loss: 0.5962, Accuracy: 63.68%, Precision: 99.98%, Recall: 61.16%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5608, Average Validation Loss: 0.4465, Accuracy: 82.11%, Precision: 99.83%, Recall: 76.24%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4429, Average Validation Loss: 0.6094, Accuracy: 78.77%, Precision: 100.00%, Recall: 72.93%, F1: 0.84\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1610, Average Validation Loss: 0.2915, Accuracy: 96.98%, Precision: 100.00%, Recall: 94.99%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.0795, Average Validation Loss: 0.1757, Accuracy: 98.48%, Precision: 100.00%, Recall: 97.41%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1583, Average Validation Loss: 0.4016, Accuracy: 90.26%, Precision: 100.00%, Recall: 85.45%, F1: 0.92\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0798, Average Validation Loss: 0.0821, Accuracy: 98.19%, Precision: 100.00%, Recall: 96.94%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0224, Average Validation Loss: 0.0264, Accuracy: 98.96%, Precision: 100.00%, Recall: 98.22%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0109, Average Validation Loss: 0.0249, Accuracy: 99.12%, Precision: 100.00%, Recall: 98.49%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0182, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.32%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0113, Accuracy: 99.81%, Precision: 99.99%, Recall: 99.68%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0100, Average Validation Loss: 0.0264, Accuracy: 99.42%, Precision: 100.00%, Recall: 98.99%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0115, Average Validation Loss: 0.0145, Accuracy: 99.69%, Precision: 100.00%, Recall: 99.46%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0281, Accuracy: 99.53%, Precision: 100.00%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0076, Average Validation Loss: 0.0133, Accuracy: 99.71%, Precision: 100.00%, Recall: 99.49%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0093, Average Validation Loss: 0.0084, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0137, Average Validation Loss: 0.0101, Accuracy: 99.72%, Precision: 100.00%, Recall: 99.51%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0094, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0085, Average Validation Loss: 0.0125, Accuracy: 99.74%, Precision: 100.00%, Recall: 99.55%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0100, Average Validation Loss: 0.0066, Accuracy: 99.79%, Precision: 100.00%, Recall: 99.63%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0069, Average Validation Loss: 0.0140, Accuracy: 99.59%, Precision: 100.00%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0090, Average Validation Loss: 0.0069, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0145, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.32%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0033, Average Validation Loss: 0.0115, Accuracy: 99.70%, Precision: 100.00%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0124, Average Validation Loss: 0.0066, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 18:05:43,096] Trial 18 finished with value: 0.006638176251648031 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 1, 'dropout': 0.5, 'metadata_vector_length': 512, 'lr': 7.771744922803283e-05, 'warmup_steps': 60}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 11,955,712 parameters\n","Num non-decayed parameter tensors: 21, with 15,362 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6270, Average Validation Loss: 0.5209, Accuracy: 96.42%, Precision: 98.66%, Recall: 95.25%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.4031, Average Validation Loss: 0.2265, Accuracy: 97.03%, Precision: 99.90%, Recall: 95.15%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.1301, Average Validation Loss: 0.0296, Accuracy: 99.00%, Precision: 100.00%, Recall: 98.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0191, Average Validation Loss: 0.0091, Accuracy: 99.64%, Precision: 100.00%, Recall: 99.38%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0060, Accuracy: 99.79%, Precision: 99.99%, Recall: 99.65%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0064, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0057, Accuracy: 99.78%, Precision: 100.00%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0051, Average Validation Loss: 0.0036, Accuracy: 99.92%, Precision: 99.98%, Recall: 99.88%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0064, Average Validation Loss: 0.0062, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0027, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0023, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.88%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0023, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0022, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0019, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0017, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0015, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 18:07:48,742] Trial 19 finished with value: 0.0015284904199762497 and parameters: {'vector_length': 512, 'num_blocks': 2, 'num_heads': 2, 'num_epochs': 3, 'dropout': 0.2, 'metadata_vector_length': 512, 'lr': 0.0005231896758518245, 'warmup_steps': 50}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 21, with 223,906,816 parameters\n","Num non-decayed parameter tensors: 37, with 113,154 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7113, Average Validation Loss: 0.7059, Accuracy: 46.95%, Precision: 77.64%, Recall: 52.44%, F1: 0.63\n","Epoch 0, Average Training Loss: 0.7030, Average Validation Loss: 0.6953, Accuracy: 57.31%, Precision: 99.84%, Recall: 57.27%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6929, Average Validation Loss: 0.6941, Accuracy: 57.22%, Precision: 99.97%, Recall: 57.21%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6916, Average Validation Loss: 0.6859, Accuracy: 57.28%, Precision: 99.97%, Recall: 57.24%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6832, Average Validation Loss: 0.6695, Accuracy: 58.33%, Precision: 99.96%, Recall: 57.85%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6748, Average Validation Loss: 0.6570, Accuracy: 59.19%, Precision: 99.97%, Recall: 58.36%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6644, Average Validation Loss: 0.6427, Accuracy: 60.16%, Precision: 99.97%, Recall: 58.95%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6505, Average Validation Loss: 0.6255, Accuracy: 63.32%, Precision: 99.98%, Recall: 60.93%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6331, Average Validation Loss: 0.6178, Accuracy: 62.10%, Precision: 99.99%, Recall: 60.14%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6176, Average Validation Loss: 0.5937, Accuracy: 67.05%, Precision: 99.99%, Recall: 63.45%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5995, Average Validation Loss: 0.5932, Accuracy: 64.15%, Precision: 99.99%, Recall: 61.47%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5975, Average Validation Loss: 0.5551, Accuracy: 74.10%, Precision: 99.98%, Recall: 68.83%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5802, Average Validation Loss: 0.5394, Accuracy: 73.13%, Precision: 99.99%, Recall: 68.04%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5605, Average Validation Loss: 0.5233, Accuracy: 73.11%, Precision: 100.00%, Recall: 68.02%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5412, Average Validation Loss: 0.5131, Accuracy: 72.62%, Precision: 100.00%, Recall: 67.62%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5320, Average Validation Loss: 0.4590, Accuracy: 79.71%, Precision: 99.97%, Recall: 73.82%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.5023, Average Validation Loss: 0.4552, Accuracy: 76.77%, Precision: 100.00%, Recall: 71.11%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.4669, Average Validation Loss: 0.4049, Accuracy: 80.33%, Precision: 100.00%, Recall: 74.41%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.4143, Average Validation Loss: 0.4749, Accuracy: 79.66%, Precision: 100.00%, Recall: 73.77%, F1: 0.85\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.3282, Average Validation Loss: 0.3928, Accuracy: 82.01%, Precision: 100.00%, Recall: 76.07%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.2017, Average Validation Loss: 0.3720, Accuracy: 82.39%, Precision: 100.00%, Recall: 76.46%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.1089, Average Validation Loss: 0.2174, Accuracy: 90.22%, Precision: 100.00%, Recall: 85.39%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.0766, Average Validation Loss: 0.1262, Accuracy: 97.79%, Precision: 100.00%, Recall: 96.28%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0476, Average Validation Loss: 0.1254, Accuracy: 98.35%, Precision: 100.00%, Recall: 97.20%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0575, Average Validation Loss: 0.1145, Accuracy: 98.59%, Precision: 100.00%, Recall: 97.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0468, Average Validation Loss: 0.1172, Accuracy: 98.61%, Precision: 100.00%, Recall: 97.63%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0443, Average Validation Loss: 0.1195, Accuracy: 98.62%, Precision: 100.00%, Recall: 97.64%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0457, Average Validation Loss: 0.1209, Accuracy: 98.62%, Precision: 100.00%, Recall: 97.64%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0537, Average Validation Loss: 0.1130, Accuracy: 98.66%, Precision: 100.00%, Recall: 97.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0509, Average Validation Loss: 0.1193, Accuracy: 98.65%, Precision: 100.00%, Recall: 97.69%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0509, Average Validation Loss: 0.1142, Accuracy: 98.69%, Precision: 100.00%, Recall: 97.77%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0247, Average Validation Loss: 0.1281, Accuracy: 98.63%, Precision: 100.00%, Recall: 97.67%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0353, Average Validation Loss: 0.1264, Accuracy: 98.65%, Precision: 100.00%, Recall: 97.70%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0504, Average Validation Loss: 0.1109, Accuracy: 98.71%, Precision: 100.00%, Recall: 97.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0275, Average Validation Loss: 0.1230, Accuracy: 98.68%, Precision: 100.00%, Recall: 97.74%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0439, Average Validation Loss: 0.1164, Accuracy: 98.71%, Precision: 100.00%, Recall: 97.79%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0326, Average Validation Loss: 0.1163, Accuracy: 98.71%, Precision: 100.00%, Recall: 97.80%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.1201, Accuracy: 98.71%, Precision: 100.00%, Recall: 97.79%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0444, Average Validation Loss: 0.1106, Accuracy: 98.72%, Precision: 100.00%, Recall: 97.82%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 18:43:59,630] Trial 20 finished with value: 0.11082767771204581 and parameters: {'vector_length': 2048, 'num_blocks': 4, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.30000000000000004, 'metadata_vector_length': 512, 'lr': 1.34571132030221e-06, 'warmup_steps': 70}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 174,649,344 parameters\n","Num non-decayed parameter tensors: 29, with 87,042 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6175, Average Validation Loss: 0.4299, Accuracy: 89.69%, Precision: 99.58%, Recall: 84.97%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.3201, Average Validation Loss: 0.2281, Accuracy: 89.45%, Precision: 100.00%, Recall: 84.43%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.0535, Average Validation Loss: 0.0371, Accuracy: 99.08%, Precision: 100.00%, Recall: 98.42%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.0439, Accuracy: 98.88%, Precision: 100.00%, Recall: 98.09%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0125, Average Validation Loss: 0.0119, Accuracy: 99.55%, Precision: 100.00%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0090, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0068, Average Validation Loss: 0.0228, Accuracy: 99.41%, Precision: 100.00%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0064, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.57%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0035, Accuracy: 99.90%, Precision: 99.97%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0080, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0044, Average Validation Loss: 0.0042, Accuracy: 99.87%, Precision: 100.00%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0071, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0029, Average Validation Loss: 0.0031, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0051, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 18:54:11,075] Trial 21 finished with value: 0.005092780539082407 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 1024, 'lr': 0.00011745670547615073, 'warmup_steps': 30}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 173,575,168 parameters\n","Num non-decayed parameter tensors: 29, with 86,530 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5750, Average Validation Loss: 0.5235, Accuracy: 68.28%, Precision: 99.99%, Recall: 64.33%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.1918, Average Validation Loss: 0.0261, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1229, Average Validation Loss: 0.0517, Accuracy: 98.39%, Precision: 100.00%, Recall: 97.27%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0402, Average Validation Loss: 0.0110, Accuracy: 99.64%, Precision: 100.00%, Recall: 99.37%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0109, Average Validation Loss: 0.0060, Accuracy: 99.85%, Precision: 99.81%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0039, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0039, Average Validation Loss: 0.0029, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0033, Accuracy: 99.92%, Precision: 99.91%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0029, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0054, Accuracy: 99.81%, Precision: 100.00%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0024, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0027, Accuracy: 99.94%, Precision: 99.95%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0024, Average Validation Loss: 0.0030, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0038, Accuracy: 99.87%, Precision: 100.00%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0088, Average Validation Loss: 0.0031, Accuracy: 99.90%, Precision: 99.85%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0016, Accuracy: 99.95%, Precision: 99.97%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 19:05:54,280] Trial 22 finished with value: 0.001548947935540078 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 8, 'num_epochs': 2, 'dropout': 0.30000000000000004, 'metadata_vector_length': 512, 'lr': 0.0004189497718749863, 'warmup_steps': 40}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 172,769,536 parameters\n","Num non-decayed parameter tensors: 29, with 86,146 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.9789, Average Validation Loss: 0.3652, Accuracy: 83.56%, Precision: 99.98%, Recall: 77.68%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.1513, Average Validation Loss: 0.0160, Accuracy: 99.41%, Precision: 100.00%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0113, Average Validation Loss: 0.0044, Accuracy: 99.85%, Precision: 99.95%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0131, Average Validation Loss: 0.0043, Accuracy: 99.85%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0027, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0024, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0032, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0024, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0016, Accuracy: 99.95%, Precision: 99.98%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0039, Average Validation Loss: 0.0019, Accuracy: 99.95%, Precision: 99.95%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0024, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0064, Average Validation Loss: 0.0040, Accuracy: 99.89%, Precision: 99.81%, Recall: 100.00%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0031, Average Validation Loss: 0.0022, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0020, Accuracy: 99.95%, Precision: 99.92%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 19:16:08,251] Trial 23 finished with value: 0.0020179052333775403 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 4, 'num_epochs': 3, 'dropout': 0.2, 'metadata_vector_length': 128, 'lr': 0.0009801759572842838, 'warmup_steps': 20}. Best is trial 10 with value: 0.0009231988737758149.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 176,797,696 parameters\n","Num non-decayed parameter tensors: 29, with 88,066 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3959, Average Validation Loss: 0.0487, Accuracy: 99.12%, Precision: 99.95%, Recall: 98.53%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0261, Average Validation Loss: 0.0312, Accuracy: 99.05%, Precision: 100.00%, Recall: 98.36%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0235, Accuracy: 99.36%, Precision: 100.00%, Recall: 98.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0173, Average Validation Loss: 0.0041, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.73%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0061, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.66%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0081, Average Validation Loss: 0.0034, Accuracy: 99.90%, Precision: 99.83%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0017, Accuracy: 99.95%, Precision: 99.96%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0013, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0062, Accuracy: 99.78%, Precision: 100.00%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0024, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0007, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0007, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 19:24:52,802] Trial 24 finished with value: 0.0007377692726672772 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.00017472157931300539, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 126,466,048 parameters\n","Num non-decayed parameter tensors: 21, with 61,442 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3265, Average Validation Loss: 0.0221, Accuracy: 99.48%, Precision: 99.41%, Recall: 99.68%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0124, Average Validation Loss: 0.0072, Accuracy: 99.78%, Precision: 99.97%, Recall: 99.65%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0047, Accuracy: 99.87%, Precision: 99.92%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0034, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0045, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0107, Average Validation Loss: 0.0026, Accuracy: 99.92%, Precision: 99.90%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0021, Accuracy: 99.96%, Precision: 99.99%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0020, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0100, Average Validation Loss: 0.0015, Accuracy: 99.96%, Precision: 99.97%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0016, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0031, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0045, Accuracy: 99.89%, Precision: 100.00%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 19:31:01,479] Trial 25 finished with value: 0.004506469165553918 and parameters: {'vector_length': 2048, 'num_blocks': 2, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.4, 'metadata_vector_length': 2048, 'lr': 0.00037339892564567143, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 21, with 227,129,344 parameters\n","Num non-decayed parameter tensors: 37, with 114,690 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7106, Average Validation Loss: 0.6751, Accuracy: 57.89%, Precision: 99.90%, Recall: 57.60%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6151, Average Validation Loss: 0.5404, Accuracy: 71.76%, Precision: 99.96%, Recall: 66.95%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.4867, Average Validation Loss: 0.3710, Accuracy: 91.67%, Precision: 99.62%, Recall: 87.54%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.3167, Average Validation Loss: 0.2390, Accuracy: 86.35%, Precision: 100.00%, Recall: 80.73%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.1140, Average Validation Loss: 0.1002, Accuracy: 98.70%, Precision: 100.00%, Recall: 97.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0193, Average Validation Loss: 0.1222, Accuracy: 98.66%, Precision: 100.00%, Recall: 97.72%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0212, Average Validation Loss: 0.0723, Accuracy: 98.79%, Precision: 100.00%, Recall: 97.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0178, Average Validation Loss: 0.0997, Accuracy: 98.71%, Precision: 100.00%, Recall: 97.80%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0204, Average Validation Loss: 0.0416, Accuracy: 99.28%, Precision: 100.00%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0101, Average Validation Loss: 0.0103, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0104, Average Validation Loss: 0.0118, Accuracy: 99.70%, Precision: 100.00%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0132, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0143, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0070, Accuracy: 99.79%, Precision: 100.00%, Recall: 99.64%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0139, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0118, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0059, Accuracy: 99.84%, Precision: 99.99%, Recall: 99.73%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0149, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0101, Average Validation Loss: 0.0046, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0067, Average Validation Loss: 0.0078, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0060, Accuracy: 99.78%, Precision: 100.00%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0089, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0075, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0060, Accuracy: 99.81%, Precision: 100.00%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 19:53:22,570] Trial 26 finished with value: 0.005952674488700624 and parameters: {'vector_length': 2048, 'num_blocks': 4, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 2.8189389253138545e-05, 'warmup_steps': 80}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 15,964,672 parameters\n","Num non-decayed parameter tensors: 29, with 23,554 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6271, Average Validation Loss: 0.5672, Accuracy: 58.71%, Precision: 100.00%, Recall: 58.07%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.3795, Average Validation Loss: 0.2360, Accuracy: 99.01%, Precision: 99.30%, Recall: 98.98%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1562, Average Validation Loss: 0.0838, Accuracy: 99.19%, Precision: 99.74%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0527, Average Validation Loss: 0.0385, Accuracy: 99.31%, Precision: 99.93%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0241, Average Validation Loss: 0.0270, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0118, Average Validation Loss: 0.0093, Accuracy: 99.65%, Precision: 100.00%, Recall: 99.40%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0127, Average Validation Loss: 0.0071, Accuracy: 99.74%, Precision: 100.00%, Recall: 99.54%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0085, Average Validation Loss: 0.0039, Accuracy: 99.85%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0067, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0052, Average Validation Loss: 0.0056, Accuracy: 99.79%, Precision: 100.00%, Recall: 99.64%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0047, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.66%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0030, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0058, Accuracy: 99.78%, Precision: 100.00%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 19:55:22,808] Trial 27 finished with value: 0.005833208439022151 and parameters: {'vector_length': 512, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.00016899200458943742, 'warmup_steps': 50}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 126,466,048 parameters\n","Num non-decayed parameter tensors: 21, with 61,442 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6727, Average Validation Loss: 0.5662, Accuracy: 81.33%, Precision: 99.95%, Recall: 75.41%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4532, Average Validation Loss: 0.3044, Accuracy: 97.59%, Precision: 99.81%, Recall: 96.12%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2083, Average Validation Loss: 0.1135, Accuracy: 95.26%, Precision: 100.00%, Recall: 92.35%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.0341, Average Validation Loss: 0.0378, Accuracy: 99.01%, Precision: 100.00%, Recall: 98.30%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0261, Average Validation Loss: 0.0371, Accuracy: 99.00%, Precision: 100.00%, Recall: 98.28%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0137, Accuracy: 99.46%, Precision: 100.00%, Recall: 99.07%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0122, Average Validation Loss: 0.0177, Accuracy: 99.30%, Precision: 100.00%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0312, Accuracy: 99.03%, Precision: 100.00%, Recall: 98.34%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0090, Average Validation Loss: 0.0158, Accuracy: 99.40%, Precision: 100.00%, Recall: 98.96%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0151, Accuracy: 99.43%, Precision: 100.00%, Recall: 99.02%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0174, Accuracy: 99.33%, Precision: 100.00%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:01:02,320] Trial 28 finished with value: 0.017415710276848562 and parameters: {'vector_length': 2048, 'num_blocks': 2, 'num_heads': 2, 'num_epochs': 3, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 3.52112466639763e-05, 'warmup_steps': 30}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 49,051,648 parameters\n","Num non-decayed parameter tensors: 29, with 43,522 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4654, Average Validation Loss: 0.1059, Accuracy: 96.75%, Precision: 99.95%, Recall: 94.67%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.0344, Average Validation Loss: 0.0072, Accuracy: 99.76%, Precision: 99.99%, Recall: 99.60%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0028, Accuracy: 99.93%, Precision: 99.94%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0040, Average Validation Loss: 0.0085, Accuracy: 99.70%, Precision: 99.99%, Recall: 99.49%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0020, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0026, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0017, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0015, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0014, Accuracy: 99.94%, Precision: 99.98%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0017, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0022, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0011, Accuracy: 99.95%, Precision: 99.96%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:04:28,061] Trial 29 finished with value: 0.001277670103150445 and parameters: {'vector_length': 1024, 'num_blocks': 3, 'num_heads': 4, 'num_epochs': 4, 'dropout': 0.4, 'metadata_vector_length': 512, 'lr': 0.0006983860948613001, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 21, with 223,906,816 parameters\n","Num non-decayed parameter tensors: 37, with 113,154 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6355, Average Validation Loss: 0.6085, Accuracy: 63.06%, Precision: 100.00%, Recall: 60.76%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.4454, Average Validation Loss: 0.1721, Accuracy: 89.70%, Precision: 100.00%, Recall: 84.74%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.1297, Average Validation Loss: 0.1042, Accuracy: 98.63%, Precision: 100.00%, Recall: 97.66%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0536, Average Validation Loss: 0.0587, Accuracy: 98.76%, Precision: 99.99%, Recall: 97.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0114, Average Validation Loss: 0.0113, Accuracy: 99.66%, Precision: 99.93%, Recall: 99.48%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0098, Average Validation Loss: 0.0082, Accuracy: 99.75%, Precision: 99.98%, Recall: 99.58%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0127, Average Validation Loss: 0.0081, Accuracy: 99.77%, Precision: 99.97%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0211, Accuracy: 99.60%, Precision: 99.99%, Recall: 99.32%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0103, Accuracy: 99.70%, Precision: 99.99%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0115, Average Validation Loss: 0.0077, Accuracy: 99.78%, Precision: 99.99%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0098, Average Validation Loss: 0.0068, Accuracy: 99.78%, Precision: 99.92%, Recall: 99.70%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0222, Accuracy: 99.55%, Precision: 100.00%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0204, Average Validation Loss: 0.0058, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0055, Average Validation Loss: 0.0041, Accuracy: 99.91%, Precision: 100.00%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0034, Average Validation Loss: 0.0040, Accuracy: 99.89%, Precision: 100.00%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0035, Average Validation Loss: 0.0050, Accuracy: 99.84%, Precision: 100.00%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0043, Accuracy: 99.84%, Precision: 100.00%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0075, Average Validation Loss: 0.0036, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0075, Accuracy: 99.72%, Precision: 100.00%, Recall: 99.51%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:22:15,264] Trial 30 finished with value: 0.0074592932872267715 and parameters: {'vector_length': 2048, 'num_blocks': 4, 'num_heads': 2, 'num_epochs': 5, 'dropout': 0.30000000000000004, 'metadata_vector_length': 512, 'lr': 0.0001215423699528795, 'warmup_steps': 40}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 49,051,648 parameters\n","Num non-decayed parameter tensors: 29, with 43,522 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4626, Average Validation Loss: 0.1356, Accuracy: 95.26%, Precision: 99.96%, Recall: 92.38%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.0409, Average Validation Loss: 0.0044, Accuracy: 99.88%, Precision: 99.93%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0094, Accuracy: 99.75%, Precision: 99.99%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0044, Accuracy: 99.88%, Precision: 99.84%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0047, Accuracy: 99.86%, Precision: 99.98%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0070, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0135, Average Validation Loss: 0.0053, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:24:18,442] Trial 31 finished with value: 0.005295569117407541 and parameters: {'vector_length': 1024, 'num_blocks': 3, 'num_heads': 4, 'num_epochs': 4, 'dropout': 0.4, 'metadata_vector_length': 512, 'lr': 0.0006836454656663719, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 49,051,648 parameters\n","Num non-decayed parameter tensors: 29, with 43,522 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5220, Average Validation Loss: 0.2395, Accuracy: 88.86%, Precision: 99.94%, Recall: 83.73%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.1653, Average Validation Loss: 0.1011, Accuracy: 97.95%, Precision: 100.00%, Recall: 96.54%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0201, Average Validation Loss: 0.0441, Accuracy: 98.84%, Precision: 100.00%, Recall: 98.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0076, Average Validation Loss: 0.0144, Accuracy: 99.52%, Precision: 100.00%, Recall: 99.17%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0096, Accuracy: 99.66%, Precision: 100.00%, Recall: 99.41%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0162, Accuracy: 99.48%, Precision: 100.00%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0110, Average Validation Loss: 0.0049, Accuracy: 99.92%, Precision: 99.91%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0113, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.33%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0049, Accuracy: 99.81%, Precision: 100.00%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0099, Average Validation Loss: 0.0029, Accuracy: 99.92%, Precision: 99.98%, Recall: 99.88%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0028, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0033, Accuracy: 99.88%, Precision: 100.00%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0049, Accuracy: 99.85%, Precision: 100.00%, Recall: 99.74%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0077, Accuracy: 99.77%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0071, Average Validation Loss: 0.0014, Accuracy: 99.96%, Precision: 99.99%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0021, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0015, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0014, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0022, Accuracy: 99.91%, Precision: 100.00%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0027, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:29:59,222] Trial 32 finished with value: 0.0027007146036487177 and parameters: {'vector_length': 1024, 'num_blocks': 3, 'num_heads': 4, 'num_epochs': 4, 'dropout': 0.4, 'metadata_vector_length': 512, 'lr': 0.0002820890836960729, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 49,051,648 parameters\n","Num non-decayed parameter tensors: 29, with 43,522 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4805, Average Validation Loss: 0.1549, Accuracy: 97.78%, Precision: 96.37%, Recall: 99.73%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0716, Average Validation Loss: 0.0136, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.33%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0086, Average Validation Loss: 0.0049, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0061, Accuracy: 99.84%, Precision: 99.99%, Recall: 99.74%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0031, Accuracy: 99.93%, Precision: 99.95%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0007, Average Validation Loss: 0.0045, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0034, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0036, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0024, Accuracy: 99.95%, Precision: 99.98%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0051, Accuracy: 99.87%, Precision: 100.00%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:32:51,975] Trial 33 finished with value: 0.00510891087342039 and parameters: {'vector_length': 1024, 'num_blocks': 3, 'num_heads': 4, 'num_epochs': 5, 'dropout': 0.5, 'metadata_vector_length': 512, 'lr': 0.0009618073457434084, 'warmup_steps': 20}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 48,776,704 parameters\n","Num non-decayed parameter tensors: 29, with 43,266 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5623, Average Validation Loss: 0.2548, Accuracy: 86.23%, Precision: 99.99%, Recall: 80.59%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.1053, Average Validation Loss: 0.0840, Accuracy: 98.56%, Precision: 100.00%, Recall: 97.54%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0076, Average Validation Loss: 0.0201, Accuracy: 99.31%, Precision: 100.00%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0073, Accuracy: 99.77%, Precision: 99.97%, Recall: 99.63%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0063, Average Validation Loss: 0.0103, Accuracy: 99.64%, Precision: 100.00%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0118, Average Validation Loss: 0.0045, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.71%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0106, Accuracy: 99.64%, Precision: 100.00%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0093, Average Validation Loss: 0.0032, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0044, Average Validation Loss: 0.0090, Accuracy: 99.70%, Precision: 100.00%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0050, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0031, Accuracy: 99.89%, Precision: 99.98%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0042, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0071, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:36:34,361] Trial 34 finished with value: 0.00706321094967771 and parameters: {'vector_length': 1024, 'num_blocks': 3, 'num_heads': 4, 'num_epochs': 3, 'dropout': 0.4, 'metadata_vector_length': 256, 'lr': 0.0004653768956404352, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 36,468,736 parameters\n","Num non-decayed parameter tensors: 21, with 30,210 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6242, Average Validation Loss: 0.4507, Accuracy: 93.96%, Precision: 98.67%, Recall: 91.44%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3208, Average Validation Loss: 0.4006, Accuracy: 83.23%, Precision: 100.00%, Recall: 77.32%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.0308, Average Validation Loss: 0.1155, Accuracy: 98.51%, Precision: 100.00%, Recall: 97.46%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0109, Average Validation Loss: 0.0197, Accuracy: 99.40%, Precision: 100.00%, Recall: 98.97%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0081, Average Validation Loss: 0.0126, Accuracy: 99.56%, Precision: 100.00%, Recall: 99.23%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0124, Average Validation Loss: 0.0070, Accuracy: 99.85%, Precision: 99.78%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0097, Average Validation Loss: 0.0036, Accuracy: 99.89%, Precision: 99.95%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0039, Average Validation Loss: 0.0036, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0080, Accuracy: 99.74%, Precision: 100.00%, Recall: 99.55%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0029, Average Validation Loss: 0.0032, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0083, Average Validation Loss: 0.0051, Accuracy: 99.86%, Precision: 99.78%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0032, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:39:12,347] Trial 35 finished with value: 0.0031866968783720653 and parameters: {'vector_length': 1024, 'num_blocks': 2, 'num_heads': 4, 'num_epochs': 5, 'dropout': 0.4, 'metadata_vector_length': 512, 'lr': 0.0006885534735138041, 'warmup_steps': 60}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 5,674,240 parameters\n","Num non-decayed parameter tensors: 29, with 12,802 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5980, Average Validation Loss: 0.3631, Accuracy: 91.38%, Precision: 99.97%, Recall: 86.92%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.2053, Average Validation Loss: 0.0746, Accuracy: 99.21%, Precision: 99.24%, Recall: 99.37%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0540, Average Validation Loss: 0.0397, Accuracy: 98.90%, Precision: 99.96%, Recall: 98.15%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0233, Average Validation Loss: 0.0151, Accuracy: 99.69%, Precision: 99.81%, Recall: 99.65%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0153, Average Validation Loss: 0.0180, Accuracy: 99.43%, Precision: 99.98%, Recall: 99.03%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0130, Average Validation Loss: 0.0172, Accuracy: 99.45%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0069, Average Validation Loss: 0.0104, Accuracy: 99.69%, Precision: 99.99%, Recall: 99.47%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0102, Accuracy: 99.68%, Precision: 99.99%, Recall: 99.46%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0149, Accuracy: 99.53%, Precision: 99.99%, Recall: 99.20%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0085, Average Validation Loss: 0.0069, Accuracy: 99.80%, Precision: 99.99%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0071, Average Validation Loss: 0.0080, Accuracy: 99.77%, Precision: 99.99%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0048, Average Validation Loss: 0.0116, Accuracy: 99.66%, Precision: 100.00%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0074, Accuracy: 99.77%, Precision: 100.00%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0024, Average Validation Loss: 0.0071, Accuracy: 99.77%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0072, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:40:59,522] Trial 36 finished with value: 0.007093638629728072 and parameters: {'vector_length': 256, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 2, 'dropout': 0.5, 'metadata_vector_length': 2048, 'lr': 0.00023687919334665786, 'warmup_steps': 20}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 48,639,232 parameters\n","Num non-decayed parameter tensors: 29, with 43,138 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6661, Average Validation Loss: 0.6635, Accuracy: 60.34%, Precision: 99.99%, Recall: 59.05%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6634, Average Validation Loss: 0.6582, Accuracy: 57.20%, Precision: 100.00%, Recall: 57.20%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6536, Average Validation Loss: 0.6425, Accuracy: 57.45%, Precision: 100.00%, Recall: 57.34%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6445, Average Validation Loss: 0.6253, Accuracy: 63.78%, Precision: 99.99%, Recall: 61.22%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6249, Average Validation Loss: 0.6113, Accuracy: 58.29%, Precision: 100.00%, Recall: 57.83%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.5989, Average Validation Loss: 0.5776, Accuracy: 66.50%, Precision: 100.00%, Recall: 63.06%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5759, Average Validation Loss: 0.5378, Accuracy: 74.47%, Precision: 100.00%, Recall: 69.14%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5513, Average Validation Loss: 0.4938, Accuracy: 75.20%, Precision: 100.00%, Recall: 69.75%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.4930, Average Validation Loss: 0.4081, Accuracy: 81.41%, Precision: 100.00%, Recall: 75.47%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4052, Average Validation Loss: 0.4596, Accuracy: 82.24%, Precision: 100.00%, Recall: 76.31%, F1: 0.87\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.1902, Average Validation Loss: 0.6717, Accuracy: 82.33%, Precision: 100.00%, Recall: 76.39%, F1: 0.87\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0321, Average Validation Loss: 0.2078, Accuracy: 96.62%, Precision: 100.00%, Recall: 94.42%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.0562, Average Validation Loss: 0.1547, Accuracy: 98.43%, Precision: 100.00%, Recall: 97.33%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0479, Average Validation Loss: 0.1439, Accuracy: 98.60%, Precision: 100.00%, Recall: 97.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0362, Average Validation Loss: 0.1435, Accuracy: 98.58%, Precision: 100.00%, Recall: 97.58%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0473, Average Validation Loss: 0.1423, Accuracy: 98.59%, Precision: 100.00%, Recall: 97.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0355, Average Validation Loss: 0.1292, Accuracy: 98.62%, Precision: 100.00%, Recall: 97.65%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0368, Average Validation Loss: 0.1405, Accuracy: 98.50%, Precision: 100.00%, Recall: 97.45%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0499, Average Validation Loss: 0.1320, Accuracy: 98.55%, Precision: 100.00%, Recall: 97.53%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0332, Average Validation Loss: 0.1379, Accuracy: 98.46%, Precision: 100.00%, Recall: 97.39%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0501, Average Validation Loss: 0.1330, Accuracy: 98.52%, Precision: 100.00%, Recall: 97.48%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0342, Average Validation Loss: 0.1223, Accuracy: 98.59%, Precision: 100.00%, Recall: 97.59%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0298, Average Validation Loss: 0.1217, Accuracy: 98.60%, Precision: 100.00%, Recall: 97.60%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0351, Average Validation Loss: 0.1139, Accuracy: 98.62%, Precision: 100.00%, Recall: 97.65%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0435, Average Validation Loss: 0.1207, Accuracy: 98.47%, Precision: 100.00%, Recall: 97.39%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.1196, Accuracy: 98.45%, Precision: 100.00%, Recall: 97.36%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0383, Average Validation Loss: 0.1046, Accuracy: 98.63%, Precision: 100.00%, Recall: 97.66%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0272, Average Validation Loss: 0.1014, Accuracy: 98.65%, Precision: 100.00%, Recall: 97.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0423, Average Validation Loss: 0.0835, Accuracy: 98.67%, Precision: 100.00%, Recall: 97.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0260, Average Validation Loss: 0.0787, Accuracy: 98.71%, Precision: 100.00%, Recall: 97.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0236, Average Validation Loss: 0.1037, Accuracy: 98.53%, Precision: 100.00%, Recall: 97.50%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0305, Average Validation Loss: 0.0603, Accuracy: 98.79%, Precision: 100.00%, Recall: 97.93%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0369, Average Validation Loss: 0.0725, Accuracy: 98.72%, Precision: 100.00%, Recall: 97.82%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0204, Average Validation Loss: 0.0688, Accuracy: 98.73%, Precision: 100.00%, Recall: 97.83%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0166, Average Validation Loss: 0.0631, Accuracy: 98.74%, Precision: 100.00%, Recall: 97.84%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0195, Average Validation Loss: 0.0512, Accuracy: 98.77%, Precision: 100.00%, Recall: 97.90%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0148, Average Validation Loss: 0.0523, Accuracy: 98.78%, Precision: 100.00%, Recall: 97.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0196, Average Validation Loss: 0.0442, Accuracy: 98.85%, Precision: 100.00%, Recall: 98.03%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0195, Average Validation Loss: 0.0484, Accuracy: 98.83%, Precision: 100.00%, Recall: 98.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0282, Average Validation Loss: 0.0418, Accuracy: 98.92%, Precision: 100.00%, Recall: 98.14%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0426, Accuracy: 98.93%, Precision: 100.00%, Recall: 98.16%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0083, Average Validation Loss: 0.0421, Accuracy: 98.95%, Precision: 100.00%, Recall: 98.19%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0060, Average Validation Loss: 0.0344, Accuracy: 99.14%, Precision: 100.00%, Recall: 98.52%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0292, Average Validation Loss: 0.0249, Accuracy: 99.46%, Precision: 100.00%, Recall: 99.06%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0360, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0191, Average Validation Loss: 0.0352, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.60%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0131, Average Validation Loss: 0.0357, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0111, Average Validation Loss: 0.0391, Accuracy: 99.11%, Precision: 100.00%, Recall: 98.46%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0309, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 20:54:36,677] Trial 37 finished with value: 0.03089677331311061 and parameters: {'vector_length': 1024, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.30000000000000004, 'metadata_vector_length': 128, 'lr': 1.2095201014564198e-05, 'warmup_steps': 80}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 21, with 223,369,728 parameters\n","Num non-decayed parameter tensors: 37, with 112,898 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6257, Average Validation Loss: 0.3083, Accuracy: 90.78%, Precision: 92.55%, Recall: 91.44%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.5402, Average Validation Loss: 0.0201, Accuracy: 99.23%, Precision: 99.99%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0362, Average Validation Loss: 0.0162, Accuracy: 99.80%, Precision: 99.87%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0097, Average Validation Loss: 0.0078, Accuracy: 99.74%, Precision: 99.99%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0057, Accuracy: 99.80%, Precision: 99.99%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0024, Average Validation Loss: 0.0076, Accuracy: 99.75%, Precision: 99.99%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0048, Accuracy: 99.82%, Precision: 99.99%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0094, Average Validation Loss: 0.0043, Accuracy: 99.89%, Precision: 99.95%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0041, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0052, Average Validation Loss: 0.0034, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0077, Average Validation Loss: 0.0032, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0082, Average Validation Loss: 0.0035, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0057, Accuracy: 99.84%, Precision: 99.98%, Recall: 99.74%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0063, Average Validation Loss: 0.0077, Accuracy: 99.77%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0031, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0041, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:09:41,745] Trial 38 finished with value: 0.004071286491848327 and parameters: {'vector_length': 2048, 'num_blocks': 4, 'num_heads': 4, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 256, 'lr': 0.00042573863061243347, 'warmup_steps': 30}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 11,955,712 parameters\n","Num non-decayed parameter tensors: 21, with 15,362 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7179, Average Validation Loss: 0.6958, Accuracy: 57.24%, Precision: 99.74%, Recall: 57.24%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6761, Average Validation Loss: 0.6428, Accuracy: 57.71%, Precision: 99.94%, Recall: 57.50%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6116, Average Validation Loss: 0.5622, Accuracy: 84.74%, Precision: 99.77%, Recall: 79.04%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.5254, Average Validation Loss: 0.4590, Accuracy: 89.50%, Precision: 99.89%, Recall: 84.55%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.4130, Average Validation Loss: 0.3367, Accuracy: 94.30%, Precision: 99.91%, Recall: 91.01%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.2745, Average Validation Loss: 0.1698, Accuracy: 93.24%, Precision: 100.00%, Recall: 89.43%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.0779, Average Validation Loss: 0.0435, Accuracy: 98.77%, Precision: 100.00%, Recall: 97.90%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0427, Accuracy: 98.87%, Precision: 100.00%, Recall: 98.07%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0137, Average Validation Loss: 0.0234, Accuracy: 99.24%, Precision: 100.00%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0209, Accuracy: 99.35%, Precision: 100.00%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0069, Average Validation Loss: 0.0134, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0113, Average Validation Loss: 0.0120, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0079, Average Validation Loss: 0.0126, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0123, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0126, Average Validation Loss: 0.0089, Accuracy: 99.74%, Precision: 100.00%, Recall: 99.54%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0121, Average Validation Loss: 0.0095, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0084, Accuracy: 99.74%, Precision: 100.00%, Recall: 99.54%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0147, Average Validation Loss: 0.0077, Accuracy: 99.74%, Precision: 100.00%, Recall: 99.55%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0099, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0076, Average Validation Loss: 0.0079, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0064, Average Validation Loss: 0.0068, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0085, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0055, Average Validation Loss: 0.0075, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:12:40,778] Trial 39 finished with value: 0.00748719477182808 and parameters: {'vector_length': 512, 'num_blocks': 2, 'num_heads': 2, 'num_epochs': 5, 'dropout': 0.1, 'metadata_vector_length': 512, 'lr': 0.0001113579469686706, 'warmup_steps': 100}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 5,674,240 parameters\n","Num non-decayed parameter tensors: 29, with 12,802 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3645, Average Validation Loss: 0.0460, Accuracy: 99.21%, Precision: 99.79%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0215, Average Validation Loss: 0.0131, Accuracy: 99.58%, Precision: 99.88%, Recall: 99.39%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0116, Accuracy: 99.57%, Precision: 99.98%, Recall: 99.28%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0061, Accuracy: 99.78%, Precision: 99.67%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0027, Accuracy: 99.92%, Precision: 99.95%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0032, Accuracy: 99.87%, Precision: 99.98%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0038, Average Validation Loss: 0.0028, Accuracy: 99.88%, Precision: 99.98%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0019, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0034, Average Validation Loss: 0.0020, Accuracy: 99.94%, Precision: 99.92%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0014, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.97%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0014, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0013, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0007, Average Validation Loss: 0.0011, Accuracy: 99.96%, Precision: 99.99%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0010, Accuracy: 99.98%, Precision: 99.98%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0009, Accuracy: 99.98%, Precision: 99.98%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:14:27,885] Trial 40 finished with value: 0.0009370596355979246 and parameters: {'vector_length': 256, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.4, 'metadata_vector_length': 2048, 'lr': 0.0006581061058245171, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 5,674,240 parameters\n","Num non-decayed parameter tensors: 29, with 12,802 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3352, Average Validation Loss: 0.0335, Accuracy: 99.25%, Precision: 99.71%, Recall: 98.98%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0205, Average Validation Loss: 0.0122, Accuracy: 99.57%, Precision: 99.65%, Recall: 99.60%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0185, Average Validation Loss: 0.0080, Accuracy: 99.76%, Precision: 99.94%, Recall: 99.64%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0077, Accuracy: 99.72%, Precision: 99.99%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0088, Accuracy: 99.73%, Precision: 99.99%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0024, Accuracy: 99.89%, Precision: 99.98%, Recall: 99.83%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0014, Accuracy: 99.96%, Precision: 99.98%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0041, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0044, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0008, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0007, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0017, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.89%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:15:54,052] Trial 41 finished with value: 0.0016899517260947356 and parameters: {'vector_length': 256, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.4, 'metadata_vector_length': 2048, 'lr': 0.0007690184120508822, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 5,674,240 parameters\n","Num non-decayed parameter tensors: 29, with 12,802 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4831, Average Validation Loss: 0.1605, Accuracy: 98.68%, Precision: 99.10%, Recall: 98.59%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0838, Average Validation Loss: 0.0209, Accuracy: 99.45%, Precision: 99.80%, Recall: 99.25%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0134, Average Validation Loss: 0.0090, Accuracy: 99.69%, Precision: 99.79%, Recall: 99.66%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0085, Accuracy: 99.73%, Precision: 99.98%, Recall: 99.55%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0069, Accuracy: 99.78%, Precision: 99.98%, Recall: 99.64%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0059, Accuracy: 99.82%, Precision: 99.98%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0031, Average Validation Loss: 0.0031, Accuracy: 99.89%, Precision: 99.98%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0024, Accuracy: 99.92%, Precision: 99.96%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0030, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0036, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0035, Average Validation Loss: 0.0016, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.89%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0020, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0033, Accuracy: 99.87%, Precision: 100.00%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0024, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0020, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0006, Average Validation Loss: 0.0015, Accuracy: 99.93%, Precision: 100.00%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:17:48,382] Trial 42 finished with value: 0.0015073725292962547 and parameters: {'vector_length': 256, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.4, 'metadata_vector_length': 2048, 'lr': 0.0005576333260337576, 'warmup_steps': 20}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 5,674,240 parameters\n","Num non-decayed parameter tensors: 29, with 12,802 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5112, Average Validation Loss: 0.1973, Accuracy: 97.39%, Precision: 99.73%, Recall: 95.88%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0964, Average Validation Loss: 0.0423, Accuracy: 99.30%, Precision: 99.70%, Recall: 99.09%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0295, Average Validation Loss: 0.0200, Accuracy: 99.56%, Precision: 99.77%, Recall: 99.46%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0223, Average Validation Loss: 0.0216, Accuracy: 99.33%, Precision: 99.97%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0160, Average Validation Loss: 0.0115, Accuracy: 99.65%, Precision: 99.96%, Recall: 99.42%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0130, Average Validation Loss: 0.0089, Accuracy: 99.75%, Precision: 99.99%, Recall: 99.58%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0082, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0065, Accuracy: 99.78%, Precision: 100.00%, Recall: 99.61%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0050, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.66%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0050, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.66%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0040, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0038, Accuracy: 99.84%, Precision: 100.00%, Recall: 99.72%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0239, Average Validation Loss: 0.0027, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.82%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0046, Accuracy: 99.81%, Precision: 100.00%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0027, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0025, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0037, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0041, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:19:57,251] Trial 43 finished with value: 0.004060440648479286 and parameters: {'vector_length': 256, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 4, 'dropout': 0.4, 'metadata_vector_length': 2048, 'lr': 0.00022980180197131427, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 5,674,240 parameters\n","Num non-decayed parameter tensors: 29, with 12,802 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5350, Average Validation Loss: 0.3105, Accuracy: 92.37%, Precision: 99.99%, Recall: 88.24%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.1640, Average Validation Loss: 0.0610, Accuracy: 98.95%, Precision: 99.90%, Recall: 98.30%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0344, Average Validation Loss: 0.0169, Accuracy: 99.58%, Precision: 99.80%, Recall: 99.47%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0187, Average Validation Loss: 0.0298, Accuracy: 99.01%, Precision: 99.99%, Recall: 98.31%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0097, Average Validation Loss: 0.0069, Accuracy: 99.79%, Precision: 99.93%, Recall: 99.71%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0058, Accuracy: 99.83%, Precision: 99.98%, Recall: 99.73%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0095, Accuracy: 99.68%, Precision: 99.99%, Recall: 99.46%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0066, Accuracy: 99.78%, Precision: 99.99%, Recall: 99.63%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0044, Average Validation Loss: 0.0053, Accuracy: 99.84%, Precision: 99.99%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0048, Accuracy: 99.82%, Precision: 100.00%, Recall: 99.69%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0045, Accuracy: 99.84%, Precision: 100.00%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0039, Average Validation Loss: 0.0029, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0022, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0039, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0024, Average Validation Loss: 0.0093, Accuracy: 99.69%, Precision: 100.00%, Recall: 99.47%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0046, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0015, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0023, Accuracy: 99.89%, Precision: 100.00%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0014, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0014, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0036, Accuracy: 99.88%, Precision: 100.00%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0029, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:22:32,827] Trial 44 finished with value: 0.002938823606834646 and parameters: {'vector_length': 256, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 5, 'dropout': 0.5, 'metadata_vector_length': 2048, 'lr': 0.000416553869330564, 'warmup_steps': 30}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 2,116,224 parameters\n","Num non-decayed parameter tensors: 29, with 6,402 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7061, Average Validation Loss: 0.6701, Accuracy: 57.72%, Precision: 99.96%, Recall: 57.50%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6457, Average Validation Loss: 0.5735, Accuracy: 61.89%, Precision: 100.00%, Recall: 60.01%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5334, Average Validation Loss: 0.4652, Accuracy: 85.60%, Precision: 100.00%, Recall: 79.88%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.4284, Average Validation Loss: 0.3730, Accuracy: 94.42%, Precision: 99.96%, Recall: 91.14%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.3449, Average Validation Loss: 0.2997, Accuracy: 97.33%, Precision: 99.93%, Recall: 95.60%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2767, Average Validation Loss: 0.2448, Accuracy: 97.46%, Precision: 99.93%, Recall: 95.80%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2262, Average Validation Loss: 0.2003, Accuracy: 98.18%, Precision: 99.90%, Recall: 97.00%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1912, Average Validation Loss: 0.1682, Accuracy: 98.35%, Precision: 99.90%, Recall: 97.28%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1554, Average Validation Loss: 0.1416, Accuracy: 98.63%, Precision: 99.88%, Recall: 97.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1333, Average Validation Loss: 0.1194, Accuracy: 99.01%, Precision: 99.82%, Recall: 98.47%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1184, Average Validation Loss: 0.1039, Accuracy: 99.05%, Precision: 99.84%, Recall: 98.52%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1090, Average Validation Loss: 0.0901, Accuracy: 99.26%, Precision: 99.81%, Recall: 98.90%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0898, Average Validation Loss: 0.0806, Accuracy: 99.25%, Precision: 99.87%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0830, Average Validation Loss: 0.0733, Accuracy: 99.22%, Precision: 99.90%, Recall: 98.76%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0734, Average Validation Loss: 0.0641, Accuracy: 99.39%, Precision: 99.87%, Recall: 99.08%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0668, Average Validation Loss: 0.0580, Accuracy: 99.44%, Precision: 99.87%, Recall: 99.16%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0576, Average Validation Loss: 0.0551, Accuracy: 99.33%, Precision: 99.93%, Recall: 98.92%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0576, Average Validation Loss: 0.0514, Accuracy: 99.36%, Precision: 99.93%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0519, Average Validation Loss: 0.0464, Accuracy: 99.42%, Precision: 99.93%, Recall: 99.06%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0421, Average Validation Loss: 0.0432, Accuracy: 99.45%, Precision: 99.93%, Recall: 99.12%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0423, Average Validation Loss: 0.0406, Accuracy: 99.47%, Precision: 99.94%, Recall: 99.13%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0425, Average Validation Loss: 0.0393, Accuracy: 99.41%, Precision: 99.96%, Recall: 99.02%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0370, Average Validation Loss: 0.0386, Accuracy: 99.37%, Precision: 99.96%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0538, Average Validation Loss: 0.0352, Accuracy: 99.44%, Precision: 99.96%, Recall: 99.07%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0333, Average Validation Loss: 0.0316, Accuracy: 99.52%, Precision: 99.95%, Recall: 99.22%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0311, Average Validation Loss: 0.0284, Accuracy: 99.63%, Precision: 99.93%, Recall: 99.42%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0300, Average Validation Loss: 0.0269, Accuracy: 99.63%, Precision: 99.94%, Recall: 99.42%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0283, Average Validation Loss: 0.0265, Accuracy: 99.58%, Precision: 99.96%, Recall: 99.30%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0276, Average Validation Loss: 0.0250, Accuracy: 99.61%, Precision: 99.97%, Recall: 99.36%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0253, Average Validation Loss: 0.0228, Accuracy: 99.66%, Precision: 99.95%, Recall: 99.46%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0246, Average Validation Loss: 0.0229, Accuracy: 99.63%, Precision: 99.97%, Recall: 99.38%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0215, Accuracy: 99.65%, Precision: 99.97%, Recall: 99.42%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0201, Average Validation Loss: 0.0214, Accuracy: 99.62%, Precision: 99.98%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0208, Average Validation Loss: 0.0198, Accuracy: 99.65%, Precision: 99.98%, Recall: 99.42%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0230, Average Validation Loss: 0.0197, Accuracy: 99.64%, Precision: 99.98%, Recall: 99.40%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0175, Average Validation Loss: 0.0203, Accuracy: 99.58%, Precision: 99.98%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0184, Average Validation Loss: 0.0177, Accuracy: 99.67%, Precision: 99.98%, Recall: 99.45%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0168, Average Validation Loss: 0.0164, Accuracy: 99.70%, Precision: 99.98%, Recall: 99.50%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0169, Average Validation Loss: 0.0159, Accuracy: 99.70%, Precision: 99.98%, Recall: 99.51%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0161, Accuracy: 99.67%, Precision: 99.98%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0131, Average Validation Loss: 0.0164, Accuracy: 99.64%, Precision: 99.99%, Recall: 99.38%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0167, Accuracy: 99.63%, Precision: 99.99%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0130, Average Validation Loss: 0.0150, Accuracy: 99.66%, Precision: 99.99%, Recall: 99.43%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0127, Average Validation Loss: 0.0155, Accuracy: 99.64%, Precision: 99.99%, Recall: 99.38%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0152, Average Validation Loss: 0.0150, Accuracy: 99.63%, Precision: 99.99%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0126, Average Validation Loss: 0.0134, Accuracy: 99.68%, Precision: 99.99%, Recall: 99.45%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0117, Average Validation Loss: 0.0130, Accuracy: 99.69%, Precision: 99.99%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0110, Average Validation Loss: 0.0121, Accuracy: 99.71%, Precision: 99.99%, Recall: 99.51%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0121, Average Validation Loss: 0.0132, Accuracy: 99.66%, Precision: 99.99%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0099, Average Validation Loss: 0.0149, Accuracy: 99.61%, Precision: 99.99%, Recall: 99.33%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0078, Average Validation Loss: 0.0153, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.32%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0064, Average Validation Loss: 0.0154, Accuracy: 99.59%, Precision: 100.00%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0152, Accuracy: 99.60%, Precision: 100.00%, Recall: 99.30%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:28:04,059] Trial 45 finished with value: 0.015225586390777214 and parameters: {'vector_length': 128, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 3, 'dropout': 0.4, 'metadata_vector_length': 1024, 'lr': 5.3792216695173005e-05, 'warmup_steps': 20}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 21, with 5,912,320 parameters\n","Num non-decayed parameter tensors: 37, with 14,338 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6221, Average Validation Loss: 0.4950, Accuracy: 68.32%, Precision: 100.00%, Recall: 64.35%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.3640, Average Validation Loss: 0.2200, Accuracy: 97.70%, Precision: 99.12%, Recall: 96.93%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1679, Average Validation Loss: 0.1015, Accuracy: 96.51%, Precision: 99.99%, Recall: 94.25%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.0556, Average Validation Loss: 0.0121, Accuracy: 99.55%, Precision: 100.00%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0126, Average Validation Loss: 0.0139, Accuracy: 99.40%, Precision: 100.00%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0149, Accuracy: 99.36%, Precision: 100.00%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0118, Accuracy: 99.51%, Precision: 100.00%, Recall: 99.15%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0098, Average Validation Loss: 0.0149, Accuracy: 99.38%, Precision: 100.00%, Recall: 98.92%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0128, Average Validation Loss: 0.0077, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.58%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0121, Average Validation Loss: 0.0104, Accuracy: 99.59%, Precision: 100.00%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0147, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.94%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0129, Average Validation Loss: 0.0063, Accuracy: 99.82%, Precision: 99.99%, Recall: 99.70%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0110, Average Validation Loss: 0.0075, Accuracy: 99.72%, Precision: 100.00%, Recall: 99.51%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0038, Average Validation Loss: 0.0071, Accuracy: 99.72%, Precision: 100.00%, Recall: 99.52%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0096, Average Validation Loss: 0.0052, Accuracy: 99.82%, Precision: 99.99%, Recall: 99.70%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0057, Accuracy: 99.79%, Precision: 100.00%, Recall: 99.63%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0049, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0049, Accuracy: 99.81%, Precision: 100.00%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0067, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0060, Average Validation Loss: 0.0042, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0051, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0072, Average Validation Loss: 0.0045, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0050, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0051, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0039, Accuracy: 99.86%, Precision: 99.99%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:31:43,093] Trial 46 finished with value: 0.003932254873467861 and parameters: {'vector_length': 256, 'num_blocks': 4, 'num_heads': 8, 'num_epochs': 4, 'dropout': 0.1, 'metadata_vector_length': 256, 'lr': 0.000323454139414175, 'warmup_steps': 10}. Best is trial 24 with value: 0.0007377692726672772.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 173,575,168 parameters\n","Num non-decayed parameter tensors: 29, with 86,530 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5587, Average Validation Loss: 0.4361, Accuracy: 76.39%, Precision: 58.98%, Recall: 99.55%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.3460, Average Validation Loss: 0.0234, Accuracy: 99.74%, Precision: 99.81%, Recall: 99.73%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.1095, Average Validation Loss: 0.0129, Accuracy: 99.50%, Precision: 100.00%, Recall: 99.13%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0167, Average Validation Loss: 0.0086, Accuracy: 99.78%, Precision: 99.96%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0067, Average Validation Loss: 0.0053, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.71%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0086, Average Validation Loss: 0.0059, Accuracy: 99.86%, Precision: 99.96%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0042, Accuracy: 99.92%, Precision: 99.93%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0099, Average Validation Loss: 0.0030, Accuracy: 99.95%, Precision: 99.95%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0067, Accuracy: 99.83%, Precision: 99.73%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0065, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0017, Accuracy: 99.93%, Precision: 99.97%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0017, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.89%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0011, Accuracy: 99.95%, Precision: 100.00%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0007, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0006, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0006, Accuracy: 99.99%, Precision: 100.00%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0010, Accuracy: 99.96%, Precision: 100.00%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0010, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0013, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0007, Accuracy: 99.98%, Precision: 100.00%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:46:13,306] Trial 47 finished with value: 0.000648165629753306 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 4, 'num_epochs': 4, 'dropout': 0.30000000000000004, 'metadata_vector_length': 512, 'lr': 0.000804319149011216, 'warmup_steps': 80}. Best is trial 47 with value: 0.000648165629753306.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 13, with 126,466,048 parameters\n","Num non-decayed parameter tensors: 21, with 61,442 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6740, Average Validation Loss: 0.6651, Accuracy: 63.96%, Precision: 98.79%, Recall: 61.52%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6641, Average Validation Loss: 0.6437, Accuracy: 57.75%, Precision: 99.94%, Recall: 57.52%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6307, Average Validation Loss: 0.6187, Accuracy: 57.94%, Precision: 99.96%, Recall: 57.63%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.5956, Average Validation Loss: 0.5695, Accuracy: 63.70%, Precision: 99.97%, Recall: 61.17%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5536, Average Validation Loss: 0.5177, Accuracy: 91.97%, Precision: 99.96%, Recall: 87.71%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.5014, Average Validation Loss: 0.4603, Accuracy: 91.75%, Precision: 99.98%, Recall: 87.40%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.4486, Average Validation Loss: 0.4018, Accuracy: 92.37%, Precision: 99.97%, Recall: 88.24%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.3875, Average Validation Loss: 0.3410, Accuracy: 95.05%, Precision: 99.97%, Recall: 92.06%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3279, Average Validation Loss: 0.2833, Accuracy: 95.78%, Precision: 99.94%, Recall: 93.18%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2762, Average Validation Loss: 0.2288, Accuracy: 95.48%, Precision: 99.99%, Recall: 92.69%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2244, Average Validation Loss: 0.2134, Accuracy: 88.68%, Precision: 99.99%, Recall: 83.48%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.1571, Average Validation Loss: 0.2720, Accuracy: 84.21%, Precision: 99.99%, Recall: 78.37%, F1: 0.88\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0788, Average Validation Loss: 0.1530, Accuracy: 95.47%, Precision: 99.99%, Recall: 92.67%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.0317, Average Validation Loss: 0.1174, Accuracy: 98.22%, Precision: 100.00%, Recall: 96.99%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0253, Average Validation Loss: 0.0831, Accuracy: 98.66%, Precision: 99.99%, Recall: 97.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0290, Average Validation Loss: 0.0930, Accuracy: 98.66%, Precision: 100.00%, Recall: 97.71%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0296, Average Validation Loss: 0.0822, Accuracy: 98.68%, Precision: 100.00%, Recall: 97.74%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0254, Average Validation Loss: 0.0970, Accuracy: 98.66%, Precision: 100.00%, Recall: 97.71%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0307, Average Validation Loss: 0.0801, Accuracy: 98.68%, Precision: 100.00%, Recall: 97.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0216, Average Validation Loss: 0.0943, Accuracy: 98.66%, Precision: 100.00%, Recall: 97.71%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0305, Average Validation Loss: 0.0720, Accuracy: 98.70%, Precision: 100.00%, Recall: 97.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0188, Average Validation Loss: 0.1077, Accuracy: 98.63%, Precision: 100.00%, Recall: 97.66%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0211, Average Validation Loss: 0.0865, Accuracy: 98.67%, Precision: 100.00%, Recall: 97.72%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0143, Average Validation Loss: 0.0895, Accuracy: 98.67%, Precision: 100.00%, Recall: 97.72%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0192, Average Validation Loss: 0.0855, Accuracy: 98.68%, Precision: 100.00%, Recall: 97.74%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0814, Accuracy: 98.69%, Precision: 100.00%, Recall: 97.75%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 21:59:23,299] Trial 48 finished with value: 0.08234018539959514 and parameters: {'vector_length': 2048, 'num_blocks': 2, 'num_heads': 2, 'num_epochs': 2, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 4.778453265136939e-06, 'warmup_steps': 80}. Best is trial 47 with value: 0.000648165629753306.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 17, with 172,769,536 parameters\n","Num non-decayed parameter tensors: 29, with 86,146 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6627, Average Validation Loss: 0.6202, Accuracy: 84.05%, Precision: 95.91%, Recall: 80.12%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.5726, Average Validation Loss: 0.5037, Accuracy: 72.21%, Precision: 100.00%, Recall: 67.30%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.2149, Average Validation Loss: 0.0385, Accuracy: 99.10%, Precision: 100.00%, Recall: 98.45%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1729, Average Validation Loss: 0.1724, Accuracy: 98.57%, Precision: 100.00%, Recall: 97.56%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0448, Average Validation Loss: 0.0570, Accuracy: 98.87%, Precision: 100.00%, Recall: 98.07%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0445, Average Validation Loss: 0.0197, Accuracy: 99.71%, Precision: 99.99%, Recall: 99.51%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0324, Average Validation Loss: 0.0173, Accuracy: 99.55%, Precision: 100.00%, Recall: 99.23%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0157, Accuracy: 99.73%, Precision: 100.00%, Recall: 99.53%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0196, Average Validation Loss: 0.0170, Accuracy: 99.69%, Precision: 100.00%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0139, Average Validation Loss: 0.0131, Accuracy: 99.70%, Precision: 99.99%, Recall: 99.48%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0148, Average Validation Loss: 0.0128, Accuracy: 99.70%, Precision: 100.00%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0099, Average Validation Loss: 0.0188, Accuracy: 99.36%, Precision: 99.15%, Recall: 99.74%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0107, Accuracy: 99.71%, Precision: 100.00%, Recall: 99.49%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0139, Average Validation Loss: 0.0119, Accuracy: 99.82%, Precision: 99.99%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0091, Accuracy: 99.70%, Precision: 100.00%, Recall: 99.48%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0137, Average Validation Loss: 0.0094, Accuracy: 99.68%, Precision: 100.00%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0141, Average Validation Loss: 0.0087, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0114, Average Validation Loss: 0.0089, Accuracy: 99.78%, Precision: 100.00%, Recall: 99.61%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0089, Average Validation Loss: 0.0087, Accuracy: 99.71%, Precision: 100.00%, Recall: 99.50%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0052, Average Validation Loss: 0.0078, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0131, Average Validation Loss: 0.0065, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.65%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0065, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0077, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0066, Accuracy: 99.84%, Precision: 99.98%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0087, Average Validation Loss: 0.0062, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0086, Average Validation Loss: 0.0057, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-06 22:18:01,927] Trial 49 finished with value: 0.005707956758025732 and parameters: {'vector_length': 2048, 'num_blocks': 3, 'num_heads': 2, 'num_epochs': 3, 'dropout': 0.2, 'metadata_vector_length': 128, 'lr': 0.00015869403923899134, 'warmup_steps': 90}. Best is trial 47 with value: 0.000648165629753306.\n"]},{"name":"stdout","output_type":"stream","text":["Best hyperparameters:\n","vector_length: 2048\n","num_blocks: 3\n","num_heads: 4\n","num_epochs: 4\n","dropout: 0.30000000000000004\n","metadata_vector_length: 512\n","lr: 0.000804319149011216\n","warmup_steps: 80\n"]}],"source":["# Create an Optuna study\n","study = optuna.create_study(direction=\"minimize\")\n","\n","# Run the optimization\n","study.optimize(objective, n_trials=50)\n","\n","# Print the best hyperparameters\n","print(\"Best hyperparameters:\")\n","for key, value in study.best_params.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","source":["vector_length = 2048\n","num_blocks = 3\n","num_heads = 4\n","num_epochs = 4\n","dropout = 0.3\n","metadata_vector_length = 512\n","lr = 0.000804319149011216\n","warmup_steps = 80\n","\n","scheduler_config = {\"warmup_steps\": warmup_steps,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": lr,\n","                    \"min_lr\": lr * 0.1}"],"metadata":{"id":"QmSNUtR6VFfR","executionInfo":{"status":"ok","timestamp":1733602915695,"user_tz":-240,"elapsed":1,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"s285dUyEs6Q5","executionInfo":{"status":"ok","timestamp":1733602922811,"user_tz":-240,"elapsed":7117,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["model = Transformer(\n","    vocab_size=10240,                    # Vocabulary size\n","    vector_length=vector_length,              # Embedding size\n","    context_size=max_context_size,            # Maximum context size for input sequences\n","    num_blocks=num_blocks,                    # Number of transformer blocks\n","    num_heads=num_heads,                      # Number of attention heads\n","    dropout=dropout,                          # Dropout rate\n","    padding_idx=tokenizer.padding_idx,        # Padding token index (from tokenizer)\n","    num_metadata_features=num_metadata_features,  # Metadata feature count\n","    metadata_vector_length=metadata_vector_length,  # Metadata vector size\n","    num_classes=2                   # Number of output classes\n",").to(device)  # Send model to the appropriate device\n","model = torch.compile(model)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"smlEHr0n4p2p","outputId":"6675f4c8-b9b8-4103-a79e-5275c4b93378","executionInfo":{"status":"ok","timestamp":1733604588311,"user_tz":-240,"elapsed":1665502,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 17, with 173,575,168 parameters\n","Num non-decayed parameter tensors: 29, with 86,530 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5722, Average Validation Loss: 0.8590, Accuracy: 67.10%, Precision: 99.99%, Recall: 63.48%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5317, Average Validation Loss: 0.0458, Accuracy: 99.80%, Precision: 99.93%, Recall: 99.72%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0345, Average Validation Loss: 0.0165, Accuracy: 99.37%, Precision: 100.00%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0097, Average Validation Loss: 0.0190, Accuracy: 99.37%, Precision: 100.00%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0067, Average Validation Loss: 0.0098, Accuracy: 99.64%, Precision: 100.00%, Recall: 99.37%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0102, Average Validation Loss: 0.0043, Accuracy: 99.84%, Precision: 99.98%, Recall: 99.75%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0048, Average Validation Loss: 0.0029, Accuracy: 99.94%, Precision: 99.97%, Recall: 99.92%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0025, Accuracy: 99.94%, Precision: 99.98%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0046, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0033, Average Validation Loss: 0.0064, Accuracy: 99.81%, Precision: 100.00%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0119, Average Validation Loss: 0.0057, Accuracy: 99.86%, Precision: 99.78%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0044, Average Validation Loss: 0.0022, Accuracy: 99.92%, Precision: 99.96%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0021, Accuracy: 99.94%, Precision: 99.94%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0037, Accuracy: 99.88%, Precision: 100.00%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0094, Average Validation Loss: 0.0026, Accuracy: 99.91%, Precision: 100.00%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0015, Accuracy: 99.96%, Precision: 99.96%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0048, Average Validation Loss: 0.0012, Accuracy: 99.96%, Precision: 100.00%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0011, Accuracy: 99.97%, Precision: 100.00%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0007, Average Validation Loss: 0.0012, Accuracy: 99.96%, Precision: 100.00%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0009, Accuracy: 99.97%, Precision: 100.00%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0009, Accuracy: 99.96%, Precision: 99.99%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0014, Accuracy: 99.94%, Precision: 99.97%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0006, Average Validation Loss: 0.0020, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0013, Accuracy: 99.94%, Precision: 99.97%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0011, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0013, Accuracy: 99.93%, Precision: 100.00%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 6 step(s).\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0012, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 7 step(s).\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0006, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0013, Accuracy: 99.96%, Precision: 99.94%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0007, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0014, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0007, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0014, Accuracy: 99.93%, Precision: 100.00%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0020, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 6 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0021, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 7 step(s).\n","Epoch 0, Average Training Loss: 0.0078, Average Validation Loss: 0.0038, Accuracy: 99.86%, Precision: 99.76%, Recall: 100.00%, F1: 1.00\n","No significant improvement in validation loss for 8 step(s).\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0009, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 9 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0020, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 10 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 10 steps.\n"]}],"source":["optimizer = model.configure_optimizers(weight_decay=0.01, learning_rate=max_lr, device_type=device) # torch.optim.AdamW(model.parameters(), lr=max_lr)\n","\n","model = train_model(model, train_loader, val_loader, num_epochs=num_epochs, optimizer=optimizer, device=device, fp16=True, scheduler_config=scheduler_config, log_interval=10, early_stopping=True, patience=10, improvement_threshold=0.0001)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Kun0xTY3Oud1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733604636026,"user_tz":-240,"elapsed":47717,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}},"outputId":"4e38aad8-414a-4c5c-f312-22460253a6b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Final Test Loss: 0.0058\n","Final Accuracy: 99.90%\n","Precision: 1.00\n","Recall: 1.00\n","F1 Score: 1.00\n"]}],"source":["test_results = run_inference_and_collect_results(model, test_loader, device, fp16=True)\n","test_loss = test_model(model, test_loader, device, fp16=False)\n","\n","accuracy = accuracy_score(test_results['Predicted Outputs'], test_results['True Labels']) * 100\n","precision = precision_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","recall = recall_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","f1 = f1_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","\n","print(f'Final Test Loss: {test_loss:.4f}')\n","print(f\"Final Accuracy: {accuracy:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"gHGB2OmuDvgw","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1733604677827,"user_tz":-240,"elapsed":41803,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}},"outputId":"c6ac5da5-b6fd-4c86-eae9-71efebd19cc0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["The Area Under Curve (AUC) is: 1.00\n"]}],"source":["auc = calculate_auc_roc(model, test_loader, device)\n","plot_confusion_matrix(model, test_loader, device)\n","print(f'The Area Under Curve (AUC) is: {auc:.2f}')"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"AQeLMjnPE3AA","executionInfo":{"status":"ok","timestamp":1733604696529,"user_tz":-240,"elapsed":18704,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["adversarial_tokenized_dataset = load_from_disk(path+\"Datasets/TransformedDataset/\")\n","\n","adversarial_train_dataset = adversarial_tokenized_dataset['train']\n","adversarial_val_dataset = adversarial_tokenized_dataset['validation']\n","adversarial_test_dataset = adversarial_tokenized_dataset['test']\n","\n","batch_size = 128\n","\n","# Prepare dataloaders for batching the data during training and evaluation\n","adversarial_train_loader = DataLoader(adversarial_train_dataset, batch_size=batch_size, shuffle=True)\n","adversarial_val_loader = DataLoader(adversarial_val_dataset, batch_size=batch_size, shuffle=True)\n","adversarial_test_loader = DataLoader(adversarial_test_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"527ilmeFKzUm","executionInfo":{"status":"ok","timestamp":1733604803414,"user_tz":-240,"elapsed":106886,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}}},"outputs":[],"source":["adversarial_losses = test_model_adversarial(model, adversarial_test_loader, device, fp16=True)\n","adversarial_results = run_inference_and_collect_results_adversarial(model, adversarial_test_loader, device, fp16=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"QMHU93MYR6D9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733604803414,"user_tz":-240,"elapsed":7,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}},"outputId":"f93f0119-3e84-4f16-b68f-1692217e7af2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adversarial Losses:\n","Original Loss: 0.0058\n","Similar Characters Loss: 0.0104\n","Case Symbols Loss: 0.0056\n","Unicode Replacement Loss: 0.0162\n","\n","Results for Original Inputs:\n","  Accuracy: 99.90%\n","  Precision: 1.00\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n","Results for Similar Inputs:\n","  Accuracy: 99.73%\n","  Precision: 1.00\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n","Results for Case symbols Inputs:\n","  Accuracy: 99.89%\n","  Precision: 1.00\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n","Results for Unicode Inputs:\n","  Accuracy: 99.50%\n","  Precision: 0.99\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n"]}],"source":["print(\"Adversarial Losses:\")\n","print(f\"Original Loss: {adversarial_losses['original_loss']:.4f}\")\n","print(f\"Similar Characters Loss: {adversarial_losses['similar_loss']:.4f}\")\n","print(f\"Case Symbols Loss: {adversarial_losses['case_symbols_loss']:.4f}\")\n","print(f\"Unicode Replacement Loss: {adversarial_losses['unicode_loss']:.4f}\\n\")\n","\n","# Evaluate metrics for each type\n","for key in adversarial_results:\n","    predictions = adversarial_results[key][\"predictions\"]\n","    labels = adversarial_results[key][\"labels\"]\n","\n","    accuracy = accuracy_score(labels, predictions) * 100\n","    precision = precision_score(labels, predictions)\n","    recall = recall_score(labels, predictions)\n","    f1 = f1_score(labels, predictions)\n","\n","    print(f\"Results for {key.capitalize()} Inputs:\")\n","    print(f\"  Accuracy: {accuracy:.2f}%\")\n","    print(f\"  Precision: {precision:.2f}\")\n","    print(f\"  Recall: {recall:.2f}\")\n","    print(f\"  F1 Score: {f1:.2f}\")\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Am2bN2givqYG"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}