{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17996,"status":"ok","timestamp":1733596494182,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"cNHp-qi0iO-b","outputId":"15c1455b-0d17-43a5-d788-49bee9940210"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/364.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/364.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/364.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m358.4/364.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/233.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install optuna -q\n","!pip install --upgrade datasets -q\n","!pip install --upgrade triton -q"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24367,"status":"ok","timestamp":1733596518542,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"6MsVjKl7huMh","outputId":"317ff8a1-2409-4e71-a2cd-c6933806b0b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') # mounting drive where files are stored"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IkmIgn4QEt86"},"outputs":[],"source":["import sys\n","path = \"/content/drive/MyDrive/AI_Cybersecurity/Project/\"\n","sys.path.append(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CLBHtY71hlUj"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F # loading libraries\n","from sklearn.datasets import load_iris\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import optuna\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset, DatasetDict, load_from_disk\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import roc_curve, auc\n","from contextlib import nullcontext\n","from utils import BPE_Tokenizer, LSTM_model, train_model, test_model, run_inference_and_collect_results, calculate_auc_roc, plot_confusion_matrix, test_model_adversarial, run_inference_and_collect_results_adversarial, multiples_of_two"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PRi6tZmEzEa6"},"outputs":[],"source":["torch.set_float32_matmul_precision('high')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2783,"status":"ok","timestamp":1733596531059,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"3WlYkCSQvBDQ","outputId":"e1d26ccf-7c7f-416a-d21e-7b7a30529364"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size is 10007\n"]}],"source":["tokenizer = BPE_Tokenizer(directory=path+'Tokenizer')\n","vocab = tokenizer.vocab\n","vocab_size = len(vocab) + 1\n","print(\"Vocab size is\", vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBTLpoNqEir8"},"outputs":[],"source":["tokenized_dataset = load_from_disk(path+\"Datasets/FinalDataset/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQOhXEj-zSiM"},"outputs":[],"source":["train_dataset = tokenized_dataset['train']\n","val_dataset = tokenized_dataset['validation']\n","test_dataset = tokenized_dataset['test']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsFSGRx9zU_R"},"outputs":[],"source":["batch_size = 128\n","\n","# Prepare dataloaders for batching the data during training and evaluation\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qb_t-4L44G6V"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","vector_length = 1024\n","hidden_length = 1024\n","num_layers = 2\n","dropout = 0.2\n","metadata_vector_length = 1024\n","num_metadata_features = len(train_dataset['metadata'][0])\n","num_epochs = 1\n","max_lr = 2e-4\n","scheduler_config = {\"warmup_steps\": 5,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": max_lr,\n","                    \"min_lr\": max_lr * 0.1}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48150,"status":"ok","timestamp":1733596600881,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"HyeHO1bs3qvb","outputId":"bebf2ebe-f4f4-4e0a-a603-9a089d64b43d"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([128, 2])\n","Initial Training Loss 0.6999\n"]}],"source":["# Initialize the model for binary classification of class 0\n","model = LSTM_model(vocab_size, vector_length, hidden_length, num_layers, dropout, num_metadata_features, metadata_vector_length).to(device)\n","\n","# Test the model with the initial untrained state and compute training loss\n","for batch in train_loader:\n","    inputs = batch[\"input_ids\"].to(device)\n","    attention_mask = batch[\"attention_mask\"].to(device)\n","    metadata = batch[\"metadata\"].to(device)\n","    labels = batch[\"label\"].to(device)\n","    logits, _ = model(inputs, attention_mask, metadata, labels)  # Forward pass through the model\n","    print(logits.shape)\n","    break\n","\n","torch.cuda.empty_cache()\n","\n","loss = test_model(model, train_loader, fp16=True, device=\"cuda\")  # Compute the loss on the training dataset\n","print(f\"Initial Training Loss {loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxaqmsgrWvra"},"outputs":[],"source":["def objective(trial):\n","    # Define hyperparameters to optimize\n","    vector_length = trial.suggest_categorical(\"vector_length\", multiples_of_two(128, 2048))\n","    hidden_length = trial.suggest_categorical(\"hidden_length\", multiples_of_two(128, 2048))\n","    num_layers = trial.suggest_int(\"num_layers\", 2, 5)\n","    num_epochs = trial.suggest_int(\"num_epochs\", 1, 5)\n","    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n","    metadata_vector_length = trial.suggest_categorical(\"metadata_vector_length\", multiples_of_two(128, 2048))\n","    lr = trial.suggest_float(\"lr\", 1e-6, 1e-2, log=True)\n","    warmup_steps = trial.suggest_int(\"warmup_steps\", 10, 100, step=10)\n","\n","    # Create the model\n","    model = LSTM_model(\n","        vocab_size=10240,\n","        vector_length=vector_length,\n","        hidden_length=hidden_length,\n","        num_layers=num_layers,\n","        dropout=dropout,\n","        padding_idx=tokenizer.padding_idx,\n","        num_metadata_features=num_metadata_features,\n","        metadata_vector_length=metadata_vector_length,\n","        num_classes=2\n","    ).to(device)\n","    model = torch.compile(model)\n","\n","    # Optimizer\n","    optimizer = model.configure_optimizers(weight_decay=0.01, learning_rate=lr, device_type=device)\n","\n","    scheduler_config = {\"warmup_steps\": warmup_steps,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": lr,\n","                    \"min_lr\": lr * 0.1}\n","\n","    # Train the model\n","    model = train_model(\n","        model=model,\n","        train_dataloader=train_loader,\n","        val_dataloader=val_loader,\n","        num_epochs=num_epochs,\n","        optimizer=optimizer,\n","        device=device,\n","        fp16=True,\n","        scheduler_config=scheduler_config,\n","        log_interval=10,\n","        early_stopping=True,\n","    )\n","\n","    # Evaluate on the validation set\n","    val_loss = test_model(model, val_loader, device, fp16=True)\n","\n","    # Return the validation loss as the objective to minimize\n","    return val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"z-sWVWASYNVB","outputId":"6297e525-3606-4b54-a65a-b50b3ea257f1"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 11:43:40,660] A new study created in memory with name: no-name-7753434d-ebb1-4927-9844-bd480664fed4\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 20, with 25,220,352 parameters\n","Num non-decayed parameter tensors: 19, with 34,306 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7004, Average Validation Loss: 0.6991, Accuracy: 49.08%, Precision: 83.74%, Recall: 53.50%, F1: 0.65\n","Epoch 0, Average Training Loss: 0.6978, Average Validation Loss: 0.6977, Accuracy: 51.61%, Precision: 88.06%, Recall: 54.78%, F1: 0.68\n","Epoch 0, Average Training Loss: 0.6957, Average Validation Loss: 0.6954, Accuracy: 54.51%, Precision: 92.96%, Recall: 56.18%, F1: 0.70\n","Epoch 0, Average Training Loss: 0.6948, Average Validation Loss: 0.6923, Accuracy: 56.94%, Precision: 96.68%, Recall: 57.33%, F1: 0.72\n","Epoch 0, Average Training Loss: 0.6913, Average Validation Loss: 0.6888, Accuracy: 58.52%, Precision: 98.58%, Recall: 58.10%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6865, Average Validation Loss: 0.6852, Accuracy: 59.44%, Precision: 99.34%, Recall: 58.57%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6840, Average Validation Loss: 0.6817, Accuracy: 60.35%, Precision: 99.62%, Recall: 59.10%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6802, Average Validation Loss: 0.6782, Accuracy: 61.30%, Precision: 99.81%, Recall: 59.66%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6776, Average Validation Loss: 0.6748, Accuracy: 62.34%, Precision: 99.90%, Recall: 60.31%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6729, Average Validation Loss: 0.6713, Accuracy: 63.16%, Precision: 99.96%, Recall: 60.83%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6685, Average Validation Loss: 0.6678, Accuracy: 64.07%, Precision: 99.99%, Recall: 61.42%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6662, Average Validation Loss: 0.6643, Accuracy: 64.92%, Precision: 99.99%, Recall: 61.98%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.6589, Average Validation Loss: 0.6607, Accuracy: 65.47%, Precision: 99.99%, Recall: 62.35%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.6621, Average Validation Loss: 0.6573, Accuracy: 66.34%, Precision: 99.99%, Recall: 62.95%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.6559, Average Validation Loss: 0.6539, Accuracy: 67.22%, Precision: 99.99%, Recall: 63.56%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.6522, Average Validation Loss: 0.6504, Accuracy: 68.08%, Precision: 99.99%, Recall: 64.18%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.6469, Average Validation Loss: 0.6470, Accuracy: 68.37%, Precision: 99.99%, Recall: 64.39%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.6448, Average Validation Loss: 0.6435, Accuracy: 69.11%, Precision: 99.99%, Recall: 64.93%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.6404, Average Validation Loss: 0.6401, Accuracy: 69.58%, Precision: 100.00%, Recall: 65.28%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.6357, Average Validation Loss: 0.6367, Accuracy: 70.06%, Precision: 100.00%, Recall: 65.64%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.6338, Average Validation Loss: 0.6332, Accuracy: 70.47%, Precision: 100.00%, Recall: 65.94%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.6342, Average Validation Loss: 0.6297, Accuracy: 71.08%, Precision: 100.00%, Recall: 66.42%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.6287, Average Validation Loss: 0.6262, Accuracy: 71.83%, Precision: 100.00%, Recall: 67.00%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.6218, Average Validation Loss: 0.6228, Accuracy: 72.70%, Precision: 100.00%, Recall: 67.69%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.6173, Average Validation Loss: 0.6191, Accuracy: 72.58%, Precision: 100.00%, Recall: 67.59%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.6191, Average Validation Loss: 0.6154, Accuracy: 72.46%, Precision: 100.00%, Recall: 67.50%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.6184, Average Validation Loss: 0.6122, Accuracy: 73.17%, Precision: 100.00%, Recall: 68.06%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.6095, Average Validation Loss: 0.6082, Accuracy: 73.97%, Precision: 100.00%, Recall: 68.72%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.6075, Average Validation Loss: 0.6050, Accuracy: 74.29%, Precision: 100.00%, Recall: 68.99%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.6050, Average Validation Loss: 0.6011, Accuracy: 74.66%, Precision: 100.00%, Recall: 69.30%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.6023, Average Validation Loss: 0.5973, Accuracy: 74.91%, Precision: 100.00%, Recall: 69.51%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5991, Average Validation Loss: 0.5938, Accuracy: 75.20%, Precision: 100.00%, Recall: 69.75%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5896, Average Validation Loss: 0.5897, Accuracy: 74.85%, Precision: 100.00%, Recall: 69.45%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5895, Average Validation Loss: 0.5860, Accuracy: 74.57%, Precision: 100.00%, Recall: 69.22%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5802, Average Validation Loss: 0.5818, Accuracy: 74.46%, Precision: 100.00%, Recall: 69.13%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5863, Average Validation Loss: 0.5776, Accuracy: 74.57%, Precision: 100.00%, Recall: 69.22%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5749, Average Validation Loss: 0.5738, Accuracy: 74.77%, Precision: 100.00%, Recall: 69.39%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5712, Average Validation Loss: 0.5695, Accuracy: 74.60%, Precision: 100.00%, Recall: 69.25%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5642, Average Validation Loss: 0.5650, Accuracy: 74.48%, Precision: 100.00%, Recall: 69.15%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5621, Average Validation Loss: 0.5605, Accuracy: 74.27%, Precision: 100.00%, Recall: 68.97%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5589, Average Validation Loss: 0.5564, Accuracy: 74.15%, Precision: 100.00%, Recall: 68.87%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5611, Average Validation Loss: 0.5518, Accuracy: 74.52%, Precision: 100.00%, Recall: 69.18%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5544, Average Validation Loss: 0.5473, Accuracy: 74.72%, Precision: 100.00%, Recall: 69.35%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5487, Average Validation Loss: 0.5424, Accuracy: 74.85%, Precision: 100.00%, Recall: 69.46%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5411, Average Validation Loss: 0.5381, Accuracy: 75.01%, Precision: 100.00%, Recall: 69.59%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5329, Average Validation Loss: 0.5329, Accuracy: 74.73%, Precision: 100.00%, Recall: 69.36%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5328, Average Validation Loss: 0.5278, Accuracy: 74.83%, Precision: 100.00%, Recall: 69.44%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5234, Average Validation Loss: 0.5225, Accuracy: 75.23%, Precision: 100.00%, Recall: 69.78%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5208, Average Validation Loss: 0.5177, Accuracy: 75.25%, Precision: 100.00%, Recall: 69.79%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5091, Average Validation Loss: 0.5126, Accuracy: 75.30%, Precision: 100.00%, Recall: 69.83%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5161, Average Validation Loss: 0.5069, Accuracy: 76.05%, Precision: 100.00%, Recall: 70.48%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.4982, Average Validation Loss: 0.5013, Accuracy: 76.69%, Precision: 100.00%, Recall: 71.04%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.4958, Average Validation Loss: 0.4953, Accuracy: 77.02%, Precision: 100.00%, Recall: 71.34%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.4821, Average Validation Loss: 0.4900, Accuracy: 77.41%, Precision: 100.00%, Recall: 71.68%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.4928, Average Validation Loss: 0.4837, Accuracy: 78.32%, Precision: 100.00%, Recall: 72.51%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.4817, Average Validation Loss: 0.4783, Accuracy: 79.26%, Precision: 100.00%, Recall: 73.38%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.4828, Average Validation Loss: 0.4721, Accuracy: 80.53%, Precision: 99.99%, Recall: 74.61%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.4819, Average Validation Loss: 0.4665, Accuracy: 81.53%, Precision: 99.99%, Recall: 75.60%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4644, Average Validation Loss: 0.4605, Accuracy: 82.12%, Precision: 99.99%, Recall: 76.19%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4671, Average Validation Loss: 0.4546, Accuracy: 82.54%, Precision: 99.99%, Recall: 76.62%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.4512, Average Validation Loss: 0.4489, Accuracy: 82.64%, Precision: 99.99%, Recall: 76.71%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.4558, Average Validation Loss: 0.4425, Accuracy: 83.05%, Precision: 99.99%, Recall: 77.14%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.4556, Average Validation Loss: 0.4368, Accuracy: 83.68%, Precision: 99.99%, Recall: 77.80%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4493, Average Validation Loss: 0.4305, Accuracy: 84.39%, Precision: 99.99%, Recall: 78.56%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4291, Average Validation Loss: 0.4249, Accuracy: 84.69%, Precision: 99.99%, Recall: 78.89%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4450, Average Validation Loss: 0.4179, Accuracy: 84.97%, Precision: 99.99%, Recall: 79.20%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4191, Average Validation Loss: 0.4120, Accuracy: 85.23%, Precision: 99.99%, Recall: 79.48%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.4036, Average Validation Loss: 0.4057, Accuracy: 85.29%, Precision: 99.99%, Recall: 79.55%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.4172, Average Validation Loss: 0.3994, Accuracy: 85.44%, Precision: 99.99%, Recall: 79.72%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.3979, Average Validation Loss: 0.3932, Accuracy: 85.72%, Precision: 99.99%, Recall: 80.02%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.4051, Average Validation Loss: 0.3871, Accuracy: 86.03%, Precision: 99.99%, Recall: 80.37%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.3906, Average Validation Loss: 0.3809, Accuracy: 86.43%, Precision: 99.99%, Recall: 80.83%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.3744, Average Validation Loss: 0.3742, Accuracy: 86.26%, Precision: 99.99%, Recall: 80.63%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.3806, Average Validation Loss: 0.3679, Accuracy: 86.54%, Precision: 99.99%, Recall: 80.96%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.3625, Average Validation Loss: 0.3613, Accuracy: 86.56%, Precision: 99.99%, Recall: 80.97%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.3513, Average Validation Loss: 0.3554, Accuracy: 86.68%, Precision: 99.99%, Recall: 81.12%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.3625, Average Validation Loss: 0.3476, Accuracy: 87.24%, Precision: 99.99%, Recall: 81.76%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.3376, Average Validation Loss: 0.3404, Accuracy: 87.68%, Precision: 99.99%, Recall: 82.28%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.3335, Average Validation Loss: 0.3336, Accuracy: 87.67%, Precision: 99.99%, Recall: 82.27%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.3489, Average Validation Loss: 0.3255, Accuracy: 88.43%, Precision: 99.99%, Recall: 83.18%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.3239, Average Validation Loss: 0.3177, Accuracy: 89.53%, Precision: 99.99%, Recall: 84.53%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.3295, Average Validation Loss: 0.3096, Accuracy: 90.34%, Precision: 99.99%, Recall: 85.56%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.3052, Average Validation Loss: 0.3020, Accuracy: 90.69%, Precision: 99.99%, Recall: 86.01%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.3017, Average Validation Loss: 0.2941, Accuracy: 90.34%, Precision: 99.99%, Recall: 85.55%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.2861, Average Validation Loss: 0.2872, Accuracy: 90.24%, Precision: 99.99%, Recall: 85.42%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.3065, Average Validation Loss: 0.2761, Accuracy: 92.08%, Precision: 99.99%, Recall: 87.84%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.2848, Average Validation Loss: 0.2665, Accuracy: 93.55%, Precision: 99.96%, Recall: 89.89%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.2821, Average Validation Loss: 0.2573, Accuracy: 93.54%, Precision: 99.98%, Recall: 89.86%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.2648, Average Validation Loss: 0.2476, Accuracy: 93.85%, Precision: 99.99%, Recall: 90.30%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.2523, Average Validation Loss: 0.2357, Accuracy: 94.92%, Precision: 99.98%, Recall: 91.86%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2548, Average Validation Loss: 0.2258, Accuracy: 95.15%, Precision: 99.99%, Recall: 92.20%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2321, Average Validation Loss: 0.2145, Accuracy: 95.85%, Precision: 99.99%, Recall: 93.24%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2393, Average Validation Loss: 0.2031, Accuracy: 96.70%, Precision: 99.97%, Recall: 94.57%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2039, Average Validation Loss: 0.1938, Accuracy: 96.26%, Precision: 99.99%, Recall: 93.87%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.1971, Average Validation Loss: 0.1847, Accuracy: 96.42%, Precision: 99.99%, Recall: 94.12%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.1990, Average Validation Loss: 0.1716, Accuracy: 97.37%, Precision: 99.99%, Recall: 95.61%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1685, Average Validation Loss: 0.1619, Accuracy: 97.58%, Precision: 99.99%, Recall: 95.94%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1689, Average Validation Loss: 0.1528, Accuracy: 97.80%, Precision: 99.99%, Recall: 96.31%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1573, Average Validation Loss: 0.1437, Accuracy: 98.02%, Precision: 99.99%, Recall: 96.66%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1465, Average Validation Loss: 0.1356, Accuracy: 98.19%, Precision: 99.99%, Recall: 96.94%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1469, Average Validation Loss: 0.1266, Accuracy: 98.56%, Precision: 99.99%, Recall: 97.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1346, Average Validation Loss: 0.1191, Accuracy: 98.74%, Precision: 99.99%, Recall: 97.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1289, Average Validation Loss: 0.1146, Accuracy: 98.60%, Precision: 99.99%, Recall: 97.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1027, Average Validation Loss: 0.1096, Accuracy: 98.56%, Precision: 99.99%, Recall: 97.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1058, Average Validation Loss: 0.1034, Accuracy: 98.69%, Precision: 99.99%, Recall: 97.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1067, Average Validation Loss: 0.0975, Accuracy: 98.92%, Precision: 99.99%, Recall: 98.15%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0981, Average Validation Loss: 0.0946, Accuracy: 98.79%, Precision: 99.99%, Recall: 97.94%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0957, Average Validation Loss: 0.0897, Accuracy: 98.92%, Precision: 99.99%, Recall: 98.16%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0870, Average Validation Loss: 0.0856, Accuracy: 98.97%, Precision: 99.99%, Recall: 98.24%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0929, Average Validation Loss: 0.0814, Accuracy: 99.04%, Precision: 99.99%, Recall: 98.35%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1024, Average Validation Loss: 0.0779, Accuracy: 99.09%, Precision: 99.99%, Recall: 98.44%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0768, Average Validation Loss: 0.0762, Accuracy: 99.00%, Precision: 99.99%, Recall: 98.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0823, Average Validation Loss: 0.0726, Accuracy: 99.06%, Precision: 99.99%, Recall: 98.39%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0661, Average Validation Loss: 0.0715, Accuracy: 99.00%, Precision: 99.99%, Recall: 98.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0969, Average Validation Loss: 0.0693, Accuracy: 98.99%, Precision: 99.99%, Recall: 98.28%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0750, Average Validation Loss: 0.0664, Accuracy: 99.19%, Precision: 99.99%, Recall: 98.60%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0618, Average Validation Loss: 0.0643, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.50%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0806, Average Validation Loss: 0.0634, Accuracy: 99.09%, Precision: 99.99%, Recall: 98.44%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0712, Average Validation Loss: 0.0616, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0647, Average Validation Loss: 0.0607, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.47%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0658, Average Validation Loss: 0.0589, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0738, Average Validation Loss: 0.0574, Accuracy: 99.20%, Precision: 99.99%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0778, Average Validation Loss: 0.0563, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0664, Average Validation Loss: 0.0556, Accuracy: 99.20%, Precision: 99.99%, Recall: 98.63%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0483, Average Validation Loss: 0.0556, Accuracy: 99.15%, Precision: 99.99%, Recall: 98.54%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0436, Average Validation Loss: 0.0553, Accuracy: 99.14%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0399, Average Validation Loss: 0.0542, Accuracy: 99.15%, Precision: 99.99%, Recall: 98.54%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0435, Average Validation Loss: 0.0526, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.57%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0750, Average Validation Loss: 0.0516, Accuracy: 99.21%, Precision: 99.99%, Recall: 98.64%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0637, Average Validation Loss: 0.0520, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0610, Average Validation Loss: 0.0508, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0568, Average Validation Loss: 0.0493, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0471, Average Validation Loss: 0.0491, Accuracy: 99.22%, Precision: 99.99%, Recall: 98.67%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0384, Average Validation Loss: 0.0494, Accuracy: 99.19%, Precision: 99.99%, Recall: 98.61%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0549, Average Validation Loss: 0.0487, Accuracy: 99.20%, Precision: 99.99%, Recall: 98.62%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0796, Average Validation Loss: 0.0474, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0518, Average Validation Loss: 0.0468, Accuracy: 99.29%, Precision: 99.99%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0432, Average Validation Loss: 0.0467, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0364, Average Validation Loss: 0.0465, Accuracy: 99.23%, Precision: 99.99%, Recall: 98.68%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0389, Average Validation Loss: 0.0470, Accuracy: 99.20%, Precision: 99.99%, Recall: 98.63%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0527, Average Validation Loss: 0.0467, Accuracy: 99.21%, Precision: 99.99%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 12:19:50,441] Trial 0 finished with value: 0.04667895930643017 and parameters: {'vector_length': 256, 'hidden_length': 512, 'num_layers': 4, 'num_epochs': 3, 'dropout': 0.4, 'metadata_vector_length': 1024, 'lr': 1.4990412150722226e-06, 'warmup_steps': 40}. Best is trial 0 with value: 0.04667895930643017.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 24, with 454,148,608 parameters\n","Num non-decayed parameter tensors: 23, with 167,938 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5969, Average Validation Loss: 0.4158, Accuracy: 88.83%, Precision: 100.00%, Recall: 83.66%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.2358, Average Validation Loss: 0.0910, Accuracy: 99.22%, Precision: 99.84%, Recall: 98.80%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0566, Average Validation Loss: 0.0416, Accuracy: 99.06%, Precision: 98.36%, Recall: 99.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0182, Average Validation Loss: 0.0130, Accuracy: 99.70%, Precision: 99.93%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0137, Average Validation Loss: 0.0060, Accuracy: 99.86%, Precision: 99.81%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0039, Average Validation Loss: 0.0017, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0019, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0018, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0021, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0025, Accuracy: 99.94%, Precision: 99.94%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0029, Average Validation Loss: 0.0037, Accuracy: 99.90%, Precision: 99.92%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 12:33:21,911] Trial 1 finished with value: 0.0037234780329084526 and parameters: {'vector_length': 512, 'hidden_length': 2048, 'num_layers': 5, 'num_epochs': 4, 'dropout': 0.1, 'metadata_vector_length': 2048, 'lr': 0.0004044399051035035, 'warmup_steps': 60}. Best is trial 1 with value: 0.0037234780329084526.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4706, Average Validation Loss: 0.1496, Accuracy: 99.05%, Precision: 99.58%, Recall: 98.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0553, Average Validation Loss: 0.0075, Accuracy: 99.79%, Precision: 99.96%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0043, Accuracy: 99.88%, Precision: 99.96%, Recall: 99.83%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0070, Accuracy: 99.76%, Precision: 99.64%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0084, Average Validation Loss: 0.0019, Accuracy: 99.94%, Precision: 99.94%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0109, Accuracy: 99.66%, Precision: 100.00%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0219, Average Validation Loss: 0.0022, Accuracy: 99.94%, Precision: 99.94%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0022, Accuracy: 99.94%, Precision: 99.91%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0030, Accuracy: 99.90%, Precision: 99.84%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0014, Accuracy: 99.95%, Precision: 99.97%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 12:35:56,277] Trial 2 finished with value: 0.0014212693657364563 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.0011800360164860848, 'warmup_steps': 50}. Best is trial 2 with value: 0.0014212693657364563.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 291,569,664 parameters\n","Num non-decayed parameter tensors: 15, with 101,378 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7126, Average Validation Loss: 0.7037, Accuracy: 33.58%, Precision: 55.96%, Recall: 43.70%, F1: 0.49\n","Epoch 0, Average Training Loss: 0.6874, Average Validation Loss: 0.6704, Accuracy: 57.72%, Precision: 99.78%, Recall: 57.51%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6498, Average Validation Loss: 0.6245, Accuracy: 58.68%, Precision: 99.94%, Recall: 58.06%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6043, Average Validation Loss: 0.5620, Accuracy: 67.77%, Precision: 99.96%, Recall: 63.96%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.5234, Average Validation Loss: 0.4572, Accuracy: 84.42%, Precision: 99.96%, Recall: 78.61%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.3691, Average Validation Loss: 0.3005, Accuracy: 87.99%, Precision: 99.02%, Recall: 83.19%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.2448, Average Validation Loss: 0.1385, Accuracy: 96.68%, Precision: 97.09%, Recall: 97.11%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.0755, Average Validation Loss: 0.0302, Accuracy: 99.42%, Precision: 99.70%, Recall: 99.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0223, Average Validation Loss: 0.0238, Accuracy: 99.49%, Precision: 99.85%, Recall: 99.26%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0175, Average Validation Loss: 0.0210, Accuracy: 99.49%, Precision: 99.92%, Recall: 99.19%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0268, Average Validation Loss: 0.0249, Accuracy: 99.61%, Precision: 99.78%, Recall: 99.54%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0239, Average Validation Loss: 0.0166, Accuracy: 99.61%, Precision: 99.96%, Recall: 99.35%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0116, Average Validation Loss: 0.0174, Accuracy: 99.67%, Precision: 99.95%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0171, Accuracy: 99.70%, Precision: 99.99%, Recall: 99.49%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0362, Average Validation Loss: 0.0152, Accuracy: 99.67%, Precision: 100.00%, Recall: 99.43%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0256, Average Validation Loss: 0.0290, Accuracy: 99.75%, Precision: 99.91%, Recall: 99.66%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0241, Average Validation Loss: 0.0163, Accuracy: 99.74%, Precision: 99.99%, Recall: 99.55%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0108, Average Validation Loss: 0.0143, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0142, Average Validation Loss: 0.0162, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0183, Average Validation Loss: 0.0207, Accuracy: 99.79%, Precision: 99.99%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 12:51:36,921] Trial 3 finished with value: 0.020717553572880257 and parameters: {'vector_length': 2048, 'hidden_length': 2048, 'num_layers': 3, 'num_epochs': 4, 'dropout': 0.1, 'metadata_vector_length': 1024, 'lr': 2.3222107956914464e-05, 'warmup_steps': 90}. Best is trial 2 with value: 0.0014212693657364563.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 44,333,056 parameters\n","Num non-decayed parameter tensors: 15, with 25,602 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6903, Average Validation Loss: 0.6799, Accuracy: 60.64%, Precision: 99.44%, Recall: 59.30%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6630, Average Validation Loss: 0.6407, Accuracy: 60.08%, Precision: 99.98%, Recall: 58.89%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6190, Average Validation Loss: 0.5940, Accuracy: 60.60%, Precision: 99.99%, Recall: 59.21%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.5782, Average Validation Loss: 0.5394, Accuracy: 70.38%, Precision: 99.99%, Recall: 65.89%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5038, Average Validation Loss: 0.4689, Accuracy: 79.08%, Precision: 99.99%, Recall: 73.22%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.4366, Average Validation Loss: 0.3639, Accuracy: 87.87%, Precision: 99.99%, Recall: 82.51%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.3254, Average Validation Loss: 0.2315, Accuracy: 93.67%, Precision: 99.99%, Recall: 90.05%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.1742, Average Validation Loss: 0.0923, Accuracy: 99.06%, Precision: 99.99%, Recall: 98.40%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0865, Average Validation Loss: 0.0502, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0425, Average Validation Loss: 0.0391, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0433, Average Validation Loss: 0.0338, Accuracy: 99.36%, Precision: 99.98%, Recall: 98.92%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0190, Average Validation Loss: 0.0378, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0249, Average Validation Loss: 0.0338, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0641, Average Validation Loss: 0.0303, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.01%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0294, Average Validation Loss: 0.0317, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0434, Average Validation Loss: 0.0284, Accuracy: 99.46%, Precision: 99.98%, Recall: 99.08%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0290, Average Validation Loss: 0.0270, Accuracy: 99.45%, Precision: 99.99%, Recall: 99.06%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0266, Accuracy: 99.40%, Precision: 99.99%, Recall: 98.97%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0260, Average Validation Loss: 0.0249, Accuracy: 99.51%, Precision: 99.93%, Recall: 99.21%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0308, Average Validation Loss: 0.0244, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0224, Accuracy: 99.53%, Precision: 99.99%, Recall: 99.19%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0324, Average Validation Loss: 0.0214, Accuracy: 99.53%, Precision: 99.91%, Recall: 99.27%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0325, Average Validation Loss: 0.0210, Accuracy: 99.47%, Precision: 99.97%, Recall: 99.12%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0136, Average Validation Loss: 0.0221, Accuracy: 99.42%, Precision: 99.99%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0276, Average Validation Loss: 0.0200, Accuracy: 99.56%, Precision: 99.90%, Recall: 99.33%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0208, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0293, Average Validation Loss: 0.0181, Accuracy: 99.58%, Precision: 99.99%, Recall: 99.28%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0217, Average Validation Loss: 0.0168, Accuracy: 99.58%, Precision: 99.97%, Recall: 99.30%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0267, Average Validation Loss: 0.0162, Accuracy: 99.60%, Precision: 99.93%, Recall: 99.37%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0226, Average Validation Loss: 0.0148, Accuracy: 99.56%, Precision: 99.93%, Recall: 99.30%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0148, Average Validation Loss: 0.0143, Accuracy: 99.59%, Precision: 99.95%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0100, Average Validation Loss: 0.0147, Accuracy: 99.57%, Precision: 99.99%, Recall: 99.26%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0238, Average Validation Loss: 0.0159, Accuracy: 99.68%, Precision: 99.84%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0185, Average Validation Loss: 0.0130, Accuracy: 99.64%, Precision: 99.99%, Recall: 99.39%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0123, Accuracy: 99.67%, Precision: 99.99%, Recall: 99.44%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0102, Average Validation Loss: 0.0116, Accuracy: 99.74%, Precision: 99.97%, Recall: 99.57%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0108, Accuracy: 99.75%, Precision: 99.96%, Recall: 99.61%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0231, Average Validation Loss: 0.0135, Accuracy: 99.72%, Precision: 99.78%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0168, Average Validation Loss: 0.0100, Accuracy: 99.73%, Precision: 99.96%, Recall: 99.58%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0084, Average Validation Loss: 0.0116, Accuracy: 99.68%, Precision: 99.75%, Recall: 99.69%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0106, Average Validation Loss: 0.0101, Accuracy: 99.72%, Precision: 99.84%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0146, Average Validation Loss: 0.0092, Accuracy: 99.75%, Precision: 99.90%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0072, Average Validation Loss: 0.0094, Accuracy: 99.77%, Precision: 99.90%, Recall: 99.69%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0068, Average Validation Loss: 0.0082, Accuracy: 99.79%, Precision: 99.91%, Recall: 99.72%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0177, Average Validation Loss: 0.0076, Accuracy: 99.79%, Precision: 99.97%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0115, Average Validation Loss: 0.0078, Accuracy: 99.83%, Precision: 99.94%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0109, Average Validation Loss: 0.0076, Accuracy: 99.79%, Precision: 99.99%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0075, Accuracy: 99.80%, Precision: 99.97%, Recall: 99.69%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0092, Average Validation Loss: 0.0076, Accuracy: 99.80%, Precision: 99.98%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:02:30,022] Trial 4 finished with value: 0.007644556783693465 and parameters: {'vector_length': 2048, 'hidden_length': 512, 'num_layers': 3, 'num_epochs': 4, 'dropout': 0.5, 'metadata_vector_length': 512, 'lr': 2.3747769895709317e-05, 'warmup_steps': 20}. Best is trial 2 with value: 0.0014212693657364563.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 3,893,248 parameters\n","Num non-decayed parameter tensors: 15, with 6,786 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.7008, Average Validation Loss: 0.6959, Accuracy: 43.94%, Precision: 59.18%, Recall: 50.85%, F1: 0.55\n","Epoch 0, Average Training Loss: 0.6896, Average Validation Loss: 0.6802, Accuracy: 69.60%, Precision: 96.97%, Recall: 65.92%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.6693, Average Validation Loss: 0.6550, Accuracy: 75.48%, Precision: 99.99%, Recall: 70.00%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.6403, Average Validation Loss: 0.6196, Accuracy: 75.01%, Precision: 99.99%, Recall: 69.59%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.6020, Average Validation Loss: 0.5718, Accuracy: 78.16%, Precision: 100.00%, Recall: 72.36%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5481, Average Validation Loss: 0.5118, Accuracy: 82.41%, Precision: 100.00%, Recall: 76.48%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.4905, Average Validation Loss: 0.4392, Accuracy: 87.14%, Precision: 100.00%, Recall: 81.64%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.3910, Average Validation Loss: 0.3572, Accuracy: 87.40%, Precision: 100.00%, Recall: 81.95%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.3271, Average Validation Loss: 0.2676, Accuracy: 95.10%, Precision: 99.94%, Recall: 92.15%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2311, Average Validation Loss: 0.1774, Accuracy: 96.28%, Precision: 99.99%, Recall: 93.91%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.1576, Average Validation Loss: 0.0877, Accuracy: 99.01%, Precision: 99.99%, Recall: 98.32%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0703, Average Validation Loss: 0.0419, Accuracy: 99.50%, Precision: 100.00%, Recall: 99.13%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0397, Average Validation Loss: 0.0278, Accuracy: 99.48%, Precision: 100.00%, Recall: 99.10%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0234, Average Validation Loss: 0.0217, Accuracy: 99.53%, Precision: 100.00%, Recall: 99.19%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0208, Average Validation Loss: 0.0242, Accuracy: 99.36%, Precision: 100.00%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0238, Average Validation Loss: 0.0220, Accuracy: 99.47%, Precision: 100.00%, Recall: 99.08%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0246, Average Validation Loss: 0.0207, Accuracy: 99.50%, Precision: 99.99%, Recall: 99.14%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0295, Average Validation Loss: 0.0195, Accuracy: 99.48%, Precision: 99.99%, Recall: 99.10%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0118, Average Validation Loss: 0.0188, Accuracy: 99.45%, Precision: 100.00%, Recall: 99.05%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0171, Accuracy: 99.49%, Precision: 100.00%, Recall: 99.12%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0181, Average Validation Loss: 0.0152, Accuracy: 99.58%, Precision: 99.99%, Recall: 99.29%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0123, Average Validation Loss: 0.0146, Accuracy: 99.54%, Precision: 100.00%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0162, Accuracy: 99.48%, Precision: 100.00%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0184, Average Validation Loss: 0.0131, Accuracy: 99.59%, Precision: 99.99%, Recall: 99.31%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0168, Average Validation Loss: 0.0137, Accuracy: 99.54%, Precision: 100.00%, Recall: 99.21%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0151, Average Validation Loss: 0.0147, Accuracy: 99.48%, Precision: 100.00%, Recall: 99.10%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0112, Average Validation Loss: 0.0129, Accuracy: 99.57%, Precision: 100.00%, Recall: 99.25%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0212, Average Validation Loss: 0.0125, Accuracy: 99.65%, Precision: 99.97%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0118, Average Validation Loss: 0.0121, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.32%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:08:05,205] Trial 5 finished with value: 0.012100986602741318 and parameters: {'vector_length': 256, 'hidden_length': 128, 'num_layers': 3, 'num_epochs': 2, 'dropout': 0.4, 'metadata_vector_length': 512, 'lr': 8.04256060676582e-05, 'warmup_steps': 50}. Best is trial 2 with value: 0.0014212693657364563.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 6,856,704 parameters\n","Num non-decayed parameter tensors: 15, with 12,674 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6941, Average Validation Loss: 0.6949, Accuracy: 42.78%, Precision: 19.30%, Recall: 49.94%, F1: 0.28\n","Epoch 0, Average Training Loss: 0.6944, Average Validation Loss: 0.6940, Accuracy: 44.15%, Precision: 26.72%, Recall: 52.29%, F1: 0.35\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6934, Average Validation Loss: 0.6924, Accuracy: 49.29%, Precision: 41.04%, Recall: 58.01%, F1: 0.48\n","Epoch 0, Average Training Loss: 0.6922, Average Validation Loss: 0.6904, Accuracy: 58.43%, Precision: 62.04%, Recall: 64.11%, F1: 0.63\n","Epoch 0, Average Training Loss: 0.6890, Average Validation Loss: 0.6876, Accuracy: 67.34%, Precision: 87.36%, Recall: 66.26%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6865, Average Validation Loss: 0.6843, Accuracy: 67.57%, Precision: 97.49%, Recall: 64.27%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.6824, Average Validation Loss: 0.6808, Accuracy: 64.67%, Precision: 99.46%, Recall: 61.89%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6801, Average Validation Loss: 0.6775, Accuracy: 62.77%, Precision: 99.83%, Recall: 60.59%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6770, Average Validation Loss: 0.6741, Accuracy: 61.43%, Precision: 99.91%, Recall: 59.73%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6714, Average Validation Loss: 0.6705, Accuracy: 60.32%, Precision: 99.94%, Recall: 59.05%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6679, Average Validation Loss: 0.6668, Accuracy: 59.16%, Precision: 99.97%, Recall: 58.34%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6638, Average Validation Loss: 0.6629, Accuracy: 58.51%, Precision: 99.99%, Recall: 57.96%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6620, Average Validation Loss: 0.6591, Accuracy: 58.34%, Precision: 99.99%, Recall: 57.85%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6600, Average Validation Loss: 0.6550, Accuracy: 58.16%, Precision: 99.99%, Recall: 57.75%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6549, Average Validation Loss: 0.6510, Accuracy: 58.16%, Precision: 100.00%, Recall: 57.75%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6535, Average Validation Loss: 0.6469, Accuracy: 58.20%, Precision: 100.00%, Recall: 57.77%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6444, Average Validation Loss: 0.6420, Accuracy: 58.25%, Precision: 100.00%, Recall: 57.80%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6443, Average Validation Loss: 0.6372, Accuracy: 58.28%, Precision: 100.00%, Recall: 57.82%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6364, Average Validation Loss: 0.6321, Accuracy: 58.35%, Precision: 100.00%, Recall: 57.86%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6379, Average Validation Loss: 0.6270, Accuracy: 58.67%, Precision: 100.00%, Recall: 58.05%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6115, Average Validation Loss: 0.6209, Accuracy: 58.71%, Precision: 100.00%, Recall: 58.07%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6163, Average Validation Loss: 0.6143, Accuracy: 58.82%, Precision: 100.00%, Recall: 58.14%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6134, Average Validation Loss: 0.6077, Accuracy: 59.03%, Precision: 100.00%, Recall: 58.26%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.5954, Average Validation Loss: 0.6007, Accuracy: 59.54%, Precision: 100.00%, Recall: 58.56%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6055, Average Validation Loss: 0.5925, Accuracy: 60.61%, Precision: 100.00%, Recall: 59.21%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.5761, Average Validation Loss: 0.5848, Accuracy: 61.69%, Precision: 100.00%, Recall: 59.88%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.5798, Average Validation Loss: 0.5755, Accuracy: 63.17%, Precision: 100.00%, Recall: 60.83%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5831, Average Validation Loss: 0.5656, Accuracy: 66.30%, Precision: 100.00%, Recall: 62.93%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5650, Average Validation Loss: 0.5543, Accuracy: 70.24%, Precision: 100.00%, Recall: 65.77%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5612, Average Validation Loss: 0.5432, Accuracy: 73.76%, Precision: 100.00%, Recall: 68.55%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5479, Average Validation Loss: 0.5305, Accuracy: 76.47%, Precision: 100.00%, Recall: 70.85%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.5347, Average Validation Loss: 0.5167, Accuracy: 78.96%, Precision: 100.00%, Recall: 73.11%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.5054, Average Validation Loss: 0.5012, Accuracy: 80.47%, Precision: 100.00%, Recall: 74.55%, F1: 0.85\n","Epoch 0, Average Training Loss: 0.4937, Average Validation Loss: 0.4848, Accuracy: 80.93%, Precision: 100.00%, Recall: 74.99%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4985, Average Validation Loss: 0.4662, Accuracy: 83.18%, Precision: 100.00%, Recall: 77.27%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.4667, Average Validation Loss: 0.4467, Accuracy: 84.57%, Precision: 100.00%, Recall: 78.75%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4602, Average Validation Loss: 0.4219, Accuracy: 84.98%, Precision: 100.00%, Recall: 79.20%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4092, Average Validation Loss: 0.3937, Accuracy: 85.55%, Precision: 100.00%, Recall: 79.84%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.3900, Average Validation Loss: 0.3578, Accuracy: 88.83%, Precision: 100.00%, Recall: 83.66%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.3534, Average Validation Loss: 0.3155, Accuracy: 92.02%, Precision: 100.00%, Recall: 87.76%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.3030, Average Validation Loss: 0.2691, Accuracy: 94.28%, Precision: 100.00%, Recall: 90.91%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.2653, Average Validation Loss: 0.2204, Accuracy: 97.29%, Precision: 100.00%, Recall: 95.48%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2137, Average Validation Loss: 0.1806, Accuracy: 97.94%, Precision: 100.00%, Recall: 96.53%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1731, Average Validation Loss: 0.1487, Accuracy: 98.71%, Precision: 100.00%, Recall: 97.79%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1332, Average Validation Loss: 0.1259, Accuracy: 98.68%, Precision: 100.00%, Recall: 97.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1271, Average Validation Loss: 0.1069, Accuracy: 98.98%, Precision: 100.00%, Recall: 98.25%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1142, Average Validation Loss: 0.0942, Accuracy: 99.07%, Precision: 100.00%, Recall: 98.39%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1173, Average Validation Loss: 0.0842, Accuracy: 99.11%, Precision: 100.00%, Recall: 98.47%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0946, Average Validation Loss: 0.0772, Accuracy: 99.16%, Precision: 100.00%, Recall: 98.55%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0771, Average Validation Loss: 0.0708, Accuracy: 99.12%, Precision: 100.00%, Recall: 98.48%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0734, Average Validation Loss: 0.0656, Accuracy: 99.18%, Precision: 100.00%, Recall: 98.58%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0757, Average Validation Loss: 0.0624, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0580, Average Validation Loss: 0.0576, Accuracy: 99.20%, Precision: 100.00%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0707, Average Validation Loss: 0.0544, Accuracy: 99.23%, Precision: 99.99%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0622, Average Validation Loss: 0.0522, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.61%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0644, Average Validation Loss: 0.0503, Accuracy: 99.27%, Precision: 100.00%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0544, Average Validation Loss: 0.0486, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0506, Average Validation Loss: 0.0483, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0415, Average Validation Loss: 0.0455, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0373, Average Validation Loss: 0.0450, Accuracy: 99.25%, Precision: 100.00%, Recall: 98.70%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0287, Average Validation Loss: 0.0457, Accuracy: 99.17%, Precision: 100.00%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0436, Average Validation Loss: 0.0447, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0449, Average Validation Loss: 0.0433, Accuracy: 99.28%, Precision: 99.94%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0472, Average Validation Loss: 0.0421, Accuracy: 99.23%, Precision: 99.99%, Recall: 98.68%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0423, Accuracy: 99.22%, Precision: 100.00%, Recall: 98.65%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0418, Average Validation Loss: 0.0414, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.69%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0304, Average Validation Loss: 0.0402, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0526, Average Validation Loss: 0.0395, Accuracy: 99.27%, Precision: 99.96%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0327, Average Validation Loss: 0.0392, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0391, Average Validation Loss: 0.0397, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.69%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0494, Average Validation Loss: 0.0390, Accuracy: 99.28%, Precision: 99.93%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0386, Average Validation Loss: 0.0381, Accuracy: 99.28%, Precision: 99.96%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0446, Average Validation Loss: 0.0377, Accuracy: 99.28%, Precision: 99.96%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0471, Average Validation Loss: 0.0375, Accuracy: 99.27%, Precision: 99.97%, Recall: 98.78%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0419, Average Validation Loss: 0.0373, Accuracy: 99.27%, Precision: 99.96%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0368, Average Validation Loss: 0.0367, Accuracy: 99.30%, Precision: 99.96%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0287, Average Validation Loss: 0.0368, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.74%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0310, Average Validation Loss: 0.0366, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.73%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0321, Average Validation Loss: 0.0363, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.74%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0434, Average Validation Loss: 0.0356, Accuracy: 99.31%, Precision: 99.96%, Recall: 98.86%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0320, Average Validation Loss: 0.0364, Accuracy: 99.28%, Precision: 99.97%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0454, Average Validation Loss: 0.0362, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.72%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0281, Average Validation Loss: 0.0362, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.73%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0339, Average Validation Loss: 0.0351, Accuracy: 99.29%, Precision: 99.98%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0367, Average Validation Loss: 0.0347, Accuracy: 99.32%, Precision: 99.96%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:24:23,192] Trial 6 finished with value: 0.03460305747953621 and parameters: {'vector_length': 256, 'hidden_length': 256, 'num_layers': 3, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 128, 'lr': 6.924720169742307e-06, 'warmup_steps': 60}. Best is trial 2 with value: 0.0014212693657364563.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 45,197,824 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6984, Average Validation Loss: 0.6761, Accuracy: 82.15%, Precision: 94.76%, Recall: 78.49%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.6428, Average Validation Loss: 0.5946, Accuracy: 86.69%, Precision: 99.95%, Recall: 81.15%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.5495, Average Validation Loss: 0.4842, Accuracy: 88.21%, Precision: 99.98%, Recall: 82.93%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.4298, Average Validation Loss: 0.3659, Accuracy: 91.14%, Precision: 99.98%, Recall: 86.60%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.3188, Average Validation Loss: 0.2461, Accuracy: 97.06%, Precision: 99.90%, Recall: 95.19%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.2067, Average Validation Loss: 0.1549, Accuracy: 97.88%, Precision: 99.85%, Recall: 96.56%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1340, Average Validation Loss: 0.0935, Accuracy: 98.60%, Precision: 99.87%, Recall: 97.74%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0684, Average Validation Loss: 0.0305, Accuracy: 99.46%, Precision: 99.97%, Recall: 99.09%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0160, Average Validation Loss: 0.0136, Accuracy: 99.63%, Precision: 99.89%, Recall: 99.46%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0160, Average Validation Loss: 0.0137, Accuracy: 99.58%, Precision: 99.96%, Recall: 99.31%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0117, Accuracy: 99.57%, Precision: 99.99%, Recall: 99.27%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0118, Accuracy: 99.53%, Precision: 100.00%, Recall: 99.19%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0105, Average Validation Loss: 0.0124, Accuracy: 99.81%, Precision: 99.93%, Recall: 99.74%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0127, Average Validation Loss: 0.0096, Accuracy: 99.73%, Precision: 99.98%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0135, Average Validation Loss: 0.0101, Accuracy: 99.80%, Precision: 99.96%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0087, Average Validation Loss: 0.0087, Accuracy: 99.76%, Precision: 99.99%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0103, Average Validation Loss: 0.0084, Accuracy: 99.76%, Precision: 99.99%, Recall: 99.59%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0076, Average Validation Loss: 0.0080, Accuracy: 99.80%, Precision: 99.99%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0089, Accuracy: 99.83%, Precision: 99.95%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0078, Accuracy: 99.77%, Precision: 99.99%, Recall: 99.60%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0060, Average Validation Loss: 0.0071, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0070, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0064, Accuracy: 99.82%, Precision: 99.97%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0057, Average Validation Loss: 0.0063, Accuracy: 99.84%, Precision: 99.96%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0085, Average Validation Loss: 0.0061, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.65%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0058, Accuracy: 99.84%, Precision: 100.00%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0068, Accuracy: 99.75%, Precision: 100.00%, Recall: 99.57%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0122, Average Validation Loss: 0.0063, Accuracy: 99.88%, Precision: 99.98%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0109, Average Validation Loss: 0.0069, Accuracy: 99.92%, Precision: 99.96%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0055, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:31:26,610] Trial 7 finished with value: 0.005459543010471641 and parameters: {'vector_length': 512, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 5, 'dropout': 0.4, 'metadata_vector_length': 2048, 'lr': 3.838002400532093e-05, 'warmup_steps': 50}. Best is trial 2 with value: 0.0014212693657364563.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 38,119,552 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6441, Average Validation Loss: 0.5419, Accuracy: 96.76%, Precision: 99.84%, Recall: 94.78%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.4165, Average Validation Loss: 0.2664, Accuracy: 96.34%, Precision: 99.95%, Recall: 94.02%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.1729, Average Validation Loss: 0.0833, Accuracy: 99.30%, Precision: 99.50%, Recall: 99.28%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0510, Average Validation Loss: 0.0279, Accuracy: 99.58%, Precision: 99.60%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0175, Average Validation Loss: 0.0135, Accuracy: 99.73%, Precision: 99.67%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0177, Average Validation Loss: 0.0100, Accuracy: 99.71%, Precision: 99.89%, Recall: 99.61%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0043, Accuracy: 99.91%, Precision: 99.96%, Recall: 99.88%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0035, Average Validation Loss: 0.0037, Accuracy: 99.89%, Precision: 99.97%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0029, Accuracy: 99.96%, Precision: 99.95%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0021, Accuracy: 99.95%, Precision: 99.97%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0038, Average Validation Loss: 0.0021, Accuracy: 99.97%, Precision: 99.97%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0020, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0019, Accuracy: 99.96%, Precision: 99.99%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0018, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.97%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0018, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0015, Accuracy: 99.96%, Precision: 99.98%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0031, Average Validation Loss: 0.0018, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0013, Accuracy: 99.94%, Precision: 99.98%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0013, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:35:54,087] Trial 8 finished with value: 0.0013000633535714744 and parameters: {'vector_length': 128, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 1, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0003830264808479387, 'warmup_steps': 80}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 24, with 13,604,608 parameters\n","Num non-decayed parameter tensors: 23, with 12,418 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6484, Average Validation Loss: 0.5679, Accuracy: 97.18%, Precision: 99.80%, Recall: 95.47%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.4606, Average Validation Loss: 0.3061, Accuracy: 98.43%, Precision: 99.67%, Recall: 97.64%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2002, Average Validation Loss: 0.0863, Accuracy: 99.27%, Precision: 99.62%, Recall: 99.11%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0450, Average Validation Loss: 0.0152, Accuracy: 99.68%, Precision: 99.93%, Recall: 99.51%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0067, Average Validation Loss: 0.0054, Accuracy: 99.83%, Precision: 99.94%, Recall: 99.77%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0040, Accuracy: 99.87%, Precision: 99.97%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0057, Accuracy: 99.82%, Precision: 99.75%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0024, Average Validation Loss: 0.0029, Accuracy: 99.90%, Precision: 99.97%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0027, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0026, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0024, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0023, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0020, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:39:20,909] Trial 9 finished with value: 0.0019671808920778662 and parameters: {'vector_length': 1024, 'hidden_length': 128, 'num_layers': 5, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0010514686174328324, 'warmup_steps': 100}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 36,194,944 parameters\n","Num non-decayed parameter tensors: 11, with 34,050 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5467, Average Validation Loss: 0.3231, Accuracy: 85.97%, Precision: 99.93%, Recall: 80.33%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.1462, Average Validation Loss: 0.0343, Accuracy: 99.26%, Precision: 98.84%, Recall: 99.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0298, Average Validation Loss: 0.0139, Accuracy: 99.47%, Precision: 99.15%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0072, Average Validation Loss: 0.0046, Accuracy: 99.89%, Precision: 99.93%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0060, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0305, Average Validation Loss: 0.0120, Accuracy: 99.74%, Precision: 99.93%, Recall: 99.61%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0130, Accuracy: 99.71%, Precision: 99.51%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0100, Average Validation Loss: 0.0243, Accuracy: 99.69%, Precision: 99.99%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0130, Average Validation Loss: 0.0153, Accuracy: 99.80%, Precision: 99.99%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:41:31,091] Trial 10 finished with value: 0.015361738761139105 and parameters: {'vector_length': 128, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 1, 'dropout': 0.2, 'metadata_vector_length': 256, 'lr': 0.005129023395331515, 'warmup_steps': 80}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 38,119,552 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6326, Average Validation Loss: 0.4914, Accuracy: 95.74%, Precision: 99.91%, Recall: 93.14%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.3494, Average Validation Loss: 0.1751, Accuracy: 98.32%, Precision: 99.82%, Recall: 97.31%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1073, Average Validation Loss: 0.0412, Accuracy: 99.28%, Precision: 99.78%, Recall: 98.96%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0272, Average Validation Loss: 0.0223, Accuracy: 99.45%, Precision: 99.09%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0157, Average Validation Loss: 0.0093, Accuracy: 99.77%, Precision: 99.77%, Recall: 99.83%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0063, Average Validation Loss: 0.0054, Accuracy: 99.88%, Precision: 99.88%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0027, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.83%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0034, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.3553, Average Validation Loss: 0.0041, Accuracy: 99.87%, Precision: 99.93%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0043, Accuracy: 99.85%, Precision: 99.93%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0031, Accuracy: 99.91%, Precision: 99.90%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0023, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:44:21,644] Trial 11 finished with value: 0.0023155359402251734 and parameters: {'vector_length': 128, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 1, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.0005261434603809059, 'warmup_steps': 80}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.1715, Average Validation Loss: 0.0394, Accuracy: 99.22%, Precision: 98.87%, Recall: 99.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0188, Average Validation Loss: 0.0678, Accuracy: 99.61%, Precision: 99.91%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0687, Average Validation Loss: 0.0431, Accuracy: 99.70%, Precision: 99.62%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0683, Average Validation Loss: 0.0147, Accuracy: 99.77%, Precision: 99.94%, Recall: 99.66%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0029, Average Validation Loss: 0.0059, Accuracy: 99.85%, Precision: 99.88%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0056, Accuracy: 99.87%, Precision: 99.88%, Recall: 99.89%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0061, Accuracy: 99.88%, Precision: 99.90%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0261, Average Validation Loss: 0.0042, Accuracy: 99.91%, Precision: 99.89%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0053, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0031, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0181, Average Validation Loss: 0.0074, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0038, Average Validation Loss: 0.0629, Accuracy: 99.55%, Precision: 100.00%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0261, Average Validation Loss: 0.0131, Accuracy: 99.87%, Precision: 99.87%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0623, Average Validation Loss: 0.0089, Accuracy: 99.92%, Precision: 99.91%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0773, Average Validation Loss: 0.0016, Accuracy: 99.98%, Precision: 99.98%, Recall: 99.99%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0130, Accuracy: 99.88%, Precision: 99.81%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0262, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.1436, Average Validation Loss: 0.0202, Accuracy: 99.94%, Precision: 99.92%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0582, Average Validation Loss: 0.0402, Accuracy: 99.92%, Precision: 99.89%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0237, Accuracy: 99.94%, Precision: 99.93%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:49:21,911] Trial 12 finished with value: 0.023547560625986473 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 2, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.006676970716681131, 'warmup_steps': 20}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 20, with 86,526,592 parameters\n","Num non-decayed parameter tensors: 19, with 66,818 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6499, Average Validation Loss: 0.5403, Accuracy: 66.98%, Precision: 99.99%, Recall: 63.40%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.3572, Average Validation Loss: 0.1724, Accuracy: 95.82%, Precision: 99.54%, Recall: 93.57%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.1432, Average Validation Loss: 0.0325, Accuracy: 99.69%, Precision: 99.89%, Recall: 99.57%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0253, Average Validation Loss: 0.0086, Accuracy: 99.83%, Precision: 99.81%, Recall: 99.89%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0082, Average Validation Loss: 0.0044, Accuracy: 99.85%, Precision: 99.99%, Recall: 99.75%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0037, Accuracy: 99.93%, Precision: 99.93%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.7244, Average Validation Loss: 0.0052, Accuracy: 99.84%, Precision: 99.76%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0115, Average Validation Loss: 0.0096, Accuracy: 99.70%, Precision: 99.98%, Recall: 99.50%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0059, Average Validation Loss: 0.1413, Accuracy: 94.67%, Precision: 90.69%, Recall: 99.98%, F1: 0.95\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0229, Average Validation Loss: 0.0046, Accuracy: 99.87%, Precision: 99.82%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:53:14,530] Trial 13 finished with value: 0.0045524842709907 and parameters: {'vector_length': 128, 'hidden_length': 1024, 'num_layers': 4, 'num_epochs': 2, 'dropout': 0.2, 'metadata_vector_length': 256, 'lr': 0.0015777151703531883, 'warmup_steps': 70}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 14,721,792 parameters\n","Num non-decayed parameter tensors: 11, with 8,578 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6859, Average Validation Loss: 0.6698, Accuracy: 57.86%, Precision: 99.99%, Recall: 57.58%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6476, Average Validation Loss: 0.6206, Accuracy: 58.62%, Precision: 100.00%, Recall: 58.02%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.5938, Average Validation Loss: 0.5222, Accuracy: 80.99%, Precision: 100.00%, Recall: 75.05%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4479, Average Validation Loss: 0.3555, Accuracy: 86.44%, Precision: 99.93%, Recall: 80.87%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.2536, Average Validation Loss: 0.1078, Accuracy: 98.18%, Precision: 99.97%, Recall: 96.94%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0581, Average Validation Loss: 0.0287, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.88%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0254, Average Validation Loss: 0.0232, Accuracy: 99.43%, Precision: 99.99%, Recall: 99.02%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0421, Average Validation Loss: 0.0230, Accuracy: 99.46%, Precision: 99.95%, Recall: 99.11%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0207, Average Validation Loss: 0.0244, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0223, Average Validation Loss: 0.0234, Accuracy: 99.47%, Precision: 99.73%, Recall: 99.34%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0172, Average Validation Loss: 0.0234, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.95%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0256, Average Validation Loss: 0.0186, Accuracy: 99.52%, Precision: 100.00%, Recall: 99.17%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0157, Average Validation Loss: 0.0179, Accuracy: 99.59%, Precision: 99.97%, Recall: 99.32%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0143, Average Validation Loss: 0.0180, Accuracy: 99.55%, Precision: 100.00%, Recall: 99.22%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0219, Average Validation Loss: 0.0187, Accuracy: 99.61%, Precision: 99.95%, Recall: 99.38%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0179, Average Validation Loss: 0.0160, Accuracy: 99.64%, Precision: 99.96%, Recall: 99.41%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0205, Average Validation Loss: 0.0152, Accuracy: 99.64%, Precision: 99.96%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0134, Average Validation Loss: 0.0154, Accuracy: 99.64%, Precision: 99.90%, Recall: 99.48%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0278, Average Validation Loss: 0.0152, Accuracy: 99.68%, Precision: 99.96%, Recall: 99.49%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0146, Average Validation Loss: 0.0144, Accuracy: 99.63%, Precision: 100.00%, Recall: 99.36%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0147, Accuracy: 99.68%, Precision: 99.94%, Recall: 99.51%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0151, Average Validation Loss: 0.0148, Accuracy: 99.57%, Precision: 100.00%, Recall: 99.26%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0126, Accuracy: 99.69%, Precision: 99.96%, Recall: 99.50%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0134, Average Validation Loss: 0.0138, Accuracy: 99.59%, Precision: 100.00%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0079, Average Validation Loss: 0.0165, Accuracy: 99.50%, Precision: 100.00%, Recall: 99.14%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0147, Accuracy: 99.53%, Precision: 100.00%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0173, Average Validation Loss: 0.0118, Accuracy: 99.67%, Precision: 99.99%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0218, Average Validation Loss: 0.0116, Accuracy: 99.67%, Precision: 100.00%, Recall: 99.42%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 13:57:53,062] Trial 14 finished with value: 0.011631017346941941 and parameters: {'vector_length': 1024, 'hidden_length': 256, 'num_layers': 2, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 128, 'lr': 0.00013721494614409493, 'warmup_steps': 30}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6413, Average Validation Loss: 0.5392, Accuracy: 73.14%, Precision: 99.99%, Recall: 68.05%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.4306, Average Validation Loss: 0.2860, Accuracy: 98.22%, Precision: 99.79%, Recall: 97.18%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1852, Average Validation Loss: 0.0770, Accuracy: 99.40%, Precision: 99.76%, Recall: 99.20%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0320, Average Validation Loss: 0.0127, Accuracy: 99.80%, Precision: 99.88%, Recall: 99.77%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0114, Average Validation Loss: 0.0071, Accuracy: 99.78%, Precision: 99.99%, Recall: 99.62%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0050, Accuracy: 99.86%, Precision: 99.98%, Recall: 99.77%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0045, Accuracy: 99.90%, Precision: 99.97%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0043, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0041, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0022, Average Validation Loss: 0.0037, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0049, Accuracy: 99.92%, Precision: 99.95%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0047, Average Validation Loss: 0.0034, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0032, Accuracy: 99.94%, Precision: 99.97%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0039, Average Validation Loss: 0.0037, Accuracy: 99.93%, Precision: 99.95%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0024, Average Validation Loss: 0.0027, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.88%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0034, Accuracy: 99.89%, Precision: 100.00%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0052, Average Validation Loss: 0.0030, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0043, Average Validation Loss: 0.0030, Accuracy: 99.96%, Precision: 99.98%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0019, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0027, Average Validation Loss: 0.0022, Accuracy: 99.96%, Precision: 99.97%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:02:55,772] Trial 15 finished with value: 0.0022367755190242787 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 5, 'dropout': 0.1, 'metadata_vector_length': 2048, 'lr': 0.00024967752024252036, 'warmup_steps': 70}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 20, with 88,451,200 parameters\n","Num non-decayed parameter tensors: 19, with 68,610 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5221, Average Validation Loss: 0.2383, Accuracy: 97.58%, Precision: 99.73%, Recall: 96.18%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1020, Average Validation Loss: 0.0206, Accuracy: 99.45%, Precision: 99.44%, Recall: 99.61%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0364, Average Validation Loss: 0.0166, Accuracy: 99.40%, Precision: 99.13%, Recall: 99.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0113, Average Validation Loss: 0.0063, Accuracy: 99.83%, Precision: 99.87%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0035, Accuracy: 99.89%, Precision: 99.92%, Recall: 99.88%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0023, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0027, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0014, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0104, Average Validation Loss: 0.0300, Accuracy: 99.75%, Precision: 99.57%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0147, Average Validation Loss: 0.0022, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0073, Accuracy: 99.82%, Precision: 99.81%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:07:08,155] Trial 16 finished with value: 0.007322466785501239 and parameters: {'vector_length': 128, 'hidden_length': 1024, 'num_layers': 4, 'num_epochs': 3, 'dropout': 0.5, 'metadata_vector_length': 2048, 'lr': 0.002098813173765957, 'warmup_steps': 100}. Best is trial 8 with value: 0.0013000633535714744.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 98,676,736 parameters\n","Num non-decayed parameter tensors: 15, with 52,226 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.1935, Average Validation Loss: 0.0214, Accuracy: 99.64%, Precision: 99.70%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0477, Average Validation Loss: 0.0211, Accuracy: 99.80%, Precision: 99.94%, Recall: 99.70%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0564, Average Validation Loss: 0.0064, Accuracy: 99.90%, Precision: 99.87%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0630, Average Validation Loss: 0.0096, Accuracy: 99.77%, Precision: 99.61%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0062, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0116, Average Validation Loss: 0.0068, Accuracy: 99.82%, Precision: 99.92%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0053, Accuracy: 99.83%, Precision: 99.94%, Recall: 99.77%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0124, Average Validation Loss: 0.0032, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0020, Accuracy: 99.94%, Precision: 99.98%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0006, Average Validation Loss: 0.0017, Accuracy: 99.96%, Precision: 99.98%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0054, Average Validation Loss: 0.0014, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0021, Average Validation Loss: 0.0010, Accuracy: 99.97%, Precision: 100.00%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0009, Accuracy: 99.97%, Precision: 100.00%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0009, Accuracy: 99.97%, Precision: 100.00%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0008, Accuracy: 99.98%, Precision: 100.00%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0007, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0008, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:12:38,507] Trial 17 finished with value: 0.0007610484100020571 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 3, 'num_epochs': 1, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0028833488994399175, 'warmup_steps': 10}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 238,838,400 parameters\n","Num non-decayed parameter tensors: 15, with 100,610 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5107, Average Validation Loss: 0.0453, Accuracy: 98.53%, Precision: 97.60%, Recall: 99.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0338, Average Validation Loss: 0.0175, Accuracy: 99.70%, Precision: 99.54%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0430, Average Validation Loss: 0.0230, Accuracy: 99.64%, Precision: 99.62%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0122, Average Validation Loss: 0.0343, Accuracy: 99.57%, Precision: 99.97%, Recall: 99.29%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0135, Average Validation Loss: 0.0131, Accuracy: 99.81%, Precision: 99.93%, Recall: 99.73%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0061, Accuracy: 99.91%, Precision: 99.87%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0350, Average Validation Loss: 0.0081, Accuracy: 99.90%, Precision: 99.84%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0101, Average Validation Loss: 0.0135, Accuracy: 99.83%, Precision: 99.71%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0060, Average Validation Loss: 0.0061, Accuracy: 99.91%, Precision: 99.87%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0030, Accuracy: 99.96%, Precision: 99.98%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0038, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0029, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0021, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0019, Accuracy: 99.96%, Precision: 99.97%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0019, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0052, Accuracy: 99.89%, Precision: 99.81%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0024, Accuracy: 99.96%, Precision: 99.96%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0017, Accuracy: 99.97%, Precision: 99.97%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0015, Accuracy: 99.97%, Precision: 99.97%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:27:00,708] Trial 18 finished with value: 0.0014953578506280694 and parameters: {'vector_length': 128, 'hidden_length': 2048, 'num_layers': 3, 'num_epochs': 1, 'dropout': 0.2, 'metadata_vector_length': 256, 'lr': 0.0038365888262460205, 'warmup_steps': 10}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 12,544,768 parameters\n","Num non-decayed parameter tensors: 15, with 6,786 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6371, Average Validation Loss: 0.5068, Accuracy: 72.39%, Precision: 100.00%, Recall: 67.45%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.3626, Average Validation Loss: 0.1652, Accuracy: 98.60%, Precision: 99.90%, Recall: 97.71%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0775, Average Validation Loss: 0.0228, Accuracy: 99.68%, Precision: 99.92%, Recall: 99.52%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0137, Average Validation Loss: 0.0119, Accuracy: 99.71%, Precision: 99.95%, Recall: 99.54%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0158, Average Validation Loss: 0.0123, Accuracy: 99.75%, Precision: 99.81%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0098, Average Validation Loss: 0.0084, Accuracy: 99.72%, Precision: 99.96%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0099, Average Validation Loss: 0.0078, Accuracy: 99.75%, Precision: 99.98%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0064, Accuracy: 99.80%, Precision: 99.95%, Recall: 99.70%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0035, Average Validation Loss: 0.0062, Accuracy: 99.83%, Precision: 99.93%, Recall: 99.77%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0054, Average Validation Loss: 0.0055, Accuracy: 99.82%, Precision: 99.96%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0053, Accuracy: 99.89%, Precision: 99.94%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0092, Average Validation Loss: 0.0043, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0057, Average Validation Loss: 0.0038, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0081, Average Validation Loss: 0.0047, Accuracy: 99.93%, Precision: 99.93%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0032, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0033, Accuracy: 99.90%, Precision: 99.99%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0030, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0032, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0023, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0026, Accuracy: 99.92%, Precision: 99.98%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:30:53,618] Trial 19 finished with value: 0.002628755263081198 and parameters: {'vector_length': 1024, 'hidden_length': 128, 'num_layers': 3, 'num_epochs': 1, 'dropout': 0.1, 'metadata_vector_length': 512, 'lr': 0.0004900667463693571, 'warmup_steps': 10}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 20, with 11,849,728 parameters\n","Num non-decayed parameter tensors: 19, with 17,666 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2909, Average Validation Loss: 0.0242, Accuracy: 99.15%, Precision: 98.90%, Recall: 99.62%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0238, Average Validation Loss: 0.0326, Accuracy: 99.73%, Precision: 99.96%, Recall: 99.58%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0224, Average Validation Loss: 0.0141, Accuracy: 99.87%, Precision: 99.91%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0116, Accuracy: 99.90%, Precision: 99.88%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0217, Average Validation Loss: 0.0158, Accuracy: 99.81%, Precision: 100.00%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0078, Accuracy: 99.89%, Precision: 99.94%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0126, Average Validation Loss: 0.0075, Accuracy: 99.88%, Precision: 99.98%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0396, Average Validation Loss: 0.0278, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0257, Accuracy: 99.90%, Precision: 99.96%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0063, Accuracy: 99.96%, Precision: 99.95%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0055, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0180, Average Validation Loss: 0.0136, Accuracy: 99.91%, Precision: 100.00%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0463, Average Validation Loss: 0.0045, Accuracy: 99.92%, Precision: 99.90%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0076, Average Validation Loss: 0.0033, Accuracy: 99.96%, Precision: 100.00%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0072, Average Validation Loss: 0.0039, Accuracy: 99.94%, Precision: 99.90%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0082, Average Validation Loss: 0.0215, Accuracy: 99.93%, Precision: 99.90%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0445, Accuracy: 99.93%, Precision: 99.94%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0157, Average Validation Loss: 0.0521, Accuracy: 99.93%, Precision: 99.93%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0540, Accuracy: 99.90%, Precision: 99.87%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:35:21,661] Trial 20 finished with value: 0.05422426798959842 and parameters: {'vector_length': 512, 'hidden_length': 256, 'num_layers': 4, 'num_epochs': 2, 'dropout': 0.2, 'metadata_vector_length': 1024, 'lr': 0.009303448878070893, 'warmup_steps': 30}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4628, Average Validation Loss: 0.1201, Accuracy: 98.09%, Precision: 99.85%, Recall: 96.90%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0520, Average Validation Loss: 0.0090, Accuracy: 99.66%, Precision: 99.96%, Recall: 99.44%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0035, Average Validation Loss: 0.0028, Accuracy: 99.93%, Precision: 99.94%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0371, Accuracy: 98.88%, Precision: 98.04%, Recall: 99.99%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0038, Accuracy: 99.89%, Precision: 99.95%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0077, Accuracy: 99.74%, Precision: 99.57%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0024, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0038, Average Validation Loss: 0.0027, Accuracy: 99.92%, Precision: 99.96%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:37:27,459] Trial 21 finished with value: 0.002706053664160145 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 1, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.0010806583438275703, 'warmup_steps': 40}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4851, Average Validation Loss: 0.1484, Accuracy: 97.63%, Precision: 99.79%, Recall: 96.20%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0621, Average Validation Loss: 0.0077, Accuracy: 99.78%, Precision: 99.94%, Recall: 99.68%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0048, Average Validation Loss: 0.0045, Accuracy: 99.88%, Precision: 99.93%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0114, Average Validation Loss: 0.0048, Accuracy: 99.86%, Precision: 99.78%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0125, Average Validation Loss: 0.0021, Accuracy: 99.95%, Precision: 99.96%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0020, Accuracy: 99.95%, Precision: 99.98%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0054, Accuracy: 99.83%, Precision: 99.74%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0018, Accuracy: 99.96%, Precision: 99.97%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0023, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0013, Accuracy: 99.97%, Precision: 99.97%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:40:03,006] Trial 22 finished with value: 0.001343771780994831 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 2, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.0019124716020458182, 'warmup_steps': 80}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 98,676,736 parameters\n","Num non-decayed parameter tensors: 15, with 52,226 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4273, Average Validation Loss: 0.0746, Accuracy: 98.84%, Precision: 99.72%, Recall: 98.28%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0177, Average Validation Loss: 0.0070, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.71%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0112, Average Validation Loss: 0.0042, Accuracy: 99.89%, Precision: 99.85%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0077, Average Validation Loss: 0.0046, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0391, Average Validation Loss: 0.0105, Accuracy: 99.77%, Precision: 99.96%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0123, Average Validation Loss: 0.0057, Accuracy: 99.88%, Precision: 99.83%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0026, Accuracy: 99.92%, Precision: 99.96%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0162, Average Validation Loss: 0.0214, Accuracy: 99.67%, Precision: 100.00%, Recall: 99.43%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0067, Average Validation Loss: 0.0073, Accuracy: 99.82%, Precision: 99.97%, Recall: 99.71%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0024, Average Validation Loss: 0.0033, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0021, Accuracy: 99.94%, Precision: 99.98%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0051, Average Validation Loss: 0.0167, Accuracy: 99.47%, Precision: 99.12%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:44:01,497] Trial 23 finished with value: 0.015346269262010685 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 3, 'num_epochs': 2, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.002724126298510117, 'warmup_steps': 80}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6488, Average Validation Loss: 0.5716, Accuracy: 68.69%, Precision: 99.99%, Recall: 64.62%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.4873, Average Validation Loss: 0.3600, Accuracy: 92.54%, Precision: 99.93%, Recall: 88.51%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.2607, Average Validation Loss: 0.1472, Accuracy: 97.45%, Precision: 99.84%, Recall: 95.86%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0796, Average Validation Loss: 0.0214, Accuracy: 99.52%, Precision: 99.96%, Recall: 99.20%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0129, Average Validation Loss: 0.0110, Accuracy: 99.74%, Precision: 99.93%, Recall: 99.61%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0038, Average Validation Loss: 0.0089, Accuracy: 99.71%, Precision: 99.99%, Recall: 99.50%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0487, Average Validation Loss: 0.0084, Accuracy: 99.74%, Precision: 99.99%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0085, Average Validation Loss: 0.0099, Accuracy: 99.88%, Precision: 99.89%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0055, Accuracy: 99.82%, Precision: 99.99%, Recall: 99.70%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0053, Average Validation Loss: 0.0043, Accuracy: 99.89%, Precision: 99.99%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0041, Accuracy: 99.92%, Precision: 99.96%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0037, Accuracy: 99.94%, Precision: 99.97%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0031, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0026, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0031, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0027, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0032, Accuracy: 99.93%, Precision: 99.93%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0040, Accuracy: 99.93%, Precision: 99.91%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:48:33,595] Trial 24 finished with value: 0.003979161686918422 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 1, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.000240892364878222, 'warmup_steps': 90}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 16,590,208 parameters\n","Num non-decayed parameter tensors: 15, with 25,218 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6958, Average Validation Loss: 0.6753, Accuracy: 57.20%, Precision: 99.96%, Recall: 57.20%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.6456, Average Validation Loss: 0.5904, Accuracy: 58.62%, Precision: 100.00%, Recall: 58.02%, F1: 0.73\n","Epoch 0, Average Training Loss: 0.4996, Average Validation Loss: 0.3112, Accuracy: 90.89%, Precision: 97.38%, Recall: 87.98%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.2023, Average Validation Loss: 0.0522, Accuracy: 98.96%, Precision: 99.96%, Recall: 98.26%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0394, Average Validation Loss: 0.0491, Accuracy: 98.81%, Precision: 99.99%, Recall: 97.97%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0593, Average Validation Loss: 0.0351, Accuracy: 99.46%, Precision: 99.86%, Recall: 99.20%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0440, Average Validation Loss: 0.0322, Accuracy: 99.27%, Precision: 100.00%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0288, Average Validation Loss: 0.0413, Accuracy: 98.91%, Precision: 100.00%, Recall: 98.13%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0229, Average Validation Loss: 0.0211, Accuracy: 99.46%, Precision: 99.99%, Recall: 99.07%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0126, Average Validation Loss: 0.0181, Accuracy: 99.53%, Precision: 99.99%, Recall: 99.19%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0164, Accuracy: 99.66%, Precision: 99.91%, Recall: 99.51%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0152, Average Validation Loss: 0.0118, Accuracy: 99.65%, Precision: 99.96%, Recall: 99.43%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0141, Average Validation Loss: 0.0103, Accuracy: 99.80%, Precision: 99.95%, Recall: 99.70%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0103, Average Validation Loss: 0.0075, Accuracy: 99.82%, Precision: 99.96%, Recall: 99.72%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0040, Average Validation Loss: 0.0067, Accuracy: 99.78%, Precision: 99.98%, Recall: 99.64%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0052, Accuracy: 99.85%, Precision: 99.95%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0051, Average Validation Loss: 0.0044, Accuracy: 99.88%, Precision: 99.96%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0049, Accuracy: 99.92%, Precision: 99.93%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0039, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0029, Accuracy: 99.90%, Precision: 99.97%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0045, Accuracy: 99.89%, Precision: 99.85%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0027, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0032, Accuracy: 99.88%, Precision: 99.98%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0025, Accuracy: 99.90%, Precision: 99.97%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0023, Accuracy: 99.92%, Precision: 99.96%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0023, Accuracy: 99.91%, Precision: 99.96%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0026, Accuracy: 99.93%, Precision: 99.93%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:54:28,241] Trial 25 finished with value: 0.00259840710912957 and parameters: {'vector_length': 128, 'hidden_length': 512, 'num_layers': 3, 'num_epochs': 2, 'dropout': 0.4, 'metadata_vector_length': 128, 'lr': 0.0007021521376657656, 'warmup_steps': 90}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3870, Average Validation Loss: 0.0518, Accuracy: 99.08%, Precision: 99.92%, Recall: 98.50%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0152, Average Validation Loss: 0.0072, Accuracy: 99.80%, Precision: 99.86%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0105, Accuracy: 99.73%, Precision: 99.58%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0273, Average Validation Loss: 0.0033, Accuracy: 99.93%, Precision: 99.95%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0082, Average Validation Loss: 0.0038, Accuracy: 99.90%, Precision: 99.92%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0153, Average Validation Loss: 0.0072, Accuracy: 99.83%, Precision: 99.99%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0548, Accuracy: 99.50%, Precision: 99.86%, Recall: 99.26%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0498, Average Validation Loss: 0.0056, Accuracy: 99.90%, Precision: 99.84%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0089, Accuracy: 99.87%, Precision: 99.79%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 14:56:47,118] Trial 26 finished with value: 0.008818969234542581 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 1, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.003318445451643856, 'warmup_steps': 70}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6629, Average Validation Loss: 0.6114, Accuracy: 69.80%, Precision: 100.00%, Recall: 65.45%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5457, Average Validation Loss: 0.4638, Accuracy: 82.46%, Precision: 100.00%, Recall: 76.53%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.3880, Average Validation Loss: 0.2787, Accuracy: 97.11%, Precision: 99.90%, Recall: 95.28%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.2003, Average Validation Loss: 0.1065, Accuracy: 99.13%, Precision: 99.67%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0551, Average Validation Loss: 0.0168, Accuracy: 99.61%, Precision: 100.00%, Recall: 99.33%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0198, Average Validation Loss: 0.0138, Accuracy: 99.69%, Precision: 99.94%, Recall: 99.51%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0114, Average Validation Loss: 0.0119, Accuracy: 99.68%, Precision: 99.99%, Recall: 99.45%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0147, Average Validation Loss: 0.0137, Accuracy: 99.79%, Precision: 99.87%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0139, Average Validation Loss: 0.0083, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0109, Average Validation Loss: 0.0085, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0086, Average Validation Loss: 0.0073, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0068, Average Validation Loss: 0.0077, Accuracy: 99.91%, Precision: 99.93%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0062, Average Validation Loss: 0.0061, Accuracy: 99.88%, Precision: 100.00%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0080, Average Validation Loss: 0.0059, Accuracy: 99.88%, Precision: 100.00%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0064, Average Validation Loss: 0.0060, Accuracy: 99.93%, Precision: 99.98%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0056, Accuracy: 99.93%, Precision: 99.97%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0031, Average Validation Loss: 0.0044, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0041, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0083, Average Validation Loss: 0.0054, Accuracy: 99.91%, Precision: 99.93%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0039, Accuracy: 99.93%, Precision: 99.96%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0034, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0059, Average Validation Loss: 0.0077, Accuracy: 99.88%, Precision: 99.83%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0058, Average Validation Loss: 0.0047, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0072, Average Validation Loss: 0.0041, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0038, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0047, Average Validation Loss: 0.0030, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 15:03:19,547] Trial 27 finished with value: 0.0030088838661794324 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 2, 'dropout': 0.1, 'metadata_vector_length': 2048, 'lr': 0.00011292815050333762, 'warmup_steps': 70}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 63,285,376 parameters\n","Num non-decayed parameter tensors: 15, with 52,226 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6493, Average Validation Loss: 0.5498, Accuracy: 88.88%, Precision: 99.98%, Recall: 83.73%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.4359, Average Validation Loss: 0.2851, Accuracy: 97.40%, Precision: 99.89%, Recall: 95.75%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1886, Average Validation Loss: 0.0944, Accuracy: 98.81%, Precision: 99.88%, Recall: 98.08%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0603, Average Validation Loss: 0.0273, Accuracy: 99.64%, Precision: 99.85%, Recall: 99.51%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0216, Average Validation Loss: 0.0086, Accuracy: 99.90%, Precision: 99.86%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0129, Average Validation Loss: 0.0115, Accuracy: 99.72%, Precision: 99.96%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0082, Average Validation Loss: 0.0093, Accuracy: 99.79%, Precision: 99.89%, Recall: 99.75%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0082, Average Validation Loss: 0.0066, Accuracy: 99.86%, Precision: 99.96%, Recall: 99.80%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0051, Accuracy: 99.89%, Precision: 99.92%, Recall: 99.89%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0043, Accuracy: 99.88%, Precision: 99.98%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0083, Average Validation Loss: 0.0033, Accuracy: 99.90%, Precision: 99.98%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0024, Average Validation Loss: 0.0028, Accuracy: 99.93%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0025, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0024, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0023, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0031, Average Validation Loss: 0.0018, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0015, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0013, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0012, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0012, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0013, Average Validation Loss: 0.0316, Accuracy: 99.18%, Precision: 98.59%, Recall: 99.97%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0017, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0016, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0017, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 15:10:39,656] Trial 28 finished with value: 0.0016597722178778133 and parameters: {'vector_length': 128, 'hidden_length': 1024, 'num_layers': 3, 'num_epochs': 1, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0002754152289859548, 'warmup_steps': 60}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 20, with 36,231,168 parameters\n","Num non-decayed parameter tensors: 19, with 34,306 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6966, Average Validation Loss: 0.6938, Accuracy: 55.51%, Precision: 78.24%, Recall: 58.27%, F1: 0.67\n","Epoch 0, Average Training Loss: 0.6912, Average Validation Loss: 0.6887, Accuracy: 60.06%, Precision: 85.66%, Recall: 60.68%, F1: 0.71\n","Epoch 0, Average Training Loss: 0.6868, Average Validation Loss: 0.6808, Accuracy: 66.01%, Precision: 94.65%, Recall: 63.64%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6763, Average Validation Loss: 0.6697, Accuracy: 68.63%, Precision: 99.04%, Recall: 64.76%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.6654, Average Validation Loss: 0.6571, Accuracy: 68.67%, Precision: 99.67%, Recall: 64.67%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.6525, Average Validation Loss: 0.6445, Accuracy: 69.15%, Precision: 99.83%, Recall: 65.00%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.6395, Average Validation Loss: 0.6321, Accuracy: 69.99%, Precision: 99.91%, Recall: 65.60%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.6275, Average Validation Loss: 0.6192, Accuracy: 70.32%, Precision: 99.94%, Recall: 65.84%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.6144, Average Validation Loss: 0.6058, Accuracy: 70.01%, Precision: 99.95%, Recall: 65.61%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5941, Average Validation Loss: 0.5918, Accuracy: 69.46%, Precision: 99.96%, Recall: 65.19%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5868, Average Validation Loss: 0.5771, Accuracy: 68.84%, Precision: 99.96%, Recall: 64.74%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5711, Average Validation Loss: 0.5623, Accuracy: 69.31%, Precision: 99.97%, Recall: 65.08%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5537, Average Validation Loss: 0.5463, Accuracy: 68.94%, Precision: 99.98%, Recall: 64.81%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5391, Average Validation Loss: 0.5308, Accuracy: 69.42%, Precision: 99.99%, Recall: 65.16%, F1: 0.79\n","Epoch 0, Average Training Loss: 0.5289, Average Validation Loss: 0.5123, Accuracy: 73.10%, Precision: 99.99%, Recall: 68.02%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.5038, Average Validation Loss: 0.4920, Accuracy: 77.37%, Precision: 99.99%, Recall: 71.65%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.4918, Average Validation Loss: 0.4703, Accuracy: 81.35%, Precision: 99.99%, Recall: 75.41%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4751, Average Validation Loss: 0.4456, Accuracy: 83.49%, Precision: 99.99%, Recall: 77.60%, F1: 0.87\n","Epoch 0, Average Training Loss: 0.4292, Average Validation Loss: 0.4197, Accuracy: 83.94%, Precision: 99.99%, Recall: 78.08%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.4208, Average Validation Loss: 0.3911, Accuracy: 85.09%, Precision: 99.99%, Recall: 79.32%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.3790, Average Validation Loss: 0.3593, Accuracy: 87.01%, Precision: 99.99%, Recall: 81.49%, F1: 0.90\n","Epoch 0, Average Training Loss: 0.3475, Average Validation Loss: 0.3226, Accuracy: 88.66%, Precision: 99.99%, Recall: 83.45%, F1: 0.91\n","Epoch 0, Average Training Loss: 0.3009, Average Validation Loss: 0.2774, Accuracy: 91.91%, Precision: 99.99%, Recall: 87.61%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.2685, Average Validation Loss: 0.2247, Accuracy: 95.48%, Precision: 99.99%, Recall: 92.69%, F1: 0.96\n","Epoch 0, Average Training Loss: 0.2120, Average Validation Loss: 0.1695, Accuracy: 97.82%, Precision: 99.99%, Recall: 96.33%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.1604, Average Validation Loss: 0.1270, Accuracy: 98.69%, Precision: 99.99%, Recall: 97.77%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.1216, Average Validation Loss: 0.0981, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.47%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0926, Average Validation Loss: 0.0810, Accuracy: 99.06%, Precision: 99.99%, Recall: 98.39%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0759, Average Validation Loss: 0.0687, Accuracy: 99.18%, Precision: 99.99%, Recall: 98.59%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0619, Average Validation Loss: 0.0608, Accuracy: 99.20%, Precision: 99.99%, Recall: 98.63%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0609, Average Validation Loss: 0.0551, Accuracy: 99.24%, Precision: 99.99%, Recall: 98.69%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0818, Average Validation Loss: 0.0511, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0573, Average Validation Loss: 0.0480, Accuracy: 99.26%, Precision: 99.99%, Recall: 98.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0561, Average Validation Loss: 0.0466, Accuracy: 99.25%, Precision: 99.99%, Recall: 98.72%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0510, Average Validation Loss: 0.0440, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.81%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0419, Average Validation Loss: 0.0430, Accuracy: 99.27%, Precision: 99.99%, Recall: 98.75%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0561, Average Validation Loss: 0.0425, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0473, Average Validation Loss: 0.0402, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0350, Average Validation Loss: 0.0397, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0408, Average Validation Loss: 0.0402, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0513, Average Validation Loss: 0.0378, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0431, Average Validation Loss: 0.0368, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0327, Average Validation Loss: 0.0373, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0379, Accuracy: 99.28%, Precision: 99.99%, Recall: 98.77%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0438, Average Validation Loss: 0.0355, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0467, Average Validation Loss: 0.0345, Accuracy: 99.36%, Precision: 99.98%, Recall: 98.91%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0376, Average Validation Loss: 0.0348, Accuracy: 99.31%, Precision: 99.99%, Recall: 98.82%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0408, Average Validation Loss: 0.0333, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.87%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0352, Average Validation Loss: 0.0331, Accuracy: 99.34%, Precision: 99.96%, Recall: 98.90%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0391, Average Validation Loss: 0.0336, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0431, Average Validation Loss: 0.0342, Accuracy: 99.31%, Precision: 99.96%, Recall: 98.85%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0360, Average Validation Loss: 0.0320, Accuracy: 99.30%, Precision: 99.96%, Recall: 98.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0491, Average Validation Loss: 0.0318, Accuracy: 99.38%, Precision: 99.92%, Recall: 99.01%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0292, Average Validation Loss: 0.0331, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.80%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0354, Average Validation Loss: 0.0328, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0345, Average Validation Loss: 0.0305, Accuracy: 99.37%, Precision: 99.93%, Recall: 98.99%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0349, Average Validation Loss: 0.0302, Accuracy: 99.33%, Precision: 99.95%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0301, Average Validation Loss: 0.0324, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0241, Average Validation Loss: 0.0333, Accuracy: 99.30%, Precision: 99.99%, Recall: 98.79%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0412, Average Validation Loss: 0.0294, Accuracy: 99.35%, Precision: 99.96%, Recall: 98.91%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0365, Average Validation Loss: 0.0290, Accuracy: 99.41%, Precision: 99.95%, Recall: 99.02%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0277, Average Validation Loss: 0.0293, Accuracy: 99.35%, Precision: 99.99%, Recall: 98.88%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0216, Average Validation Loss: 0.0303, Accuracy: 99.33%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0282, Average Validation Loss: 0.0294, Accuracy: 99.34%, Precision: 99.98%, Recall: 98.89%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0309, Average Validation Loss: 0.0280, Accuracy: 99.39%, Precision: 99.96%, Recall: 98.97%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0337, Average Validation Loss: 0.0277, Accuracy: 99.39%, Precision: 99.95%, Recall: 99.00%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0200, Average Validation Loss: 0.0297, Accuracy: 99.32%, Precision: 99.99%, Recall: 98.83%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.0290, Accuracy: 99.34%, Precision: 99.99%, Recall: 98.86%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0464, Average Validation Loss: 0.0272, Accuracy: 99.44%, Precision: 99.99%, Recall: 99.04%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0378, Average Validation Loss: 0.0270, Accuracy: 99.47%, Precision: 99.96%, Recall: 99.11%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 15:28:39,336] Trial 29 finished with value: 0.027070416122473576 and parameters: {'vector_length': 1024, 'hidden_length': 512, 'num_layers': 4, 'num_epochs': 2, 'dropout': 0.4, 'metadata_vector_length': 1024, 'lr': 4.82861880513938e-06, 'warmup_steps': 40}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 5,283,840 parameters\n","Num non-decayed parameter tensors: 11, with 8,578 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6845, Average Validation Loss: 0.6843, Accuracy: 75.48%, Precision: 86.81%, Recall: 74.51%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.6852, Average Validation Loss: 0.6841, Accuracy: 75.60%, Precision: 87.56%, Recall: 74.33%, F1: 0.80\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6835, Average Validation Loss: 0.6838, Accuracy: 75.58%, Precision: 88.83%, Recall: 73.80%, F1: 0.81\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.6840, Average Validation Loss: 0.6835, Accuracy: 75.56%, Precision: 90.55%, Recall: 73.12%, F1: 0.81\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.6831, Average Validation Loss: 0.6831, Accuracy: 75.38%, Precision: 92.55%, Recall: 72.22%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.6839, Average Validation Loss: 0.6825, Accuracy: 74.60%, Precision: 94.42%, Recall: 70.86%, F1: 0.81\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6823, Average Validation Loss: 0.6818, Accuracy: 73.48%, Precision: 95.92%, Recall: 69.40%, F1: 0.81\n","Epoch 0, Average Training Loss: 0.6816, Average Validation Loss: 0.6811, Accuracy: 72.47%, Precision: 97.21%, Recall: 68.19%, F1: 0.80\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6794, Average Validation Loss: 0.6803, Accuracy: 71.04%, Precision: 98.26%, Recall: 66.77%, F1: 0.80\n","Epoch 0, Average Training Loss: 0.6808, Average Validation Loss: 0.6795, Accuracy: 69.80%, Precision: 98.89%, Recall: 65.67%, F1: 0.79\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6793, Average Validation Loss: 0.6787, Accuracy: 68.53%, Precision: 99.25%, Recall: 64.65%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.6789, Average Validation Loss: 0.6780, Accuracy: 67.42%, Precision: 99.53%, Recall: 63.79%, F1: 0.78\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6771, Average Validation Loss: 0.6772, Accuracy: 66.33%, Precision: 99.70%, Recall: 62.99%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.6760, Average Validation Loss: 0.6764, Accuracy: 65.56%, Precision: 99.84%, Recall: 62.44%, F1: 0.77\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6753, Average Validation Loss: 0.6756, Accuracy: 64.53%, Precision: 99.91%, Recall: 61.73%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6734, Average Validation Loss: 0.6748, Accuracy: 63.53%, Precision: 99.95%, Recall: 61.07%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6763, Average Validation Loss: 0.6740, Accuracy: 62.98%, Precision: 99.96%, Recall: 60.71%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6745, Average Validation Loss: 0.6732, Accuracy: 62.50%, Precision: 99.98%, Recall: 60.40%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6734, Average Validation Loss: 0.6725, Accuracy: 62.15%, Precision: 99.99%, Recall: 60.18%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6744, Average Validation Loss: 0.6719, Accuracy: 62.07%, Precision: 99.99%, Recall: 60.13%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6714, Average Validation Loss: 0.6711, Accuracy: 61.92%, Precision: 100.00%, Recall: 60.03%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6720, Average Validation Loss: 0.6705, Accuracy: 61.78%, Precision: 100.00%, Recall: 59.94%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6712, Average Validation Loss: 0.6698, Accuracy: 61.64%, Precision: 100.00%, Recall: 59.85%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6690, Average Validation Loss: 0.6690, Accuracy: 61.39%, Precision: 100.00%, Recall: 59.69%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6698, Average Validation Loss: 0.6684, Accuracy: 61.13%, Precision: 100.00%, Recall: 59.54%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6659, Average Validation Loss: 0.6676, Accuracy: 60.93%, Precision: 100.00%, Recall: 59.41%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6673, Average Validation Loss: 0.6669, Accuracy: 60.77%, Precision: 100.00%, Recall: 59.31%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6668, Average Validation Loss: 0.6661, Accuracy: 60.55%, Precision: 100.00%, Recall: 59.18%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6631, Average Validation Loss: 0.6654, Accuracy: 60.32%, Precision: 100.00%, Recall: 59.04%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6646, Average Validation Loss: 0.6647, Accuracy: 60.13%, Precision: 100.00%, Recall: 58.93%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6635, Average Validation Loss: 0.6640, Accuracy: 59.97%, Precision: 100.00%, Recall: 58.83%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6602, Average Validation Loss: 0.6631, Accuracy: 59.78%, Precision: 100.00%, Recall: 58.71%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6629, Average Validation Loss: 0.6624, Accuracy: 59.60%, Precision: 100.00%, Recall: 58.60%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6598, Average Validation Loss: 0.6617, Accuracy: 59.49%, Precision: 100.00%, Recall: 58.54%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6624, Average Validation Loss: 0.6611, Accuracy: 59.45%, Precision: 100.00%, Recall: 58.51%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6646, Average Validation Loss: 0.6604, Accuracy: 59.43%, Precision: 100.00%, Recall: 58.50%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6607, Average Validation Loss: 0.6596, Accuracy: 59.42%, Precision: 100.00%, Recall: 58.50%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6583, Average Validation Loss: 0.6590, Accuracy: 59.42%, Precision: 100.00%, Recall: 58.50%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6598, Average Validation Loss: 0.6582, Accuracy: 59.39%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6605, Average Validation Loss: 0.6576, Accuracy: 59.39%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6582, Average Validation Loss: 0.6569, Accuracy: 59.40%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6607, Average Validation Loss: 0.6562, Accuracy: 59.44%, Precision: 100.00%, Recall: 58.51%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6568, Average Validation Loss: 0.6557, Accuracy: 59.49%, Precision: 100.00%, Recall: 58.54%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6570, Average Validation Loss: 0.6550, Accuracy: 59.56%, Precision: 100.00%, Recall: 58.58%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6551, Average Validation Loss: 0.6543, Accuracy: 59.57%, Precision: 100.00%, Recall: 58.58%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6534, Average Validation Loss: 0.6535, Accuracy: 59.55%, Precision: 100.00%, Recall: 58.57%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6568, Average Validation Loss: 0.6528, Accuracy: 59.55%, Precision: 100.00%, Recall: 58.57%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6550, Average Validation Loss: 0.6523, Accuracy: 59.56%, Precision: 100.00%, Recall: 58.58%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6502, Average Validation Loss: 0.6516, Accuracy: 59.51%, Precision: 100.00%, Recall: 58.55%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6500, Average Validation Loss: 0.6509, Accuracy: 59.49%, Precision: 100.00%, Recall: 58.54%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6516, Average Validation Loss: 0.6502, Accuracy: 59.43%, Precision: 100.00%, Recall: 58.50%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6510, Average Validation Loss: 0.6494, Accuracy: 59.40%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6481, Average Validation Loss: 0.6487, Accuracy: 59.40%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6517, Average Validation Loss: 0.6481, Accuracy: 59.40%, Precision: 100.00%, Recall: 58.49%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6450, Average Validation Loss: 0.6473, Accuracy: 59.40%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6481, Average Validation Loss: 0.6467, Accuracy: 59.39%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6457, Average Validation Loss: 0.6460, Accuracy: 59.41%, Precision: 100.00%, Recall: 58.49%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6451, Average Validation Loss: 0.6453, Accuracy: 59.38%, Precision: 100.00%, Recall: 58.47%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6457, Average Validation Loss: 0.6446, Accuracy: 59.36%, Precision: 100.00%, Recall: 58.46%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6496, Average Validation Loss: 0.6440, Accuracy: 59.40%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6400, Average Validation Loss: 0.6433, Accuracy: 59.39%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6415, Average Validation Loss: 0.6426, Accuracy: 59.40%, Precision: 100.00%, Recall: 58.48%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6427, Average Validation Loss: 0.6419, Accuracy: 59.38%, Precision: 100.00%, Recall: 58.47%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6429, Average Validation Loss: 0.6411, Accuracy: 59.40%, Precision: 100.00%, Recall: 58.49%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6429, Average Validation Loss: 0.6405, Accuracy: 59.43%, Precision: 100.00%, Recall: 58.50%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6379, Average Validation Loss: 0.6399, Accuracy: 59.45%, Precision: 100.00%, Recall: 58.51%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6427, Average Validation Loss: 0.6391, Accuracy: 59.44%, Precision: 100.00%, Recall: 58.51%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6443, Average Validation Loss: 0.6385, Accuracy: 59.49%, Precision: 100.00%, Recall: 58.54%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6376, Average Validation Loss: 0.6376, Accuracy: 59.54%, Precision: 100.00%, Recall: 58.56%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6357, Average Validation Loss: 0.6374, Accuracy: 59.57%, Precision: 100.00%, Recall: 58.59%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6381, Average Validation Loss: 0.6363, Accuracy: 59.57%, Precision: 100.00%, Recall: 58.58%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6388, Average Validation Loss: 0.6358, Accuracy: 59.56%, Precision: 100.00%, Recall: 58.58%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6390, Average Validation Loss: 0.6349, Accuracy: 59.60%, Precision: 100.00%, Recall: 58.60%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6321, Average Validation Loss: 0.6344, Accuracy: 59.63%, Precision: 100.00%, Recall: 58.62%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6333, Average Validation Loss: 0.6337, Accuracy: 59.64%, Precision: 100.00%, Recall: 58.63%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6374, Average Validation Loss: 0.6332, Accuracy: 59.68%, Precision: 100.00%, Recall: 58.65%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6389, Average Validation Loss: 0.6323, Accuracy: 59.79%, Precision: 100.00%, Recall: 58.72%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6335, Average Validation Loss: 0.6318, Accuracy: 59.88%, Precision: 100.00%, Recall: 58.77%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6383, Average Validation Loss: 0.6311, Accuracy: 60.02%, Precision: 100.00%, Recall: 58.86%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6377, Average Validation Loss: 0.6305, Accuracy: 60.14%, Precision: 100.00%, Recall: 58.93%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6366, Average Validation Loss: 0.6299, Accuracy: 60.29%, Precision: 100.00%, Recall: 59.02%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6312, Average Validation Loss: 0.6293, Accuracy: 60.46%, Precision: 100.00%, Recall: 59.12%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6289, Average Validation Loss: 0.6286, Accuracy: 60.54%, Precision: 100.00%, Recall: 59.17%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6238, Average Validation Loss: 0.6276, Accuracy: 60.52%, Precision: 100.00%, Recall: 59.16%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6346, Average Validation Loss: 0.6271, Accuracy: 60.58%, Precision: 100.00%, Recall: 59.20%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6316, Average Validation Loss: 0.6265, Accuracy: 60.70%, Precision: 100.00%, Recall: 59.27%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6228, Average Validation Loss: 0.6257, Accuracy: 60.74%, Precision: 100.00%, Recall: 59.29%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6220, Average Validation Loss: 0.6250, Accuracy: 60.73%, Precision: 100.00%, Recall: 59.29%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6274, Average Validation Loss: 0.6245, Accuracy: 60.74%, Precision: 100.00%, Recall: 59.30%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6275, Average Validation Loss: 0.6239, Accuracy: 60.77%, Precision: 100.00%, Recall: 59.32%, F1: 0.74\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6245, Average Validation Loss: 0.6228, Accuracy: 60.83%, Precision: 100.00%, Recall: 59.35%, F1: 0.74\n","Epoch 0, Average Training Loss: 0.6274, Average Validation Loss: 0.6220, Accuracy: 60.90%, Precision: 100.00%, Recall: 59.39%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6236, Average Validation Loss: 0.6215, Accuracy: 60.99%, Precision: 100.00%, Recall: 59.45%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6211, Average Validation Loss: 0.6210, Accuracy: 61.04%, Precision: 100.00%, Recall: 59.48%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6131, Average Validation Loss: 0.6201, Accuracy: 61.05%, Precision: 100.00%, Recall: 59.49%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6240, Average Validation Loss: 0.6196, Accuracy: 61.05%, Precision: 100.00%, Recall: 59.49%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6231, Average Validation Loss: 0.6186, Accuracy: 61.16%, Precision: 100.00%, Recall: 59.55%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6203, Average Validation Loss: 0.6182, Accuracy: 61.27%, Precision: 100.00%, Recall: 59.62%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6099, Average Validation Loss: 0.6172, Accuracy: 61.31%, Precision: 100.00%, Recall: 59.65%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6182, Average Validation Loss: 0.6167, Accuracy: 61.33%, Precision: 100.00%, Recall: 59.66%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6241, Average Validation Loss: 0.6159, Accuracy: 61.44%, Precision: 100.00%, Recall: 59.73%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6204, Average Validation Loss: 0.6151, Accuracy: 61.57%, Precision: 100.00%, Recall: 59.81%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6135, Average Validation Loss: 0.6146, Accuracy: 61.69%, Precision: 100.00%, Recall: 59.89%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6177, Average Validation Loss: 0.6137, Accuracy: 61.76%, Precision: 100.00%, Recall: 59.93%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6103, Average Validation Loss: 0.6132, Accuracy: 61.84%, Precision: 100.00%, Recall: 59.98%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6180, Average Validation Loss: 0.6126, Accuracy: 61.91%, Precision: 100.00%, Recall: 60.02%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6135, Average Validation Loss: 0.6117, Accuracy: 61.99%, Precision: 100.00%, Recall: 60.07%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6114, Average Validation Loss: 0.6110, Accuracy: 62.06%, Precision: 100.00%, Recall: 60.12%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6035, Average Validation Loss: 0.6103, Accuracy: 62.08%, Precision: 100.00%, Recall: 60.13%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6127, Average Validation Loss: 0.6098, Accuracy: 62.22%, Precision: 100.00%, Recall: 60.22%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6092, Average Validation Loss: 0.6089, Accuracy: 62.24%, Precision: 100.00%, Recall: 60.23%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6122, Average Validation Loss: 0.6083, Accuracy: 62.30%, Precision: 100.00%, Recall: 60.27%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6117, Average Validation Loss: 0.6075, Accuracy: 62.37%, Precision: 100.00%, Recall: 60.32%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6069, Average Validation Loss: 0.6068, Accuracy: 62.48%, Precision: 100.00%, Recall: 60.39%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6047, Average Validation Loss: 0.6059, Accuracy: 62.59%, Precision: 100.00%, Recall: 60.45%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6118, Average Validation Loss: 0.6053, Accuracy: 62.69%, Precision: 100.00%, Recall: 60.52%, F1: 0.75\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6067, Average Validation Loss: 0.6045, Accuracy: 62.78%, Precision: 100.00%, Recall: 60.58%, F1: 0.75\n","Epoch 0, Average Training Loss: 0.6094, Average Validation Loss: 0.6042, Accuracy: 62.92%, Precision: 100.00%, Recall: 60.66%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5981, Average Validation Loss: 0.6034, Accuracy: 62.94%, Precision: 100.00%, Recall: 60.68%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6023, Average Validation Loss: 0.6025, Accuracy: 62.95%, Precision: 100.00%, Recall: 60.69%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6062, Average Validation Loss: 0.6018, Accuracy: 63.03%, Precision: 100.00%, Recall: 60.74%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5965, Average Validation Loss: 0.6011, Accuracy: 63.06%, Precision: 100.00%, Recall: 60.75%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6015, Average Validation Loss: 0.6002, Accuracy: 63.11%, Precision: 100.00%, Recall: 60.79%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6042, Average Validation Loss: 0.5994, Accuracy: 63.22%, Precision: 100.00%, Recall: 60.86%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6033, Average Validation Loss: 0.5989, Accuracy: 63.32%, Precision: 100.00%, Recall: 60.93%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.6017, Average Validation Loss: 0.5981, Accuracy: 63.43%, Precision: 100.00%, Recall: 60.99%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6025, Average Validation Loss: 0.5974, Accuracy: 63.59%, Precision: 100.00%, Recall: 61.10%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5940, Average Validation Loss: 0.5967, Accuracy: 63.65%, Precision: 100.00%, Recall: 61.14%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6015, Average Validation Loss: 0.5961, Accuracy: 63.78%, Precision: 100.00%, Recall: 61.23%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5946, Average Validation Loss: 0.5954, Accuracy: 63.93%, Precision: 100.00%, Recall: 61.32%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.6021, Average Validation Loss: 0.5943, Accuracy: 64.10%, Precision: 100.00%, Recall: 61.44%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5948, Average Validation Loss: 0.5939, Accuracy: 64.29%, Precision: 100.00%, Recall: 61.56%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5927, Average Validation Loss: 0.5929, Accuracy: 64.44%, Precision: 100.00%, Recall: 61.66%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5951, Average Validation Loss: 0.5922, Accuracy: 64.60%, Precision: 100.00%, Recall: 61.77%, F1: 0.76\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5970, Average Validation Loss: 0.5915, Accuracy: 64.75%, Precision: 100.00%, Recall: 61.87%, F1: 0.76\n","Epoch 0, Average Training Loss: 0.5893, Average Validation Loss: 0.5907, Accuracy: 64.92%, Precision: 100.00%, Recall: 61.98%, F1: 0.77\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5979, Average Validation Loss: 0.5898, Accuracy: 65.05%, Precision: 100.00%, Recall: 62.07%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5998, Average Validation Loss: 0.5892, Accuracy: 65.23%, Precision: 100.00%, Recall: 62.19%, F1: 0.77\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5930, Average Validation Loss: 0.5884, Accuracy: 65.50%, Precision: 100.00%, Recall: 62.37%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5922, Average Validation Loss: 0.5875, Accuracy: 65.83%, Precision: 100.00%, Recall: 62.60%, F1: 0.77\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5782, Average Validation Loss: 0.5871, Accuracy: 66.00%, Precision: 100.00%, Recall: 62.71%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5836, Average Validation Loss: 0.5860, Accuracy: 66.11%, Precision: 100.00%, Recall: 62.79%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5778, Average Validation Loss: 0.5854, Accuracy: 66.13%, Precision: 100.00%, Recall: 62.81%, F1: 0.77\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5932, Average Validation Loss: 0.5847, Accuracy: 66.25%, Precision: 100.00%, Recall: 62.89%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5935, Average Validation Loss: 0.5836, Accuracy: 66.53%, Precision: 100.00%, Recall: 63.08%, F1: 0.77\n","Epoch 0, Average Training Loss: 0.5924, Average Validation Loss: 0.5830, Accuracy: 66.83%, Precision: 100.00%, Recall: 63.29%, F1: 0.78\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.5716, Average Validation Loss: 0.5825, Accuracy: 66.97%, Precision: 100.00%, Recall: 63.39%, F1: 0.78\n","Epoch 0, Average Training Loss: 0.1762, Average Validation Loss: 0.5823, Accuracy: 67.00%, Precision: 100.00%, Recall: 63.41%, F1: 0.78\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5866, Average Validation Loss: 0.5820, Accuracy: 67.03%, Precision: 100.00%, Recall: 63.43%, F1: 0.78\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 1, Average Training Loss: 0.5799, Average Validation Loss: 0.5820, Accuracy: 67.08%, Precision: 100.00%, Recall: 63.46%, F1: 0.78\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 1, Average Training Loss: 0.5894, Average Validation Loss: 0.5814, Accuracy: 67.18%, Precision: 100.00%, Recall: 63.54%, F1: 0.78\n","Epoch 1, Average Training Loss: 0.5884, Average Validation Loss: 0.5808, Accuracy: 67.27%, Precision: 100.00%, Recall: 63.60%, F1: 0.78\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5868, Average Validation Loss: 0.5804, Accuracy: 67.43%, Precision: 100.00%, Recall: 63.72%, F1: 0.78\n","Epoch 1, Average Training Loss: 0.5821, Average Validation Loss: 0.5798, Accuracy: 67.64%, Precision: 100.00%, Recall: 63.87%, F1: 0.78\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5814, Average Validation Loss: 0.5791, Accuracy: 67.87%, Precision: 100.00%, Recall: 64.03%, F1: 0.78\n","Epoch 1, Average Training Loss: 0.5899, Average Validation Loss: 0.5783, Accuracy: 68.26%, Precision: 100.00%, Recall: 64.31%, F1: 0.78\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5750, Average Validation Loss: 0.5770, Accuracy: 68.55%, Precision: 100.00%, Recall: 64.52%, F1: 0.78\n","Epoch 1, Average Training Loss: 0.5769, Average Validation Loss: 0.5760, Accuracy: 68.80%, Precision: 100.00%, Recall: 64.70%, F1: 0.79\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5776, Average Validation Loss: 0.5751, Accuracy: 68.95%, Precision: 100.00%, Recall: 64.81%, F1: 0.79\n","Epoch 1, Average Training Loss: 0.5785, Average Validation Loss: 0.5743, Accuracy: 69.16%, Precision: 100.00%, Recall: 64.97%, F1: 0.79\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5743, Average Validation Loss: 0.5730, Accuracy: 69.51%, Precision: 100.00%, Recall: 65.22%, F1: 0.79\n","Epoch 1, Average Training Loss: 0.5711, Average Validation Loss: 0.5720, Accuracy: 69.63%, Precision: 100.00%, Recall: 65.31%, F1: 0.79\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5701, Average Validation Loss: 0.5708, Accuracy: 69.80%, Precision: 100.00%, Recall: 65.44%, F1: 0.79\n","Epoch 1, Average Training Loss: 0.5645, Average Validation Loss: 0.5700, Accuracy: 69.86%, Precision: 100.00%, Recall: 65.49%, F1: 0.79\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5774, Average Validation Loss: 0.5689, Accuracy: 70.08%, Precision: 100.00%, Recall: 65.66%, F1: 0.79\n","Epoch 1, Average Training Loss: 0.5634, Average Validation Loss: 0.5679, Accuracy: 70.24%, Precision: 100.00%, Recall: 65.78%, F1: 0.79\n","Epoch 1, Average Training Loss: 0.5735, Average Validation Loss: 0.5668, Accuracy: 70.58%, Precision: 100.00%, Recall: 66.03%, F1: 0.80\n","Epoch 1, Average Training Loss: 0.5678, Average Validation Loss: 0.5655, Accuracy: 70.82%, Precision: 100.00%, Recall: 66.22%, F1: 0.80\n","Epoch 1, Average Training Loss: 0.5632, Average Validation Loss: 0.5646, Accuracy: 71.11%, Precision: 100.00%, Recall: 66.44%, F1: 0.80\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5633, Average Validation Loss: 0.5637, Accuracy: 71.31%, Precision: 100.00%, Recall: 66.59%, F1: 0.80\n","Epoch 1, Average Training Loss: 0.5789, Average Validation Loss: 0.5625, Accuracy: 71.73%, Precision: 100.00%, Recall: 66.92%, F1: 0.80\n","Epoch 1, Average Training Loss: 0.5752, Average Validation Loss: 0.5612, Accuracy: 72.24%, Precision: 100.00%, Recall: 67.32%, F1: 0.80\n","Epoch 1, Average Training Loss: 0.5625, Average Validation Loss: 0.5600, Accuracy: 72.59%, Precision: 100.00%, Recall: 67.60%, F1: 0.81\n","Epoch 1, Average Training Loss: 0.5670, Average Validation Loss: 0.5589, Accuracy: 73.07%, Precision: 100.00%, Recall: 67.99%, F1: 0.81\n","Epoch 1, Average Training Loss: 0.5620, Average Validation Loss: 0.5579, Accuracy: 73.44%, Precision: 100.00%, Recall: 68.29%, F1: 0.81\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5507, Average Validation Loss: 0.5572, Accuracy: 73.56%, Precision: 100.00%, Recall: 68.38%, F1: 0.81\n","Epoch 1, Average Training Loss: 0.5639, Average Validation Loss: 0.5558, Accuracy: 73.70%, Precision: 100.00%, Recall: 68.50%, F1: 0.81\n","Epoch 1, Average Training Loss: 0.5677, Average Validation Loss: 0.5546, Accuracy: 73.90%, Precision: 100.00%, Recall: 68.66%, F1: 0.81\n","Epoch 1, Average Training Loss: 0.5660, Average Validation Loss: 0.5536, Accuracy: 74.24%, Precision: 100.00%, Recall: 68.95%, F1: 0.82\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5489, Average Validation Loss: 0.5523, Accuracy: 74.55%, Precision: 100.00%, Recall: 69.21%, F1: 0.82\n","Epoch 1, Average Training Loss: 0.5522, Average Validation Loss: 0.5510, Accuracy: 74.76%, Precision: 100.00%, Recall: 69.38%, F1: 0.82\n","Epoch 1, Average Training Loss: 0.5561, Average Validation Loss: 0.5497, Accuracy: 75.03%, Precision: 100.00%, Recall: 69.61%, F1: 0.82\n","Epoch 1, Average Training Loss: 0.5493, Average Validation Loss: 0.5482, Accuracy: 75.33%, Precision: 100.00%, Recall: 69.86%, F1: 0.82\n","Epoch 1, Average Training Loss: 0.5396, Average Validation Loss: 0.5474, Accuracy: 75.44%, Precision: 100.00%, Recall: 69.96%, F1: 0.82\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5363, Average Validation Loss: 0.5459, Accuracy: 75.40%, Precision: 100.00%, Recall: 69.92%, F1: 0.82\n","Epoch 1, Average Training Loss: 0.5528, Average Validation Loss: 0.5444, Accuracy: 75.59%, Precision: 100.00%, Recall: 70.09%, F1: 0.82\n","Epoch 1, Average Training Loss: 0.5513, Average Validation Loss: 0.5437, Accuracy: 75.92%, Precision: 100.00%, Recall: 70.37%, F1: 0.83\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5476, Average Validation Loss: 0.5422, Accuracy: 76.18%, Precision: 100.00%, Recall: 70.59%, F1: 0.83\n","Epoch 1, Average Training Loss: 0.5463, Average Validation Loss: 0.5409, Accuracy: 76.44%, Precision: 100.00%, Recall: 70.82%, F1: 0.83\n","Epoch 1, Average Training Loss: 0.5328, Average Validation Loss: 0.5395, Accuracy: 76.47%, Precision: 100.00%, Recall: 70.85%, F1: 0.83\n","Epoch 1, Average Training Loss: 0.5405, Average Validation Loss: 0.5384, Accuracy: 76.60%, Precision: 100.00%, Recall: 70.96%, F1: 0.83\n","Epoch 1, Average Training Loss: 0.5325, Average Validation Loss: 0.5371, Accuracy: 76.78%, Precision: 100.00%, Recall: 71.13%, F1: 0.83\n","Epoch 1, Average Training Loss: 0.5360, Average Validation Loss: 0.5357, Accuracy: 76.98%, Precision: 100.00%, Recall: 71.30%, F1: 0.83\n","Epoch 1, Average Training Loss: 0.5394, Average Validation Loss: 0.5343, Accuracy: 77.17%, Precision: 100.00%, Recall: 71.47%, F1: 0.83\n","Epoch 1, Average Training Loss: 0.5377, Average Validation Loss: 0.5326, Accuracy: 77.44%, Precision: 100.00%, Recall: 71.71%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5380, Average Validation Loss: 0.5317, Accuracy: 77.61%, Precision: 100.00%, Recall: 71.87%, F1: 0.84\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5327, Average Validation Loss: 0.5304, Accuracy: 77.75%, Precision: 100.00%, Recall: 71.99%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5372, Average Validation Loss: 0.5288, Accuracy: 77.98%, Precision: 100.00%, Recall: 72.20%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5394, Average Validation Loss: 0.5275, Accuracy: 78.26%, Precision: 100.00%, Recall: 72.46%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5331, Average Validation Loss: 0.5263, Accuracy: 78.44%, Precision: 100.00%, Recall: 72.62%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5315, Average Validation Loss: 0.5254, Accuracy: 78.65%, Precision: 100.00%, Recall: 72.82%, F1: 0.84\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 1, Average Training Loss: 0.5213, Average Validation Loss: 0.5237, Accuracy: 78.77%, Precision: 100.00%, Recall: 72.92%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5112, Average Validation Loss: 0.5223, Accuracy: 78.82%, Precision: 100.00%, Recall: 72.98%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5168, Average Validation Loss: 0.5210, Accuracy: 78.91%, Precision: 100.00%, Recall: 73.06%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5215, Average Validation Loss: 0.5193, Accuracy: 79.00%, Precision: 100.00%, Recall: 73.14%, F1: 0.84\n","Epoch 1, Average Training Loss: 0.5190, Average Validation Loss: 0.5179, Accuracy: 79.14%, Precision: 100.00%, Recall: 73.28%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5194, Average Validation Loss: 0.5166, Accuracy: 79.27%, Precision: 100.00%, Recall: 73.39%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5070, Average Validation Loss: 0.5149, Accuracy: 79.38%, Precision: 100.00%, Recall: 73.50%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5146, Average Validation Loss: 0.5132, Accuracy: 79.46%, Precision: 100.00%, Recall: 73.58%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5261, Average Validation Loss: 0.5118, Accuracy: 79.72%, Precision: 100.00%, Recall: 73.82%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5185, Average Validation Loss: 0.5104, Accuracy: 79.91%, Precision: 100.00%, Recall: 74.01%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.4981, Average Validation Loss: 0.5090, Accuracy: 80.01%, Precision: 100.00%, Recall: 74.10%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5021, Average Validation Loss: 0.5073, Accuracy: 80.09%, Precision: 100.00%, Recall: 74.18%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5225, Average Validation Loss: 0.5057, Accuracy: 80.25%, Precision: 100.00%, Recall: 74.33%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5077, Average Validation Loss: 0.5047, Accuracy: 80.50%, Precision: 100.00%, Recall: 74.58%, F1: 0.85\n","Epoch 1, Average Training Loss: 0.5056, Average Validation Loss: 0.5027, Accuracy: 80.68%, Precision: 100.00%, Recall: 74.75%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5056, Average Validation Loss: 0.5015, Accuracy: 80.78%, Precision: 100.00%, Recall: 74.85%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5071, Average Validation Loss: 0.4995, Accuracy: 81.03%, Precision: 100.00%, Recall: 75.10%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5084, Average Validation Loss: 0.4980, Accuracy: 81.25%, Precision: 100.00%, Recall: 75.31%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5048, Average Validation Loss: 0.4965, Accuracy: 81.52%, Precision: 100.00%, Recall: 75.58%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5002, Average Validation Loss: 0.4950, Accuracy: 81.73%, Precision: 100.00%, Recall: 75.79%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.5097, Average Validation Loss: 0.4932, Accuracy: 81.85%, Precision: 100.00%, Recall: 75.91%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.4978, Average Validation Loss: 0.4917, Accuracy: 82.02%, Precision: 100.00%, Recall: 76.08%, F1: 0.86\n","Epoch 1, Average Training Loss: 0.4949, Average Validation Loss: 0.4907, Accuracy: 82.16%, Precision: 100.00%, Recall: 76.22%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4816, Average Validation Loss: 0.4891, Accuracy: 82.16%, Precision: 100.00%, Recall: 76.22%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4879, Average Validation Loss: 0.4867, Accuracy: 82.17%, Precision: 100.00%, Recall: 76.24%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4836, Average Validation Loss: 0.4852, Accuracy: 82.20%, Precision: 100.00%, Recall: 76.27%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4793, Average Validation Loss: 0.4836, Accuracy: 82.26%, Precision: 100.00%, Recall: 76.32%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.5068, Average Validation Loss: 0.4820, Accuracy: 82.40%, Precision: 100.00%, Recall: 76.47%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4891, Average Validation Loss: 0.4807, Accuracy: 82.56%, Precision: 100.00%, Recall: 76.63%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4765, Average Validation Loss: 0.4786, Accuracy: 82.69%, Precision: 100.00%, Recall: 76.77%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4825, Average Validation Loss: 0.4772, Accuracy: 82.83%, Precision: 100.00%, Recall: 76.91%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4851, Average Validation Loss: 0.4752, Accuracy: 82.96%, Precision: 100.00%, Recall: 77.04%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4831, Average Validation Loss: 0.4735, Accuracy: 83.08%, Precision: 100.00%, Recall: 77.17%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4809, Average Validation Loss: 0.4720, Accuracy: 83.24%, Precision: 100.00%, Recall: 77.34%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4711, Average Validation Loss: 0.4700, Accuracy: 83.32%, Precision: 100.00%, Recall: 77.42%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4818, Average Validation Loss: 0.4684, Accuracy: 83.38%, Precision: 100.00%, Recall: 77.49%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4766, Average Validation Loss: 0.4670, Accuracy: 83.44%, Precision: 100.00%, Recall: 77.55%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4649, Average Validation Loss: 0.4654, Accuracy: 83.46%, Precision: 100.00%, Recall: 77.57%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4595, Average Validation Loss: 0.4636, Accuracy: 83.49%, Precision: 100.00%, Recall: 77.60%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4718, Average Validation Loss: 0.4624, Accuracy: 83.56%, Precision: 100.00%, Recall: 77.67%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4627, Average Validation Loss: 0.4601, Accuracy: 83.58%, Precision: 100.00%, Recall: 77.70%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4636, Average Validation Loss: 0.4588, Accuracy: 83.61%, Precision: 100.00%, Recall: 77.72%, F1: 0.87\n","Epoch 1, Average Training Loss: 0.4640, Average Validation Loss: 0.4569, Accuracy: 83.78%, Precision: 99.99%, Recall: 77.91%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4529, Average Validation Loss: 0.4550, Accuracy: 83.82%, Precision: 99.99%, Recall: 77.95%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4564, Average Validation Loss: 0.4529, Accuracy: 83.91%, Precision: 99.99%, Recall: 78.05%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4577, Average Validation Loss: 0.4514, Accuracy: 83.98%, Precision: 99.99%, Recall: 78.12%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4558, Average Validation Loss: 0.4499, Accuracy: 84.05%, Precision: 99.99%, Recall: 78.19%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4487, Average Validation Loss: 0.4479, Accuracy: 84.10%, Precision: 99.99%, Recall: 78.25%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4578, Average Validation Loss: 0.4458, Accuracy: 84.22%, Precision: 99.99%, Recall: 78.38%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4447, Average Validation Loss: 0.4447, Accuracy: 84.30%, Precision: 99.98%, Recall: 78.47%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4578, Average Validation Loss: 0.4423, Accuracy: 84.37%, Precision: 99.98%, Recall: 78.54%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4439, Average Validation Loss: 0.4408, Accuracy: 84.43%, Precision: 99.98%, Recall: 78.61%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4402, Average Validation Loss: 0.4393, Accuracy: 84.47%, Precision: 99.98%, Recall: 78.66%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4380, Average Validation Loss: 0.4372, Accuracy: 84.52%, Precision: 99.98%, Recall: 78.71%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4501, Average Validation Loss: 0.4354, Accuracy: 84.58%, Precision: 99.98%, Recall: 78.77%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4345, Average Validation Loss: 0.4338, Accuracy: 84.60%, Precision: 99.98%, Recall: 78.79%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4409, Average Validation Loss: 0.4323, Accuracy: 84.72%, Precision: 99.98%, Recall: 78.93%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4558, Average Validation Loss: 0.4304, Accuracy: 84.82%, Precision: 99.97%, Recall: 79.04%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4220, Average Validation Loss: 0.4282, Accuracy: 84.89%, Precision: 99.97%, Recall: 79.12%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4502, Average Validation Loss: 0.4263, Accuracy: 85.04%, Precision: 99.96%, Recall: 79.28%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4226, Average Validation Loss: 0.4248, Accuracy: 85.14%, Precision: 99.96%, Recall: 79.39%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4180, Average Validation Loss: 0.4226, Accuracy: 85.15%, Precision: 99.96%, Recall: 79.41%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4104, Average Validation Loss: 0.4212, Accuracy: 85.15%, Precision: 99.96%, Recall: 79.40%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4227, Average Validation Loss: 0.4189, Accuracy: 85.13%, Precision: 99.96%, Recall: 79.38%, F1: 0.88\n","Epoch 1, Average Training Loss: 0.4344, Average Validation Loss: 0.4175, Accuracy: 85.18%, Precision: 99.96%, Recall: 79.43%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4160, Average Validation Loss: 0.4156, Accuracy: 85.23%, Precision: 99.96%, Recall: 79.50%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4275, Average Validation Loss: 0.4137, Accuracy: 85.33%, Precision: 99.96%, Recall: 79.61%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4159, Average Validation Loss: 0.4118, Accuracy: 85.44%, Precision: 99.95%, Recall: 79.74%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4229, Average Validation Loss: 0.4100, Accuracy: 85.50%, Precision: 99.93%, Recall: 79.80%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4131, Average Validation Loss: 0.4081, Accuracy: 85.53%, Precision: 99.93%, Recall: 79.84%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4087, Average Validation Loss: 0.4063, Accuracy: 85.51%, Precision: 99.93%, Recall: 79.82%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4008, Average Validation Loss: 0.4046, Accuracy: 85.48%, Precision: 99.94%, Recall: 79.78%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4136, Average Validation Loss: 0.4028, Accuracy: 85.50%, Precision: 99.93%, Recall: 79.81%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4054, Average Validation Loss: 0.4009, Accuracy: 85.62%, Precision: 99.93%, Recall: 79.94%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.3952, Average Validation Loss: 0.3984, Accuracy: 85.63%, Precision: 99.93%, Recall: 79.95%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4059, Average Validation Loss: 0.3972, Accuracy: 85.74%, Precision: 99.92%, Recall: 80.08%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4057, Average Validation Loss: 0.3949, Accuracy: 85.86%, Precision: 99.90%, Recall: 80.23%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4035, Average Validation Loss: 0.3933, Accuracy: 85.96%, Precision: 99.89%, Recall: 80.35%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.3981, Average Validation Loss: 0.3912, Accuracy: 86.10%, Precision: 99.89%, Recall: 80.50%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4001, Average Validation Loss: 0.3887, Accuracy: 86.26%, Precision: 99.89%, Recall: 80.68%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.3978, Average Validation Loss: 0.3870, Accuracy: 86.31%, Precision: 99.89%, Recall: 80.74%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.3859, Average Validation Loss: 0.3855, Accuracy: 86.37%, Precision: 99.88%, Recall: 80.82%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.3886, Average Validation Loss: 0.3831, Accuracy: 86.40%, Precision: 99.88%, Recall: 80.85%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.4037, Average Validation Loss: 0.3810, Accuracy: 86.50%, Precision: 99.87%, Recall: 80.96%, F1: 0.89\n","Epoch 1, Average Training Loss: 0.3933, Average Validation Loss: 0.3791, Accuracy: 86.70%, Precision: 99.85%, Recall: 81.21%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3919, Average Validation Loss: 0.3773, Accuracy: 86.82%, Precision: 99.84%, Recall: 81.35%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3952, Average Validation Loss: 0.3748, Accuracy: 86.89%, Precision: 99.84%, Recall: 81.43%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3694, Average Validation Loss: 0.3730, Accuracy: 86.97%, Precision: 99.84%, Recall: 81.52%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3837, Average Validation Loss: 0.3702, Accuracy: 87.09%, Precision: 99.81%, Recall: 81.68%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3660, Average Validation Loss: 0.3686, Accuracy: 87.15%, Precision: 99.78%, Recall: 81.76%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3780, Average Validation Loss: 0.3662, Accuracy: 87.18%, Precision: 99.80%, Recall: 81.80%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3785, Average Validation Loss: 0.3641, Accuracy: 87.28%, Precision: 99.78%, Recall: 81.92%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3659, Average Validation Loss: 0.3615, Accuracy: 87.43%, Precision: 99.76%, Recall: 82.11%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.3464, Average Validation Loss: 0.3597, Accuracy: 87.43%, Precision: 99.77%, Recall: 82.10%, F1: 0.90\n","Epoch 1, Average Training Loss: 0.1184, Average Validation Loss: 0.3583, Accuracy: 87.43%, Precision: 99.77%, Recall: 82.10%, F1: 0.90\n","Epoch 2, Average Training Loss: 0.3646, Average Validation Loss: 0.3586, Accuracy: 87.47%, Precision: 99.77%, Recall: 82.15%, F1: 0.90\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.3664, Average Validation Loss: 0.3582, Accuracy: 87.48%, Precision: 99.77%, Recall: 82.16%, F1: 0.90\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.3581, Average Validation Loss: 0.3568, Accuracy: 87.48%, Precision: 99.77%, Recall: 82.16%, F1: 0.90\n","Epoch 2, Average Training Loss: 0.3682, Average Validation Loss: 0.3556, Accuracy: 87.51%, Precision: 99.77%, Recall: 82.20%, F1: 0.90\n","Epoch 2, Average Training Loss: 0.3663, Average Validation Loss: 0.3542, Accuracy: 87.59%, Precision: 99.75%, Recall: 82.31%, F1: 0.90\n","Epoch 2, Average Training Loss: 0.3627, Average Validation Loss: 0.3522, Accuracy: 87.68%, Precision: 99.74%, Recall: 82.42%, F1: 0.90\n","Epoch 2, Average Training Loss: 0.3528, Average Validation Loss: 0.3496, Accuracy: 87.85%, Precision: 99.73%, Recall: 82.62%, F1: 0.90\n","Epoch 2, Average Training Loss: 0.3692, Average Validation Loss: 0.3467, Accuracy: 88.18%, Precision: 99.71%, Recall: 83.03%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3571, Average Validation Loss: 0.3434, Accuracy: 88.55%, Precision: 99.67%, Recall: 83.51%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3343, Average Validation Loss: 0.3401, Accuracy: 88.70%, Precision: 99.67%, Recall: 83.68%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3426, Average Validation Loss: 0.3371, Accuracy: 88.77%, Precision: 99.67%, Recall: 83.77%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3498, Average Validation Loss: 0.3335, Accuracy: 88.80%, Precision: 99.70%, Recall: 83.79%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3353, Average Validation Loss: 0.3304, Accuracy: 88.85%, Precision: 99.70%, Recall: 83.86%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3304, Average Validation Loss: 0.3268, Accuracy: 88.88%, Precision: 99.72%, Recall: 83.89%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3200, Average Validation Loss: 0.3234, Accuracy: 88.89%, Precision: 99.72%, Recall: 83.90%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3202, Average Validation Loss: 0.3195, Accuracy: 88.91%, Precision: 99.73%, Recall: 83.90%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3382, Average Validation Loss: 0.3161, Accuracy: 89.10%, Precision: 99.73%, Recall: 84.15%, F1: 0.91\n","Epoch 2, Average Training Loss: 0.3142, Average Validation Loss: 0.3114, Accuracy: 89.55%, Precision: 99.71%, Recall: 84.73%, F1: 0.92\n","Epoch 2, Average Training Loss: 0.3237, Average Validation Loss: 0.3071, Accuracy: 89.96%, Precision: 99.67%, Recall: 85.26%, F1: 0.92\n","Epoch 2, Average Training Loss: 0.3197, Average Validation Loss: 0.3018, Accuracy: 90.45%, Precision: 99.66%, Recall: 85.91%, F1: 0.92\n","Epoch 2, Average Training Loss: 0.3004, Average Validation Loss: 0.2978, Accuracy: 90.72%, Precision: 99.66%, Recall: 86.25%, F1: 0.92\n","Epoch 2, Average Training Loss: 0.3036, Average Validation Loss: 0.2927, Accuracy: 91.03%, Precision: 99.65%, Recall: 86.66%, F1: 0.93\n","Epoch 2, Average Training Loss: 0.2992, Average Validation Loss: 0.2871, Accuracy: 91.24%, Precision: 99.65%, Recall: 86.94%, F1: 0.93\n","Epoch 2, Average Training Loss: 0.2913, Average Validation Loss: 0.2822, Accuracy: 91.56%, Precision: 99.65%, Recall: 87.37%, F1: 0.93\n","Epoch 2, Average Training Loss: 0.2811, Average Validation Loss: 0.2767, Accuracy: 92.04%, Precision: 99.64%, Recall: 88.02%, F1: 0.93\n","Epoch 2, Average Training Loss: 0.2937, Average Validation Loss: 0.2706, Accuracy: 92.36%, Precision: 99.64%, Recall: 88.46%, F1: 0.94\n","Epoch 2, Average Training Loss: 0.2820, Average Validation Loss: 0.2643, Accuracy: 92.99%, Precision: 99.63%, Recall: 89.33%, F1: 0.94\n","Epoch 2, Average Training Loss: 0.2704, Average Validation Loss: 0.2577, Accuracy: 93.50%, Precision: 99.59%, Recall: 90.09%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2587, Average Validation Loss: 0.2514, Accuracy: 93.73%, Precision: 99.62%, Recall: 90.39%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2578, Average Validation Loss: 0.2450, Accuracy: 94.11%, Precision: 99.62%, Recall: 90.95%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2466, Average Validation Loss: 0.2376, Accuracy: 94.42%, Precision: 99.63%, Recall: 91.39%, F1: 0.95\n","Epoch 2, Average Training Loss: 0.2326, Average Validation Loss: 0.2311, Accuracy: 94.66%, Precision: 99.64%, Recall: 91.73%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2376, Average Validation Loss: 0.2247, Accuracy: 94.96%, Precision: 99.64%, Recall: 92.18%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2293, Average Validation Loss: 0.2177, Accuracy: 95.00%, Precision: 99.73%, Recall: 92.18%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2312, Average Validation Loss: 0.2103, Accuracy: 95.54%, Precision: 99.68%, Recall: 93.02%, F1: 0.96\n","Epoch 2, Average Training Loss: 0.2153, Average Validation Loss: 0.2030, Accuracy: 96.00%, Precision: 99.67%, Recall: 93.72%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.2203, Average Validation Loss: 0.1956, Accuracy: 96.22%, Precision: 99.70%, Recall: 94.05%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.2054, Average Validation Loss: 0.1882, Accuracy: 96.53%, Precision: 99.70%, Recall: 94.54%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1872, Average Validation Loss: 0.1809, Accuracy: 96.93%, Precision: 99.70%, Recall: 95.17%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1903, Average Validation Loss: 0.1742, Accuracy: 97.07%, Precision: 99.74%, Recall: 95.36%, F1: 0.97\n","Epoch 2, Average Training Loss: 0.1840, Average Validation Loss: 0.1680, Accuracy: 97.30%, Precision: 99.76%, Recall: 95.71%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1612, Average Validation Loss: 0.1615, Accuracy: 97.47%, Precision: 99.80%, Recall: 95.94%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1679, Average Validation Loss: 0.1564, Accuracy: 97.56%, Precision: 99.81%, Recall: 96.07%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1718, Average Validation Loss: 0.1497, Accuracy: 97.78%, Precision: 99.81%, Recall: 96.44%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1628, Average Validation Loss: 0.1439, Accuracy: 98.00%, Precision: 99.80%, Recall: 96.80%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1629, Average Validation Loss: 0.1388, Accuracy: 98.18%, Precision: 99.81%, Recall: 97.10%, F1: 0.98\n","Epoch 2, Average Training Loss: 0.1478, Average Validation Loss: 0.1341, Accuracy: 98.30%, Precision: 99.81%, Recall: 97.28%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1461, Average Validation Loss: 0.1296, Accuracy: 98.35%, Precision: 99.81%, Recall: 97.37%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1293, Average Validation Loss: 0.1256, Accuracy: 98.37%, Precision: 99.84%, Recall: 97.37%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1370, Average Validation Loss: 0.1219, Accuracy: 98.41%, Precision: 99.88%, Recall: 97.40%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1229, Average Validation Loss: 0.1185, Accuracy: 98.47%, Precision: 99.88%, Recall: 97.51%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1206, Average Validation Loss: 0.1154, Accuracy: 98.52%, Precision: 99.88%, Recall: 97.59%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1228, Average Validation Loss: 0.1123, Accuracy: 98.63%, Precision: 99.89%, Recall: 97.76%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1261, Average Validation Loss: 0.1091, Accuracy: 98.69%, Precision: 99.88%, Recall: 97.88%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1086, Average Validation Loss: 0.1072, Accuracy: 98.72%, Precision: 99.90%, Recall: 97.91%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1200, Average Validation Loss: 0.1037, Accuracy: 98.80%, Precision: 99.88%, Recall: 98.06%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1091, Average Validation Loss: 0.1013, Accuracy: 98.85%, Precision: 99.87%, Recall: 98.15%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0998, Average Validation Loss: 0.0990, Accuracy: 98.85%, Precision: 99.88%, Recall: 98.15%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1163, Average Validation Loss: 0.0972, Accuracy: 98.87%, Precision: 99.91%, Recall: 98.15%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1112, Average Validation Loss: 0.0951, Accuracy: 98.90%, Precision: 99.91%, Recall: 98.20%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0988, Average Validation Loss: 0.0934, Accuracy: 98.94%, Precision: 99.91%, Recall: 98.26%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0906, Average Validation Loss: 0.0918, Accuracy: 98.94%, Precision: 99.92%, Recall: 98.25%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0937, Average Validation Loss: 0.0898, Accuracy: 98.94%, Precision: 99.93%, Recall: 98.25%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1029, Average Validation Loss: 0.0882, Accuracy: 98.99%, Precision: 99.93%, Recall: 98.34%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0858, Average Validation Loss: 0.0871, Accuracy: 99.01%, Precision: 99.93%, Recall: 98.36%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.1029, Average Validation Loss: 0.0852, Accuracy: 99.03%, Precision: 99.92%, Recall: 98.42%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0976, Average Validation Loss: 0.0840, Accuracy: 99.05%, Precision: 99.91%, Recall: 98.45%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0827, Average Validation Loss: 0.0828, Accuracy: 99.04%, Precision: 99.92%, Recall: 98.42%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0931, Average Validation Loss: 0.0816, Accuracy: 99.04%, Precision: 99.93%, Recall: 98.42%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0801, Average Validation Loss: 0.0803, Accuracy: 99.05%, Precision: 99.95%, Recall: 98.41%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0906, Average Validation Loss: 0.0792, Accuracy: 99.05%, Precision: 99.95%, Recall: 98.42%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0809, Average Validation Loss: 0.0782, Accuracy: 99.05%, Precision: 99.95%, Recall: 98.42%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0783, Average Validation Loss: 0.0772, Accuracy: 99.05%, Precision: 99.95%, Recall: 98.42%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0774, Average Validation Loss: 0.0763, Accuracy: 99.06%, Precision: 99.96%, Recall: 98.43%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0782, Average Validation Loss: 0.0754, Accuracy: 99.07%, Precision: 99.97%, Recall: 98.43%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0838, Average Validation Loss: 0.0745, Accuracy: 99.07%, Precision: 99.97%, Recall: 98.43%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0839, Average Validation Loss: 0.0740, Accuracy: 99.08%, Precision: 99.96%, Recall: 98.46%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0779, Average Validation Loss: 0.0733, Accuracy: 99.09%, Precision: 99.96%, Recall: 98.47%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0878, Average Validation Loss: 0.0722, Accuracy: 99.10%, Precision: 99.96%, Recall: 98.49%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0792, Average Validation Loss: 0.0717, Accuracy: 99.12%, Precision: 99.97%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0704, Average Validation Loss: 0.0706, Accuracy: 99.11%, Precision: 99.97%, Recall: 98.50%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0788, Average Validation Loss: 0.0699, Accuracy: 99.12%, Precision: 99.97%, Recall: 98.51%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0587, Average Validation Loss: 0.0694, Accuracy: 99.11%, Precision: 99.98%, Recall: 98.50%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0725, Average Validation Loss: 0.0692, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.48%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0810, Average Validation Loss: 0.0681, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.47%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0809, Average Validation Loss: 0.0675, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.48%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0762, Average Validation Loss: 0.0671, Accuracy: 99.12%, Precision: 99.99%, Recall: 98.50%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0620, Average Validation Loss: 0.0666, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0743, Average Validation Loss: 0.0658, Accuracy: 99.12%, Precision: 99.99%, Recall: 98.50%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0622, Average Validation Loss: 0.0652, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.49%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0628, Average Validation Loss: 0.0647, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.48%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0655, Average Validation Loss: 0.0643, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.47%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0755, Average Validation Loss: 0.0638, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.49%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0628, Average Validation Loss: 0.0637, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0636, Average Validation Loss: 0.0632, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0686, Average Validation Loss: 0.0623, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0503, Average Validation Loss: 0.0624, Accuracy: 99.11%, Precision: 99.99%, Recall: 98.48%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0632, Average Validation Loss: 0.0615, Accuracy: 99.12%, Precision: 99.99%, Recall: 98.49%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0615, Average Validation Loss: 0.0612, Accuracy: 99.12%, Precision: 99.99%, Recall: 98.49%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0713, Average Validation Loss: 0.0607, Accuracy: 99.12%, Precision: 99.99%, Recall: 98.50%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0590, Average Validation Loss: 0.0603, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0601, Average Validation Loss: 0.0599, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0635, Average Validation Loss: 0.0595, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0565, Average Validation Loss: 0.0592, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.51%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0658, Average Validation Loss: 0.0588, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.50%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0666, Average Validation Loss: 0.0588, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0534, Average Validation Loss: 0.0581, Accuracy: 99.14%, Precision: 99.99%, Recall: 98.53%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0645, Average Validation Loss: 0.0577, Accuracy: 99.14%, Precision: 99.99%, Recall: 98.53%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0536, Average Validation Loss: 0.0574, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0648, Average Validation Loss: 0.0571, Accuracy: 99.14%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0524, Average Validation Loss: 0.0571, Accuracy: 99.14%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 2, Average Training Loss: 0.0545, Average Validation Loss: 0.0565, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0491, Average Validation Loss: 0.0562, Accuracy: 99.13%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0636, Average Validation Loss: 0.0559, Accuracy: 99.14%, Precision: 99.99%, Recall: 98.52%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0655, Average Validation Loss: 0.0556, Accuracy: 99.16%, Precision: 99.99%, Recall: 98.55%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 2, Average Training Loss: 0.0566, Average Validation Loss: 0.0552, Accuracy: 99.16%, Precision: 99.99%, Recall: 98.56%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0563, Average Validation Loss: 0.0556, Accuracy: 99.16%, Precision: 99.99%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0606, Average Validation Loss: 0.0548, Accuracy: 99.16%, Precision: 99.99%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0507, Average Validation Loss: 0.0545, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 2, Average Training Loss: 0.0646, Average Validation Loss: 0.0544, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.57%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 2, Average Training Loss: 0.0505, Average Validation Loss: 0.0539, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.58%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0539, Average Validation Loss: 0.0543, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.58%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0591, Average Validation Loss: 0.0539, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.58%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0613, Average Validation Loss: 0.0531, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.58%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 2, Average Training Loss: 0.0534, Average Validation Loss: 0.0529, Accuracy: 99.17%, Precision: 99.99%, Recall: 98.58%, F1: 0.99\n","Epoch 2, Average Training Loss: 0.0516, Average Validation Loss: 0.0526, Accuracy: 99.18%, Precision: 99.99%, Recall: 98.59%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 2, Average Training Loss: 0.0507, Average Validation Loss: 0.0523, Accuracy: 99.18%, Precision: 99.99%, Recall: 98.60%, F1: 0.99\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 2, Average Training Loss: 0.0739, Average Validation Loss: 0.0525, Accuracy: 99.18%, Precision: 99.99%, Recall: 98.60%, F1: 0.99\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 2, Average Training Loss: 0.0716, Average Validation Loss: 0.0522, Accuracy: 99.19%, Precision: 99.99%, Recall: 98.62%, F1: 0.99\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 2, Average Training Loss: 0.0494, Average Validation Loss: 0.0519, Accuracy: 99.19%, Precision: 99.99%, Recall: 98.62%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 2: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 16:36:15,502] Trial 30 finished with value: 0.05172136248768987 and parameters: {'vector_length': 256, 'hidden_length': 256, 'num_layers': 2, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 128, 'lr': 1.3088561315523223e-06, 'warmup_steps': 80}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4592, Average Validation Loss: 0.1183, Accuracy: 98.78%, Precision: 99.63%, Recall: 98.26%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0364, Average Validation Loss: 0.0050, Accuracy: 99.84%, Precision: 99.85%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0303, Average Validation Loss: 0.0057, Accuracy: 99.83%, Precision: 99.78%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0079, Average Validation Loss: 0.0036, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0007, Average Validation Loss: 0.0090, Accuracy: 99.74%, Precision: 99.99%, Recall: 99.56%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0166, Average Validation Loss: 0.0015, Accuracy: 99.95%, Precision: 99.94%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0054, Average Validation Loss: 0.0024, Accuracy: 99.91%, Precision: 99.85%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0013, Accuracy: 99.95%, Precision: 100.00%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0020, Accuracy: 99.94%, Precision: 100.00%, Recall: 99.89%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0012, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0015, Average Validation Loss: 0.0031, Accuracy: 99.90%, Precision: 99.83%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 16:39:04,036] Trial 31 finished with value: 0.003126082861156438 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.0014094192183308138, 'warmup_steps': 50}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3698, Average Validation Loss: 0.0311, Accuracy: 99.57%, Precision: 99.87%, Recall: 99.37%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0162, Average Validation Loss: 0.0097, Accuracy: 99.68%, Precision: 99.94%, Recall: 99.50%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0113, Average Validation Loss: 0.0065, Accuracy: 99.82%, Precision: 99.76%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0022, Accuracy: 99.94%, Precision: 99.93%, Recall: 99.97%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0023, Average Validation Loss: 0.0052, Accuracy: 99.91%, Precision: 100.00%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0048, Average Validation Loss: 0.0048, Accuracy: 99.88%, Precision: 99.87%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0096, Average Validation Loss: 0.0015, Accuracy: 99.97%, Precision: 99.97%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0023, Accuracy: 99.95%, Precision: 99.92%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0047, Average Validation Loss: 0.0014, Accuracy: 99.97%, Precision: 99.99%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 16:41:22,730] Trial 32 finished with value: 0.001423090674892978 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 1, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.0010556695553164042, 'warmup_steps': 20}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 193,054,720 parameters\n","Num non-decayed parameter tensors: 11, with 69,634 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4152, Average Validation Loss: 0.0848, Accuracy: 98.71%, Precision: 99.62%, Recall: 98.14%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0332, Average Validation Loss: 0.0093, Accuracy: 99.68%, Precision: 99.93%, Recall: 99.51%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0043, Average Validation Loss: 0.0032, Accuracy: 99.91%, Precision: 99.90%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0061, Accuracy: 99.86%, Precision: 99.96%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0067, Average Validation Loss: 0.0045, Accuracy: 99.90%, Precision: 99.91%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0037, Accuracy: 99.93%, Precision: 99.92%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0178, Accuracy: 99.56%, Precision: 99.29%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0095, Average Validation Loss: 0.0062, Accuracy: 99.84%, Precision: 99.87%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 16:45:54,350] Trial 33 finished with value: 0.00613142331340478 and parameters: {'vector_length': 2048, 'hidden_length': 2048, 'num_layers': 2, 'num_epochs': 3, 'dropout': 0.30000000000000004, 'metadata_vector_length': 2048, 'lr': 0.002150135513572898, 'warmup_steps': 90}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 69,263,872 parameters\n","Num non-decayed parameter tensors: 15, with 51,202 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5833, Average Validation Loss: 0.3347, Accuracy: 89.97%, Precision: 99.98%, Recall: 85.09%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.1746, Average Validation Loss: 0.0512, Accuracy: 98.39%, Precision: 99.98%, Recall: 97.29%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0095, Accuracy: 99.72%, Precision: 99.96%, Recall: 99.56%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0104, Average Validation Loss: 0.0037, Accuracy: 99.88%, Precision: 99.98%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0079, Average Validation Loss: 0.0023, Accuracy: 99.94%, Precision: 99.92%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0022, Accuracy: 99.93%, Precision: 99.90%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0017, Accuracy: 99.95%, Precision: 99.96%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0019, Accuracy: 99.94%, Precision: 99.98%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0014, Accuracy: 99.96%, Precision: 99.95%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0014, Accuracy: 99.96%, Precision: 99.95%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 16:49:03,356] Trial 34 finished with value: 0.001364990693793909 and parameters: {'vector_length': 512, 'hidden_length': 1024, 'num_layers': 3, 'num_epochs': 5, 'dropout': 0.4, 'metadata_vector_length': 1024, 'lr': 0.0006145596057896085, 'warmup_steps': 30}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 24, with 119,595,520 parameters\n","Num non-decayed parameter tensors: 23, with 83,970 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5833, Average Validation Loss: 0.3823, Accuracy: 81.56%, Precision: 100.00%, Recall: 75.61%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.1894, Average Validation Loss: 0.0573, Accuracy: 99.44%, Precision: 99.79%, Recall: 99.23%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0055, Accuracy: 99.83%, Precision: 99.92%, Recall: 99.79%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0038, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.80%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0029, Accuracy: 99.91%, Precision: 99.99%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0011, Average Validation Loss: 0.0016, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0017, Accuracy: 99.96%, Precision: 99.96%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0013, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0033, Accuracy: 99.92%, Precision: 100.00%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0074, Average Validation Loss: 0.0011, Accuracy: 99.96%, Precision: 99.98%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0030, Accuracy: 99.89%, Precision: 99.83%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 16:54:10,510] Trial 35 finished with value: 0.0029757084472441567 and parameters: {'vector_length': 512, 'hidden_length': 1024, 'num_layers': 5, 'num_epochs': 5, 'dropout': 0.5, 'metadata_vector_length': 1024, 'lr': 0.0005649425891216698, 'warmup_steps': 30}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 250,673,664 parameters\n","Num non-decayed parameter tensors: 15, with 101,378 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4473, Average Validation Loss: 0.1225, Accuracy: 98.98%, Precision: 98.81%, Recall: 99.40%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0497, Average Validation Loss: 0.0155, Accuracy: 99.56%, Precision: 99.80%, Recall: 99.43%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0081, Average Validation Loss: 0.0116, Accuracy: 99.70%, Precision: 99.53%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0040, Average Validation Loss: 0.0038, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0034, Average Validation Loss: 0.0046, Accuracy: 99.90%, Precision: 99.91%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 1.8496, Average Validation Loss: 0.0037, Accuracy: 99.88%, Precision: 99.92%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0073, Average Validation Loss: 0.0065, Accuracy: 99.81%, Precision: 99.78%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0057, Average Validation Loss: 0.0038, Accuracy: 99.88%, Precision: 99.89%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0116, Average Validation Loss: 0.0057, Accuracy: 99.79%, Precision: 99.99%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:01:09,551] Trial 36 finished with value: 0.005759257425528926 and parameters: {'vector_length': 512, 'hidden_length': 2048, 'num_layers': 3, 'num_epochs': 2, 'dropout': 0.4, 'metadata_vector_length': 1024, 'lr': 0.0003627365214488789, 'warmup_steps': 10}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 22,599,168 parameters\n","Num non-decayed parameter tensors: 15, with 26,114 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6716, Average Validation Loss: 0.6332, Accuracy: 90.39%, Precision: 99.97%, Recall: 85.63%, F1: 0.92\n","Epoch 0, Average Training Loss: 0.5779, Average Validation Loss: 0.4951, Accuracy: 80.64%, Precision: 100.00%, Recall: 74.71%, F1: 0.86\n","Epoch 0, Average Training Loss: 0.4141, Average Validation Loss: 0.2861, Accuracy: 92.82%, Precision: 99.96%, Recall: 88.87%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.1877, Average Validation Loss: 0.0524, Accuracy: 98.93%, Precision: 100.00%, Recall: 98.16%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0236, Accuracy: 99.39%, Precision: 100.00%, Recall: 98.94%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0324, Average Validation Loss: 0.0206, Accuracy: 99.65%, Precision: 99.85%, Recall: 99.54%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0176, Average Validation Loss: 0.0153, Accuracy: 99.55%, Precision: 99.99%, Recall: 99.23%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0067, Average Validation Loss: 0.0125, Accuracy: 99.67%, Precision: 99.98%, Recall: 99.45%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0087, Average Validation Loss: 0.0114, Accuracy: 99.69%, Precision: 99.98%, Recall: 99.49%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0096, Average Validation Loss: 0.0137, Accuracy: 99.56%, Precision: 100.00%, Recall: 99.23%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0210, Average Validation Loss: 0.0106, Accuracy: 99.77%, Precision: 99.95%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0264, Average Validation Loss: 0.0112, Accuracy: 99.85%, Precision: 99.93%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0096, Accuracy: 99.72%, Precision: 99.99%, Recall: 99.53%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0170, Average Validation Loss: 0.0079, Accuracy: 99.83%, Precision: 99.97%, Recall: 99.73%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0092, Average Validation Loss: 0.0085, Accuracy: 99.89%, Precision: 99.96%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0093, Average Validation Loss: 0.0061, Accuracy: 99.87%, Precision: 99.97%, Recall: 99.80%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0055, Average Validation Loss: 0.0054, Accuracy: 99.87%, Precision: 99.97%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0038, Average Validation Loss: 0.0050, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0046, Accuracy: 99.89%, Precision: 99.98%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0044, Accuracy: 99.89%, Precision: 99.98%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0020, Average Validation Loss: 0.0041, Accuracy: 99.89%, Precision: 99.98%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0038, Accuracy: 99.90%, Precision: 99.97%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0040, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0035, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0036, Accuracy: 99.92%, Precision: 99.97%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0035, Accuracy: 99.93%, Precision: 99.97%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0031, Average Validation Loss: 0.0030, Accuracy: 99.91%, Precision: 99.98%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:07:04,312] Trial 37 finished with value: 0.003017196332645678 and parameters: {'vector_length': 512, 'hidden_length': 512, 'num_layers': 3, 'num_epochs': 1, 'dropout': 0.4, 'metadata_vector_length': 1024, 'lr': 0.0001584096442149725, 'warmup_steps': 40}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 6,777,088 parameters\n","Num non-decayed parameter tensors: 15, with 6,786 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6494, Average Validation Loss: 0.5454, Accuracy: 84.25%, Precision: 99.96%, Recall: 78.43%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.3874, Average Validation Loss: 0.1622, Accuracy: 98.23%, Precision: 99.80%, Recall: 97.18%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0660, Average Validation Loss: 0.0118, Accuracy: 99.69%, Precision: 99.96%, Recall: 99.50%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0140, Average Validation Loss: 0.0068, Accuracy: 99.81%, Precision: 99.91%, Recall: 99.76%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0068, Average Validation Loss: 0.0056, Accuracy: 99.83%, Precision: 99.92%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0116, Average Validation Loss: 0.0050, Accuracy: 99.86%, Precision: 99.90%, Recall: 99.85%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0061, Average Validation Loss: 0.0048, Accuracy: 99.86%, Precision: 99.97%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0049, Accuracy: 99.87%, Precision: 99.84%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0035, Accuracy: 99.88%, Precision: 99.97%, Recall: 99.82%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0032, Accuracy: 99.88%, Precision: 99.97%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0029, Accuracy: 99.92%, Precision: 99.97%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0060, Average Validation Loss: 0.0025, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0032, Average Validation Loss: 0.0028, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0022, Accuracy: 99.95%, Precision: 99.96%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0019, Accuracy: 99.95%, Precision: 99.98%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0022, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0034, Average Validation Loss: 0.0022, Accuracy: 99.95%, Precision: 99.96%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:10:24,051] Trial 38 finished with value: 0.0021868258393943824 and parameters: {'vector_length': 512, 'hidden_length': 128, 'num_layers': 3, 'num_epochs': 5, 'dropout': 0.5, 'metadata_vector_length': 512, 'lr': 0.0007657146317084891, 'warmup_steps': 20}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 20, with 89,710,848 parameters\n","Num non-decayed parameter tensors: 19, with 67,586 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6869, Average Validation Loss: 0.6728, Accuracy: 77.55%, Precision: 99.10%, Recall: 72.10%, F1: 0.83\n","Epoch 0, Average Training Loss: 0.6521, Average Validation Loss: 0.6189, Accuracy: 74.17%, Precision: 99.95%, Recall: 68.90%, F1: 0.82\n","Epoch 0, Average Training Loss: 0.5906, Average Validation Loss: 0.5353, Accuracy: 78.30%, Precision: 99.99%, Recall: 72.50%, F1: 0.84\n","Epoch 0, Average Training Loss: 0.4771, Average Validation Loss: 0.4030, Accuracy: 85.17%, Precision: 99.99%, Recall: 79.42%, F1: 0.89\n","Epoch 0, Average Training Loss: 0.3232, Average Validation Loss: 0.2480, Accuracy: 91.27%, Precision: 95.41%, Recall: 89.93%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.1958, Average Validation Loss: 0.1231, Accuracy: 97.80%, Precision: 98.84%, Recall: 97.36%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0648, Average Validation Loss: 0.0265, Accuracy: 99.09%, Precision: 99.91%, Recall: 98.52%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0282, Average Validation Loss: 0.0256, Accuracy: 99.39%, Precision: 99.78%, Recall: 99.17%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0232, Average Validation Loss: 0.0255, Accuracy: 99.46%, Precision: 99.82%, Recall: 99.23%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0244, Average Validation Loss: 0.0216, Accuracy: 99.51%, Precision: 99.87%, Recall: 99.28%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0179, Average Validation Loss: 0.0222, Accuracy: 99.52%, Precision: 99.75%, Recall: 99.41%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0175, Average Validation Loss: 0.0160, Accuracy: 99.54%, Precision: 99.95%, Recall: 99.26%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0157, Accuracy: 99.53%, Precision: 99.99%, Recall: 99.18%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0169, Average Validation Loss: 0.0175, Accuracy: 99.66%, Precision: 99.96%, Recall: 99.45%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0147, Average Validation Loss: 0.0139, Accuracy: 99.67%, Precision: 99.93%, Recall: 99.49%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0241, Accuracy: 99.77%, Precision: 99.77%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0139, Average Validation Loss: 0.0108, Accuracy: 99.60%, Precision: 99.96%, Recall: 99.35%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0205, Average Validation Loss: 0.0125, Accuracy: 99.63%, Precision: 100.00%, Recall: 99.36%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0107, Average Validation Loss: 0.0111, Accuracy: 99.78%, Precision: 100.00%, Recall: 99.62%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0090, Average Validation Loss: 0.0089, Accuracy: 99.79%, Precision: 100.00%, Recall: 99.64%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0133, Average Validation Loss: 0.0089, Accuracy: 99.89%, Precision: 100.00%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0054, Average Validation Loss: 0.0071, Accuracy: 99.77%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0183, Average Validation Loss: 0.0075, Accuracy: 99.87%, Precision: 99.99%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0125, Average Validation Loss: 0.0081, Accuracy: 99.89%, Precision: 100.00%, Recall: 99.81%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0107, Average Validation Loss: 0.0063, Accuracy: 99.89%, Precision: 100.00%, Recall: 99.80%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0094, Average Validation Loss: 0.0057, Accuracy: 99.83%, Precision: 100.00%, Recall: 99.70%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0079, Average Validation Loss: 0.0059, Accuracy: 99.80%, Precision: 100.00%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0086, Average Validation Loss: 0.0056, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0063, Accuracy: 99.76%, Precision: 100.00%, Recall: 99.59%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0089, Average Validation Loss: 0.0073, Accuracy: 99.83%, Precision: 99.95%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0069, Average Validation Loss: 0.0207, Accuracy: 99.19%, Precision: 100.00%, Recall: 98.61%, F1: 0.99\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:21:58,819] Trial 39 finished with value: 0.02071508884530615 and parameters: {'vector_length': 256, 'hidden_length': 1024, 'num_layers': 4, 'num_epochs': 4, 'dropout': 0.1, 'metadata_vector_length': 1024, 'lr': 6.243902412843496e-05, 'warmup_steps': 60}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 16, with 68,439,040 parameters\n","Num non-decayed parameter tensors: 15, with 50,434 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5748, Average Validation Loss: 0.4476, Accuracy: 84.38%, Precision: 99.99%, Recall: 78.56%, F1: 0.88\n","Epoch 0, Average Training Loss: 0.1851, Average Validation Loss: 0.0256, Accuracy: 99.42%, Precision: 99.56%, Recall: 99.42%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0219, Average Validation Loss: 0.0127, Accuracy: 99.80%, Precision: 99.69%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0060, Average Validation Loss: 0.1279, Accuracy: 98.41%, Precision: 97.26%, Recall: 99.96%, F1: 0.99\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0166, Average Validation Loss: 0.0040, Accuracy: 99.87%, Precision: 99.93%, Recall: 99.85%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0023, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0005, Average Validation Loss: 0.0015, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0033, Average Validation Loss: 0.0041, Accuracy: 99.86%, Precision: 99.77%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0069, Average Validation Loss: 0.0010, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0012, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0010, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0007, Average Validation Loss: 0.0083, Accuracy: 99.89%, Precision: 99.88%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.0088, Accuracy: 99.78%, Precision: 99.93%, Recall: 99.67%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0074, Accuracy: 99.77%, Precision: 99.65%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:26:17,986] Trial 40 finished with value: 0.007390505028259311 and parameters: {'vector_length': 512, 'hidden_length': 1024, 'num_layers': 3, 'num_epochs': 1, 'dropout': 0.4, 'metadata_vector_length': 256, 'lr': 0.003935501779709027, 'warmup_steps': 100}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.4121, Average Validation Loss: 0.1004, Accuracy: 95.98%, Precision: 99.96%, Recall: 93.46%, F1: 0.97\n","Epoch 0, Average Training Loss: 0.0319, Average Validation Loss: 0.0080, Accuracy: 99.79%, Precision: 99.73%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0075, Accuracy: 99.77%, Precision: 99.75%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0055, Average Validation Loss: 0.0045, Accuracy: 99.89%, Precision: 99.89%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0056, Average Validation Loss: 0.0028, Accuracy: 99.89%, Precision: 99.84%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0036, Average Validation Loss: 0.0032, Accuracy: 99.90%, Precision: 99.91%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0010, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0010, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0015, Accuracy: 99.95%, Precision: 99.93%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0006, Average Validation Loss: 0.0008, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0028, Average Validation Loss: 0.0006, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0009, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:29:18,257] Trial 41 finished with value: 0.0008890133735177015 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0017791099300147738, 'warmup_steps': 50}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3554, Average Validation Loss: 0.0383, Accuracy: 99.20%, Precision: 98.76%, Recall: 99.84%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0221, Average Validation Loss: 0.0121, Accuracy: 99.63%, Precision: 99.41%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0047, Average Validation Loss: 0.0058, Accuracy: 99.86%, Precision: 99.98%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0139, Accuracy: 99.63%, Precision: 99.43%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0198, Accuracy: 99.67%, Precision: 100.00%, Recall: 99.43%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0268, Average Validation Loss: 0.0145, Accuracy: 99.75%, Precision: 99.57%, Recall: 100.00%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0315, Average Validation Loss: 0.0029, Accuracy: 99.92%, Precision: 99.87%, Recall: 99.99%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0109, Average Validation Loss: 0.0012, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.98%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0006, Accuracy: 99.98%, Precision: 99.97%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0009, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0008, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0006, Accuracy: 99.98%, Precision: 99.97%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0005, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:32:33,316] Trial 42 finished with value: 0.0010232214287326142 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0021553191571889244, 'warmup_steps': 40}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2277, Average Validation Loss: 0.0223, Accuracy: 99.20%, Precision: 98.83%, Recall: 99.78%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0171, Average Validation Loss: 0.0251, Accuracy: 99.79%, Precision: 99.78%, Recall: 99.86%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0309, Average Validation Loss: 0.0270, Accuracy: 99.65%, Precision: 99.51%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0306, Average Validation Loss: 0.0108, Accuracy: 99.85%, Precision: 99.90%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0283, Average Validation Loss: 0.0192, Accuracy: 99.77%, Precision: 99.96%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0090, Average Validation Loss: 0.0254, Accuracy: 99.85%, Precision: 99.96%, Recall: 99.78%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0168, Accuracy: 99.91%, Precision: 100.00%, Recall: 99.84%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0087, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0065, Accuracy: 99.97%, Precision: 99.98%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0551, Average Validation Loss: 0.0173, Accuracy: 99.88%, Precision: 99.82%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0654, Average Validation Loss: 0.0163, Accuracy: 99.83%, Precision: 99.72%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0369, Average Validation Loss: 0.0455, Accuracy: 99.68%, Precision: 99.47%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0266, Average Validation Loss: 0.0277, Accuracy: 99.87%, Precision: 99.81%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0706, Average Validation Loss: 0.0390, Accuracy: 99.90%, Precision: 99.96%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:36:02,189] Trial 43 finished with value: 0.0389202524278615 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.007759911684657365, 'warmup_steps': 50}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 73,510,912 parameters\n","Num non-decayed parameter tensors: 11, with 35,842 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3174, Average Validation Loss: 0.0380, Accuracy: 98.82%, Precision: 98.04%, Recall: 99.89%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0138, Average Validation Loss: 0.0097, Accuracy: 99.75%, Precision: 99.90%, Recall: 99.66%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0216, Average Validation Loss: 0.0092, Accuracy: 99.80%, Precision: 99.67%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0214, Average Validation Loss: 0.0042, Accuracy: 99.89%, Precision: 99.86%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0206, Accuracy: 99.67%, Precision: 99.99%, Recall: 99.44%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0158, Accuracy: 99.84%, Precision: 99.76%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0110, Average Validation Loss: 0.0086, Accuracy: 99.85%, Precision: 99.97%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0063, Accuracy: 99.92%, Precision: 99.98%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0140, Average Validation Loss: 0.0047, Accuracy: 99.91%, Precision: 99.93%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:38:18,645] Trial 44 finished with value: 0.0046461412450065145 and parameters: {'vector_length': 2048, 'hidden_length': 1024, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0047715483090722, 'warmup_steps': 60}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 23,960,320 parameters\n","Num non-decayed parameter tensors: 11, with 6,274 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5790, Average Validation Loss: 0.3286, Accuracy: 94.56%, Precision: 99.96%, Recall: 91.35%, F1: 0.95\n","Epoch 0, Average Training Loss: 0.1498, Average Validation Loss: 0.0309, Accuracy: 99.50%, Precision: 99.69%, Recall: 99.43%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0120, Average Validation Loss: 0.0088, Accuracy: 99.75%, Precision: 99.78%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0066, Average Validation Loss: 0.0072, Accuracy: 99.78%, Precision: 99.69%, Recall: 99.92%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0089, Average Validation Loss: 0.0076, Accuracy: 99.79%, Precision: 99.90%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0139, Average Validation Loss: 0.0029, Accuracy: 99.92%, Precision: 99.95%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0020, Accuracy: 99.94%, Precision: 99.95%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0017, Accuracy: 99.96%, Precision: 99.94%, Recall: 99.99%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0017, Accuracy: 99.95%, Precision: 99.93%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0013, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0016, Accuracy: 99.95%, Precision: 99.93%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0010, Average Validation Loss: 0.0012, Accuracy: 99.96%, Precision: 99.96%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0013, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:40:28,999] Trial 45 finished with value: 0.0012760148226113194 and parameters: {'vector_length': 2048, 'hidden_length': 128, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0018268738694919432, 'warmup_steps': 50}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 23,960,320 parameters\n","Num non-decayed parameter tensors: 11, with 6,274 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.5062, Average Validation Loss: 0.1927, Accuracy: 98.05%, Precision: 99.89%, Recall: 96.81%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0768, Average Validation Loss: 0.0125, Accuracy: 99.65%, Precision: 99.72%, Recall: 99.67%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0161, Average Validation Loss: 0.0101, Accuracy: 99.68%, Precision: 99.55%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0064, Average Validation Loss: 0.0058, Accuracy: 99.87%, Precision: 99.87%, Recall: 99.90%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0035, Accuracy: 99.87%, Precision: 99.87%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0036, Accuracy: 99.88%, Precision: 99.89%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0066, Accuracy: 99.86%, Precision: 99.76%, Recall: 100.00%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0042, Average Validation Loss: 0.0061, Accuracy: 99.90%, Precision: 99.85%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0052, Average Validation Loss: 0.0028, Accuracy: 99.93%, Precision: 99.97%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0038, Accuracy: 99.88%, Precision: 99.87%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:42:09,491] Trial 46 finished with value: 0.003763723046191641 and parameters: {'vector_length': 2048, 'hidden_length': 128, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.1, 'metadata_vector_length': 2048, 'lr': 0.002881727985489531, 'warmup_steps': 50}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 23,960,320 parameters\n","Num non-decayed parameter tensors: 11, with 6,274 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.3682, Average Validation Loss: 0.0282, Accuracy: 99.43%, Precision: 99.41%, Recall: 99.59%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0127, Average Validation Loss: 0.0091, Accuracy: 99.78%, Precision: 99.79%, Recall: 99.81%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0344, Average Validation Loss: 0.0093, Accuracy: 99.77%, Precision: 99.66%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0009, Average Validation Loss: 0.0130, Accuracy: 99.79%, Precision: 99.81%, Recall: 99.82%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0263, Average Validation Loss: 0.0230, Accuracy: 99.57%, Precision: 99.27%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0064, Average Validation Loss: 0.0098, Accuracy: 99.78%, Precision: 99.98%, Recall: 99.65%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0154, Average Validation Loss: 0.0035, Accuracy: 99.88%, Precision: 99.99%, Recall: 99.80%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0046, Average Validation Loss: 0.0032, Accuracy: 99.95%, Precision: 99.93%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0014, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.92%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0014, Accuracy: 99.95%, Precision: 99.98%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0017, Accuracy: 99.94%, Precision: 99.93%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0018, Accuracy: 99.95%, Precision: 99.93%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0015, Accuracy: 99.94%, Precision: 99.95%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0013, Accuracy: 99.95%, Precision: 99.96%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:44:28,344] Trial 47 finished with value: 0.0013067155975747752 and parameters: {'vector_length': 2048, 'hidden_length': 128, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 2048, 'lr': 0.0057012837774030305, 'warmup_steps': 40}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 2,058,112 parameters\n","Num non-decayed parameter tensors: 11, with 4,738 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6683, Average Validation Loss: 0.6199, Accuracy: 92.95%, Precision: 99.76%, Recall: 89.19%, F1: 0.94\n","Epoch 0, Average Training Loss: 0.5467, Average Validation Loss: 0.4399, Accuracy: 90.90%, Precision: 99.97%, Recall: 86.29%, F1: 0.93\n","Epoch 0, Average Training Loss: 0.3362, Average Validation Loss: 0.1787, Accuracy: 97.69%, Precision: 99.83%, Recall: 96.27%, F1: 0.98\n","Epoch 0, Average Training Loss: 0.0977, Average Validation Loss: 0.0303, Accuracy: 99.55%, Precision: 99.80%, Recall: 99.42%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0145, Average Validation Loss: 0.0055, Accuracy: 99.84%, Precision: 99.95%, Recall: 99.78%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0037, Average Validation Loss: 0.0055, Accuracy: 99.86%, Precision: 99.88%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0075, Average Validation Loss: 0.0044, Accuracy: 99.88%, Precision: 99.93%, Recall: 99.86%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0054, Average Validation Loss: 0.0080, Accuracy: 99.77%, Precision: 99.88%, Recall: 99.72%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0077, Average Validation Loss: 0.0060, Accuracy: 99.84%, Precision: 99.84%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0070, Average Validation Loss: 0.0042, Accuracy: 99.89%, Precision: 99.95%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0043, Average Validation Loss: 0.0045, Accuracy: 99.86%, Precision: 99.97%, Recall: 99.79%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0125, Average Validation Loss: 0.0033, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0065, Average Validation Loss: 0.0031, Accuracy: 99.91%, Precision: 99.97%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0033, Accuracy: 99.92%, Precision: 99.93%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0030, Average Validation Loss: 0.0028, Accuracy: 99.92%, Precision: 99.95%, Recall: 99.91%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0025, Accuracy: 99.92%, Precision: 99.97%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0007, Average Validation Loss: 0.0025, Accuracy: 99.92%, Precision: 99.99%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:47:11,837] Trial 48 finished with value: 0.0025381933247027103 and parameters: {'vector_length': 128, 'hidden_length': 128, 'num_layers': 2, 'num_epochs': 4, 'dropout': 0.2, 'metadata_vector_length': 512, 'lr': 0.0008909145424369177, 'warmup_steps': 50}. Best is trial 17 with value: 0.0007610484100020571.\n"]},{"name":"stdout","output_type":"stream","text":["Num decayed parameter tensors: 12, with 3,773,440 parameters\n","Num non-decayed parameter tensors: 11, with 6,274 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.6243, Average Validation Loss: 0.4527, Accuracy: 98.36%, Precision: 99.77%, Recall: 97.43%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.2664, Average Validation Loss: 0.0997, Accuracy: 98.60%, Precision: 99.88%, Recall: 97.73%, F1: 0.99\n","Epoch 0, Average Training Loss: 0.0596, Average Validation Loss: 0.0169, Accuracy: 99.59%, Precision: 99.58%, Recall: 99.70%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0099, Average Validation Loss: 0.0074, Accuracy: 99.77%, Precision: 99.94%, Recall: 99.66%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0104, Average Validation Loss: 0.0043, Accuracy: 99.86%, Precision: 99.84%, Recall: 99.92%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0026, Average Validation Loss: 0.0023, Accuracy: 99.93%, Precision: 99.94%, Recall: 99.93%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0049, Average Validation Loss: 0.0038, Accuracy: 99.86%, Precision: 100.00%, Recall: 99.76%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0006, Average Validation Loss: 0.0024, Accuracy: 99.90%, Precision: 100.00%, Recall: 99.83%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0014, Average Validation Loss: 0.0012, Accuracy: 99.96%, Precision: 99.96%, Recall: 99.97%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0012, Average Validation Loss: 0.0016, Accuracy: 99.95%, Precision: 99.93%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0004, Average Validation Loss: 0.0012, Accuracy: 99.97%, Precision: 99.97%, Recall: 99.98%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0012, Accuracy: 99.96%, Precision: 99.97%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0013, Accuracy: 99.96%, Precision: 99.97%, Recall: 99.96%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0013, Accuracy: 99.96%, Precision: 99.95%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 5 steps.\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-12-07 17:49:26,968] Trial 49 finished with value: 0.0013402563828364962 and parameters: {'vector_length': 256, 'hidden_length': 128, 'num_layers': 2, 'num_epochs': 3, 'dropout': 0.1, 'metadata_vector_length': 2048, 'lr': 0.0014236869562677086, 'warmup_steps': 60}. Best is trial 17 with value: 0.0007610484100020571.\n"]}],"source":["# Create an Optuna study\n","study = optuna.create_study(direction=\"minimize\")\n","\n","# Run the optimization\n","study.optimize(objective, n_trials=50)"]},{"cell_type":"code","source":["# Print the best hyperparameters\n","print(\"Best hyperparameters:\")\n","for key, value in study.best_params.items():\n","    print(f\"{key}: {value}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b06_mK-EerWM","executionInfo":{"status":"ok","timestamp":1733597784839,"user_tz":-240,"elapsed":1011,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"}},"outputId":"4db285e7-69ad-45ba-9c12-6282d0efd460"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["vector_length: 2048\n","hidden_length: 1024\n","num_layers: 3\n","num_epochs: 1\n","dropout: 0.2\n","metadata_vector_length: 2048\n","lr: 0.0028833488994399175\n","warmup_steps: 10\n"]}]},{"cell_type":"code","source":["vector_length = 2048\n","hidden_length = 1024\n","num_layers = 3\n","num_epochs = 1\n","dropout = 0.2\n","metadata_vector_length = 2048\n","lr = 0.0028833488994399175\n","warmup_steps = 10\n","\n","scheduler_config = {\"warmup_steps\": warmup_steps,\n","                    \"max_steps\": num_epochs * len(train_loader),\n","                    \"max_lr\": lr,\n","                    \"min_lr\": lr * 0.1}"],"metadata":{"id":"M4tG85bwemEn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s285dUyEs6Q5"},"outputs":[],"source":["model = LSTM_model(\n","    vocab_size=10240,                    # Vocabulary size\n","    vector_length=vector_length,              # Embedding size\n","    hidden_length=hidden_length,\n","    num_layers=num_layers,                    # Number of transformer blocks\n","    dropout=dropout,                          # Dropout rate\n","    padding_idx=tokenizer.padding_idx,        # Padding token index (from tokenizer)\n","    num_metadata_features=num_metadata_features,  # Metadata feature count\n","    metadata_vector_length=metadata_vector_length,  # Metadata vector size\n","    num_classes=2                   # Number of output classes\n",").to(device)  # Send model to the appropriate device\n","model = torch.compile(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":626953,"status":"ok","timestamp":1733599289746,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"smlEHr0n4p2p","outputId":"b6483247-0c77-4f5c-b1d4-d406a2cfa670"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num decayed parameter tensors: 16, with 98,199,552 parameters\n","Num non-decayed parameter tensors: 15, with 52,226 parameters\n","Using fused AdamW: True\n","Epoch 0, Average Training Loss: 0.2105, Average Validation Loss: 0.0137, Accuracy: 99.68%, Precision: 99.59%, Recall: 99.84%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0220, Average Validation Loss: 0.0395, Accuracy: 99.72%, Precision: 99.97%, Recall: 99.55%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0197, Average Validation Loss: 0.0292, Accuracy: 99.73%, Precision: 99.63%, Recall: 99.90%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0164, Average Validation Loss: 0.0236, Accuracy: 99.82%, Precision: 99.96%, Recall: 99.73%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0506, Average Validation Loss: 0.0112, Accuracy: 99.87%, Precision: 99.81%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0045, Average Validation Loss: 0.0032, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.94%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0052, Average Validation Loss: 0.0027, Accuracy: 99.94%, Precision: 99.99%, Recall: 99.91%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0157, Average Validation Loss: 0.0023, Accuracy: 99.95%, Precision: 99.97%, Recall: 99.95%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0002, Average Validation Loss: 0.0026, Accuracy: 99.93%, Precision: 99.93%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0016, Average Validation Loss: 0.0121, Accuracy: 99.78%, Precision: 99.67%, Recall: 99.94%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0007, Average Validation Loss: 0.0070, Accuracy: 99.87%, Precision: 99.85%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0076, Average Validation Loss: 0.0047, Accuracy: 99.91%, Precision: 99.96%, Recall: 99.89%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0190, Average Validation Loss: 0.0021, Accuracy: 99.96%, Precision: 99.96%, Recall: 99.96%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0018, Average Validation Loss: 0.0063, Accuracy: 99.80%, Precision: 99.66%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0025, Average Validation Loss: 0.0024, Accuracy: 99.94%, Precision: 99.96%, Recall: 99.95%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0028, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0031, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0032, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0041, Average Validation Loss: 0.0027, Accuracy: 99.95%, Precision: 99.99%, Recall: 99.93%, F1: 1.00\n","No significant improvement in validation loss for 6 step(s).\n","Epoch 0, Average Training Loss: 0.0035, Average Validation Loss: 0.0034, Accuracy: 99.93%, Precision: 100.00%, Recall: 99.87%, F1: 1.00\n","No significant improvement in validation loss for 7 step(s).\n","Epoch 0, Average Training Loss: 0.0097, Average Validation Loss: 0.0014, Accuracy: 99.96%, Precision: 99.93%, Recall: 99.99%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0017, Average Validation Loss: 0.0009, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0008, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0008, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 1 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0008, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 2 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0008, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 3 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0007, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 4 step(s).\n","Epoch 0, Average Training Loss: 0.0050, Average Validation Loss: 0.0008, Accuracy: 99.99%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 5 step(s).\n","Epoch 0, Average Training Loss: 0.0001, Average Validation Loss: 0.0032, Accuracy: 99.93%, Precision: 100.00%, Recall: 99.88%, F1: 1.00\n","No significant improvement in validation loss for 6 step(s).\n","Epoch 0, Average Training Loss: 0.0019, Average Validation Loss: 0.0021, Accuracy: 99.95%, Precision: 100.00%, Recall: 99.92%, F1: 1.00\n","No significant improvement in validation loss for 7 step(s).\n","Epoch 0, Average Training Loss: 0.0008, Average Validation Loss: 0.0010, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.97%, F1: 1.00\n","No significant improvement in validation loss for 8 step(s).\n","Epoch 0, Average Training Loss: 0.0003, Average Validation Loss: 0.0007, Accuracy: 99.98%, Precision: 99.99%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 9 step(s).\n","Epoch 0, Average Training Loss: 0.0000, Average Validation Loss: 0.0011, Accuracy: 99.97%, Precision: 99.96%, Recall: 99.99%, F1: 1.00\n","No significant improvement in validation loss for 10 step(s).\n","Early stopping at epoch 0: Validation loss did not improve for 10 steps.\n"]}],"source":["optimizer = model.configure_optimizers(weight_decay=0.01, learning_rate=max_lr, device_type=device) # torch.optim.AdamW(model.parameters(), lr=max_lr)\n","\n","model = train_model(model, train_loader, val_loader, num_epochs=num_epochs, optimizer=optimizer, device=device, fp16=True, scheduler_config=scheduler_config, log_interval=10, early_stopping=True, patience=10, improvement_threshold=0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15688,"status":"ok","timestamp":1733599305412,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"Kun0xTY3Oud1","outputId":"62ec07c1-e562-4d3d-db0f-c923e658f191"},"outputs":[{"output_type":"stream","name":"stdout","text":["Final Test Loss: 0.0024\n","Final Accuracy: 99.98%\n","Precision: 1.00\n","Recall: 1.00\n","F1 Score: 1.00\n"]}],"source":["test_results = run_inference_and_collect_results(model, test_loader, device, fp16=True)\n","test_loss = test_model(model, test_loader, device, fp16=False)\n","\n","accuracy = accuracy_score(test_results['Predicted Outputs'], test_results['True Labels']) * 100\n","precision = precision_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","recall = recall_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","f1 = f1_score(test_results['True Labels'], test_results['Predicted Outputs'])\n","\n","print(f'Final Test Loss: {test_loss:.4f}')\n","print(f\"Final Accuracy: {accuracy:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":18127,"status":"ok","timestamp":1733599323535,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"gHGB2OmuDvgw","outputId":"616cc765-a3a9-4b8f-ee8b-a6e61bd6d71f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["The Area Under Curve (AUC) is: 1.00\n"]}],"source":["auc = calculate_auc_roc(model, test_loader, device)\n","plot_confusion_matrix(model, test_loader, device)\n","print(f'The Area Under Curve (AUC) is: {auc:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQeLMjnPE3AA"},"outputs":[],"source":["adversarial_tokenized_dataset = load_from_disk(path+\"Datasets/TransformedDataset/\")\n","\n","adversarial_train_dataset = adversarial_tokenized_dataset['train']\n","adversarial_val_dataset = adversarial_tokenized_dataset['validation']\n","adversarial_test_dataset = adversarial_tokenized_dataset['test']\n","\n","batch_size = 128\n","\n","# Prepare dataloaders for batching the data during training and evaluation\n","adversarial_train_loader = DataLoader(adversarial_train_dataset, batch_size=batch_size, shuffle=True)\n","adversarial_val_loader = DataLoader(adversarial_val_dataset, batch_size=batch_size, shuffle=True)\n","adversarial_test_loader = DataLoader(adversarial_test_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"527ilmeFKzUm"},"outputs":[],"source":["adversarial_losses = test_model_adversarial(model, adversarial_test_loader, device, fp16=True)\n","adversarial_results = run_inference_and_collect_results_adversarial(model, adversarial_test_loader, device, fp16=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1733599392656,"user":{"displayName":"Amr Tamer","userId":"02148080871367257808"},"user_tz":-240},"id":"QMHU93MYR6D9","outputId":"f939350a-2bfb-48e4-c5a8-b73b55429174"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adversarial Losses:\n","Original Loss: 0.0024\n","Similar Characters Loss: 0.0024\n","Case Symbols Loss: 0.0024\n","Unicode Replacement Loss: 0.0024\n","\n","Results for Original Inputs:\n","  Accuracy: 99.98%\n","  Precision: 1.00\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n","Results for Similar Inputs:\n","  Accuracy: 99.98%\n","  Precision: 1.00\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n","Results for Case symbols Inputs:\n","  Accuracy: 99.98%\n","  Precision: 1.00\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n","Results for Unicode Inputs:\n","  Accuracy: 99.98%\n","  Precision: 1.00\n","  Recall: 1.00\n","  F1 Score: 1.00\n","\n","\n"]}],"source":["print(\"Adversarial Losses:\")\n","print(f\"Original Loss: {adversarial_losses['original_loss']:.4f}\")\n","print(f\"Similar Characters Loss: {adversarial_losses['similar_loss']:.4f}\")\n","print(f\"Case Symbols Loss: {adversarial_losses['case_symbols_loss']:.4f}\")\n","print(f\"Unicode Replacement Loss: {adversarial_losses['unicode_loss']:.4f}\\n\")\n","\n","# Evaluate metrics for each type\n","for key in adversarial_results:\n","    predictions = adversarial_results[key][\"predictions\"]\n","    labels = adversarial_results[key][\"labels\"]\n","\n","    accuracy = accuracy_score(labels, predictions) * 100\n","    precision = precision_score(labels, predictions)\n","    recall = recall_score(labels, predictions)\n","    f1 = f1_score(labels, predictions)\n","\n","    print(f\"Results for {key.capitalize()} Inputs:\")\n","    print(f\"  Accuracy: {accuracy:.2f}%\")\n","    print(f\"  Precision: {precision:.2f}\")\n","    print(f\"  Recall: {recall:.2f}\")\n","    print(f\"  F1 Score: {f1:.2f}\")\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Am2bN2givqYG"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}